[
  {
    "name": "Julian McAuley",
    "scholar_id": "icbo4M0AAAAJ",
    "publications": [
      {
        "title": "Image-based recommendations on styles and substitutes",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:j3f4tGmQtD8C",
        "authors": [
          "Julian McAuley",
          "Christopher Targett",
          "Qinfeng Shi",
          "Anton van den Hengel"
        ],
        "publication_date": "2015-10-17",
        "conference": "SIGIR",
        "description": "Humans inevitably develop a sense of the relationships between objects, some of which are based on their appearance. Some pairs of objects might be seen as being alternatives to each other (such as two pairs of jeans), while others may be seen as being complementary (such as a pair of jeans and a matching shirt). This information guides many of the choices that people make, from buying clothes to their interactions with each other. We seek here to model this human sense of the relationships between objects based on their appearance. Our approach is not based on fine-grained modeling of user annotations but rather on capturing the largest dataset possible and developing a scalable method for uncovering human notions of the visual relationships within. We cast this as a network inference problem defined on graphs of related images, and provide a large-scale dataset for the training and evaluation of the\u00a0\u2026",
        "total_citations": 2678
      },
      {
        "title": "Learning to discover social circles in ego networks",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:evX43VCCuoAC",
        "authors": [
          "Julian McAuley",
          "Jure Leskovec"
        ],
        "publication_date": "2012-10-17",
        "conference": "Advances in Neural Information Processing Systems",
        "pages": "539-547",
        "total_citations": 2587
      },
      {
        "title": "Self-attentive sequential recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:kRWSkSYxWN8C",
        "authors": [
          "Wang-Cheng Kang",
          "Julian McAuley"
        ],
        "publication_date": "2018-10-17",
        "conference": "International Conference on Data Mining",
        "description": "Sequential dynamics are a key feature of many modern recommender systems, which seek to capture the 'context' of users' activities on the basis of actions they have performed recently. To capture such patterns, two approaches have proliferated: Markov Chains (MCs) and Recurrent Neural Networks (RNNs). Markov Chains assume that a user's next action can be predicted on the basis of just their last (or last few) actions, while RNNs in principle allow for longer-term semantics to be uncovered. Generally speaking, MC-based methods perform best in extremely sparse datasets, where model parsimony is critical, while RNNs perform better in denser datasets where higher model complexity is affordable. The goal of our work is to balance these two goals, by proposing a self-attention based sequential model (SASRec) that allows us to capture long-term semantics (like an RNN), but, using an attention mechanism\u00a0\u2026",
        "total_citations": 2496
      },
      {
        "title": "Modeling the visual evolution of fashion trends with one-class collaborative filtering",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:NMxIlDl6LWMC",
        "authors": [
          "Ruining He",
          "Julian McAuley"
        ],
        "publication_date": "2016-04-17",
        "conference": "World Wide Web",
        "total_citations": 2366
      },
      {
        "title": "Hidden factors and hidden topics: understanding rating dimensions with review text",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:4DMP91E08xMC",
        "authors": [
          "Julian McAuley",
          "Jure Leskovec"
        ],
        "publication_date": "2013-10-17",
        "conference": "ACM Conference on Recommender Systems",
        "description": "In order to recommend products to users we must ultimately predict how a user will respond to a new product. To do so we must uncover the implicit tastes of each user as well as the properties of each product. For example, in order to predict whether a user will enjoy Harry Potter, it helps to identify that the book is about wizards, as well as the user's level of interest in wizardry. User feedback is required to discover these latent product and user dimensions. Such feedback often comes in the form of a numeric rating accompanied by review text. However, traditional methods often discard review text, which makes user and product latent dimensions difficult to interpret, since they ignore the very text that justifies a user's rating. In this paper, we aim to combine latent rating dimensions (such as those of latent-factor recommender systems) with latent review topics (such as those learned by topic models like LDA). Our\u00a0\u2026",
        "total_citations": 2201
      },
      {
        "title": "Justifying recommendations using distantly-labeled reviews and fine-grained aspects",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:g3aElNc5_aQC",
        "authors": [
          "Jianmo Ni",
          "Jiacheng Li",
          "Julian McAuley"
        ],
        "publication_date": "2019-10-17",
        "conference": "Empirical Methods in Natural Language Processing",
        "description": "Several recent works have considered the problem of generating reviews (or \u2018tips\u2019) as a form of explanation as to why a recommendation might match a customer\u2019s interests. While promising, we demonstrate that existing approaches struggle (in terms of both quality and content) to generate justifications that are relevant to users\u2019 decision-making process. We seek to introduce new datasets and methods to address the recommendation justification task. In terms of data, we first propose an \u2018extractive\u2019approach to identify review segments which justify users\u2019 intentions; this approach is then used to distantly label massive review corpora and construct large-scale personalized recommendation justification datasets. In terms of generation, we are able to design two personalized generation models with this data:(1) a reference-based Seq2Seq model with aspect-planning which can generate justifications covering different aspects, and (2) an aspect-conditional masked language model which can generate diverse justifications based on templates extracted from justification histories. We conduct experiments on two real-world datasets which show that our model is capable of generating convincing and diverse justifications.",
        "total_citations": 1437
      },
      {
        "title": "Community detection in networks with node attributes",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:qUcmZB5y_30C",
        "authors": [
          "Jaewon Yang",
          "Julian McAuley",
          "Jure Leskovec"
        ],
        "publication_date": "2013-10-17",
        "conference": "International Conference on Data Mining",
        "description": "Community detection algorithms are fundamental tools that allow us to uncover organizational principles in networks. When detecting communities, there are two possible sources of information one can use: the network structure, and the features and attributes of nodes. Even though communities form around nodes that have common edges and common attributes, typically, algorithms have only focused on one of these two data modalities: community detection algorithms traditionally focus only on the network structure, while clustering algorithms mostly consider only node attributes. In this paper, we develop Communities from Edge Structure and Node Attributes (CESNA), an accurate and scalable algorithm for detecting overlapping communities in networks with node attributes. CESNA statistically models the interaction between the network structure and the node attributes, which leads to more accurate\u00a0\u2026",
        "total_citations": 1100
      },
      {
        "title": "Adversarial Audio Synthesis",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:9vf0nzSNQJEC",
        "authors": [
          "Chris Donahue",
          "Julian McAuley",
          "Miller Puckette"
        ],
        "publication_date": "2019-10-17",
        "conference": "International Conference on Learning Representations",
        "description": "Audio signals are sampled at high temporal resolutions, and learning to synthesize audio requires capturing structure across a range of timescales. Generative adversarial networks (GANs) have seen wide success at generating images that are both locally and globally coherent, but they have seen little application to audio generation. In this paper we introduce WaveGAN, a first attempt at applying GANs to unsupervised synthesis of raw-waveform audio. WaveGAN is capable of synthesizing one second slices of audio waveforms with global coherence, suitable for sound effect generation. Our experiments demonstrate that, without labels, WaveGAN learns to produce intelligible words when trained on a small-vocabulary speech dataset, and can also synthesize audio from other domains such as drums, bird vocalizations, and piano. We compare WaveGAN to a method which applies GANs designed for image generation on image-like audio feature representations, finding both approaches to be promising.",
        "total_citations": 1024
      },
      {
        "title": "VBPR: Visual bayesian personalized ranking from implicit feedback",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:k_IJM867U9cC",
        "authors": [
          "Ruining He",
          "Julian McAuley"
        ],
        "publication_date": "2016-10-17",
        "conference": "AAAI Conference on Artificial Intelligence",
        "description": "Modern recommender systems model people and items by discovering orteasing apart'the underlying dimensions that encode the properties of items and users' preferences toward them. Critically, such dimensions are uncovered based on user feedback, often in implicit form (such as purchase histories, browsing logs, etc.); in addition, some recommender systems make use of side information, such as product attributes, temporal information, or review text. However one important feature that is typically ignored by existing personalized recommendation and ranking methods is the visual appearance of the items being considered. In this paper we propose a scalable factorization model to incorporate visual signals into predictors of people's opinions, which we apply to a selection of large, real-world datasets. We make use of visual features extracted from product images using (pre-trained) deep networks, on top of which we learn an additional layer that uncovers the visual dimensions that best explain the variation in people's feedback. This not only leads to significantly more accurate personalized ranking methods, but also helps to alleviate cold start issues, and qualitatively to analyze the visual dimensions that influence people's opinions.",
        "total_citations": 954
      },
      {
        "title": "Inferring networks of substitutable and complementary products",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:4JMBOYKVnBMC",
        "authors": [
          "Julian McAuley",
          "Rahul Pandey",
          "Jure Leskovec"
        ],
        "publication_date": "2015-10-17",
        "conference": "Knowledge Discovery and Data Mining",
        "description": "To design a useful recommender system, it is important to understand how products relate to each other. For example, while a user is browsing mobile phones, it might make sense to recommend other phones, but once they buy a phone, we might instead want to recommend batteries, cases, or chargers. In economics, these two types of recommendations are referred to as substitutes and complements: substitutes are products that can be purchased instead of each other, while complements are products that can be purchased in addition to each other. Such relationships are essential as they help us to identify items that are relevant to a user's search. Our goal in this paper is to learn the semantics of substitutes and complements from the text of online reviews. We treat this as a supervised learning problem, trained using networks of products derived from browsing and co-purchasing logs. Methodologically, we\u00a0\u2026",
        "total_citations": 904
      },
      {
        "title": "Fusing similarity models with Markov chains for sparse sequential recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:70eg2SAEIzsC",
        "authors": [
          "Ruining He",
          "Julian McAuley"
        ],
        "publication_date": "2016-10-17",
        "conference": "International Conference on Data Mining",
        "description": "Predicting personalized sequential behavior is a key task for recommender systems. In order to predict user actions such as the next product to purchase, movie to watch, or place to visit, it is essential to take into account both long-term user preferences and sequential patterns (i.e., short-term dynamics). Matrix Factorization and Markov Chain methods have emerged as two separate but powerful paradigms for modeling the two respectively. Combining these ideas has led to unified methods that accommodate long-and short-term dynamics simultaneously by modeling pairwise user-item and item-item interactions. In spite of the success of such methods for tackling dense data, they are challenged by sparsity issues, which are prevalent in real-world datasets. In recent years, similarity-based methods have been proposed for (sequentially-unaware) item recommendation with promising results on sparse datasets. In\u00a0\u2026",
        "total_citations": 789
      },
      {
        "title": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:ULOm3_A8WrAC",
        "authors": [
          "Julian John McAuley",
          "Jure Leskovec"
        ],
        "publication_date": "2013-05-13",
        "conference": "World Wide Web",
        "pages": "897-908",
        "description": "Recommending products to consumers means not only understanding their tastes, but also understanding their level of experience. For example, it would be a mistake to recommend the iconic film Seven Samurai simply because a user enjoys other action movies; rather, we might conclude that they will eventually enjoy it---once they are ready. The same is true for beers, wines, gourmet foods---or any products where users have acquired tastes: the `best' products may not be the most 'accessible'. Thus our goal in this paper is to recommend products that a user will enjoy now, while acknowledging that their tastes may have changed over time, and may change again in the future. We model how tastes change due to the very act of consuming more products---in other words, as users become more experienced. We develop a latent factor recommendation system that explicitly accounts for each user's level of\u00a0\u2026",
        "total_citations": 694
      },
      {
        "title": "Learning graph matching",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:u5HHmVD_uO8C",
        "authors": [
          "Tib\u00e9rio S Caetano",
          "Julian J McAuley",
          "Li Cheng",
          "Quoc V Le",
          "Alex J Smola"
        ],
        "publication_date": "2009-06-17",
        "pages": "1048-1058",
        "publisher": "IEEE",
        "description": "As a fundamental problem in pattern recognition, graph matching has applications in a variety of fields, from computer vision to computational biology. In graph matching, patterns are modeled as graphs and pattern recognition amounts to finding a correspondence between the nodes of different graphs. Many formulations of this problem can be cast in general as a quadratic assignment problem, where a linear term in the objective function encodes node compatibility and a quadratic term encodes edge compatibility. The main research focus in this theme is about designing efficient algorithms for approximately solving the quadratic assignment problem, since it is NP-hard. In this paper we turn our attention to a different question: how to estimate compatibility functions such that the solution of the resulting graph matching problem best matches the expected solution that a human would manually provide. We present\u00a0\u2026",
        "total_citations": 614
      },
      {
        "title": "Time-interval aware self-attention for sequential recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:tuHXwOkdijsC",
        "authors": [
          "Jiacheng Li",
          "Yujie Wang",
          "Julian McAuley"
        ],
        "publication_date": "2020-10-17",
        "conference": "Web Search and Data Mining",
        "description": "Sequential recommender systems seek to exploit the order of users' interactions, in order to predict their next action based on the context of what they have done recently. Traditionally, Markov Chains(MCs), and more recently Recurrent Neural Networks (RNNs) and Self Attention (SA) have proliferated due to their ability to capture the dynamics of sequential patterns. However a simplifying assumption made by most of these models is to regard interaction histories as ordered sequences, without regard for the time intervals between each interaction (i.e., they model the time-order but not the actual timestamp). In this paper, we seek to explicitly model the timestamps of interactions within a sequential modeling framework to explore the influence of different time intervals on next item prediction. We propose TiSASRec (Time Interval aware Self-attention based sequential recommendation), which models both the\u00a0\u2026",
        "total_citations": 587
      },
      {
        "title": "Translation-based recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:cFHS6HbyZ2cC",
        "authors": [
          "Ruining He",
          "Wang-Cheng Kang",
          "Julian McAuley"
        ],
        "publication_date": "2017-07-08",
        "conference": "ACM Conference on Recommender Systems",
        "description": "Modeling the complex interactions between users and items as well as amongst items themselves is at the core of designing successful recommender systems. One classical setting is predicting users' personalized sequential behavior (or 'next-item' recommendation), where the challenges mainly lie in modeling 'third-order' interactions between a user, her previously visited item(s), and the next item to consume. Existing methods typically decompose these higher-order interactions into a combination of pairwise relationships, by way of which user preferences (user-item interactions) and sequential patterns (item-item interactions) are captured by separate components. In this paper, we propose a unified method, TransRec, to model such third-order relationships for large-scale sequential prediction. Methodologically, we embed items into a 'transition space' where users are modeled as translation vectors operating\u00a0\u2026",
        "total_citations": 470
      },
      {
        "title": "Leveraging social connections to improve personalized ranking for collaborative filtering",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:HDshCWvjkbEC",
        "authors": [
          "Tong Zhao",
          "Julian McAuley",
          "Irwin King"
        ],
        "publication_date": "2014-10-17",
        "conference": "Conference on Information and Knowledge Management",
        "description": "Recommending products to users means estimating their preferences for certain items over others. This can be cast either as a problem of estimating the rating that each user will give to each item, or as a problem of estimating users' relative preferences in the form of a ranking. Although collaborative-filtering approaches can be used to identify users who rate and rank products similarly, another source of data that informs us about users' preferences is their set of social connections. Both rating- and ranking-based paradigms are important in real-world recommendation settings, though rankings are especially important in settings where explicit feedback in the form of a numerical rating may not be available. Although many existing works have studied how social connections can be used to build better models for rating prediction, few have used social connections as a means to derive more accurate ranking-based\u00a0\u2026",
        "total_citations": 448
      },
      {
        "title": "Discovering social circles in ego networks",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:Dip1O2bNi0gC",
        "authors": [
          "Julian Mcauley",
          "Jure Leskovec"
        ],
        "publication_date": "2014-02-01",
        "pages": "1-28",
        "publisher": "ACM",
        "description": "People's personal social networks are big and cluttered, and currently there is no good way to automatically organize them. Social networking sites allow users to manually categorize their friends into social circles (e.g., \u201ccircles\u201d on Google+, and \u201clists\u201d on Facebook and Twitter). However, circles are laborious to construct and must be manually updated whenever a user's network grows. In this article, we study the novel task of automatically identifying users' social circles. We pose this task as a multimembership node clustering problem on a user's ego network, a network of connections between her friends. We develop a model for detecting circles that combines network structure as well as user profile information. For each circle, we learn its members and the circle-specific user profile similarity metric. Modeling node membership to multiple circles allows us to detect overlapping as well as hierarchically nested\u00a0\u2026",
        "total_citations": 397
      },
      {
        "title": "Learning visual clothing style with heterogeneous dyadic co-occurrences",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:bEWYMUwI8FkC",
        "authors": [
          "Andreas Veit",
          "Balazs Kovacs",
          "Sean Bell",
          "Julian McAuley",
          "Kavita Bala",
          "Serge Belongie"
        ],
        "publication_date": "2015-10-17",
        "conference": "International Conference on Computer Vision",
        "description": "With the rapid proliferation of smart mobile devices, users now take millions of photos every day. These include large numbers of clothing and accessory images. We would like to answer questions likeWhat outfit goes well with this pair of shoes?'To answer these types of questions, one has to go beyond learning visual similarity and learn a visual notion of compatibility across categories. In this paper, we propose a novel learning framework to help answer these types of questions. The main idea of this framework is to learn a feature transformation from images of items into a latent space that expresses compatibility. For the feature transformation, we use a Siamese Convolutional Neural Network (CNN) architecture, where training examples are pairs of items that are either compatible or incompatible. We model compatibility based on co-occurrence in large-scale user behavior data; in particular co-purchase data from Amazon. com. To learn cross-category fit, we introduce a strategic method to sample training data, where pairs of items are heterogeneous dyads, ie, the two elements of a pair belong to different high-level categories. While this approach is applicable to a wide variety of settings, we focus on the representative problem of learning compatible clothing style. Our results indicate that the proposed framework is capable of learning semantic information about visual style and is able to generate outfits of clothes, with items from different categories, that go well together.",
        "total_citations": 375
      },
      {
        "title": "Learning attitudes and attributes from multi-aspect reviews",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:9ZlFYXVOiuMC",
        "authors": [
          "Julian McAuley",
          "Jure Leskovec",
          "Dan Jurafsky"
        ],
        "publication_date": "2012-12-10",
        "conference": "International Conference on Data Mining",
        "pages": "1020-1025",
        "publisher": "IEEE",
        "description": "Most online reviews consist of plain-text feedback together with a single numeric score. However, understanding the multiple `aspects' that contribute to users' ratings may help us to better understand their individual preferences. For example, a user's impression of an audio book presumably depends on aspects such as the story and the narrator, and knowing their opinions on these aspects may help us to recommend better products. In this paper, we build models for rating systems in which such dimensions are explicit, in the sense that users leave separate ratings for each aspect of a product. By introducing new corpora consisting of five million reviews, rated with between three and six aspects, we evaluate our models on three prediction tasks: First, we uncover which parts of a review discuss which of the rated aspects. Second, we summarize reviews by finding the sentences that best explain a user's rating\u00a0\u2026",
        "total_citations": 349
      },
      {
        "title": "Visually-aware fashion recommendation and design with generative image models",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:D03iK_w7-QYC",
        "authors": [
          "Wang-Cheng Kang",
          "Chen Fang",
          "Zhaowen Wang",
          "Julian McAuley"
        ],
        "publication_date": "2017-10-17",
        "conference": "International Conference on Data Mining",
        "description": "Building effective recommender systems for domains like fashion is challenging due to the high level of subjectivity and the semantic complexity of the features involved (i.e., fashion styles). Recent work has shown that approaches to 'visual' recommendation (e.g. clothing, art, etc.) can be made more accurate by incorporating visual signals directly into the recommendation objective, using 'off-the-shelf' feature representations derived from deep networks. Here, we seek to extend this contribution by showing that recommendation performance can be significantly improved by learning 'fashion aware' image representations directly, i.e., by training the image representation (from the pixel level) and the recommender system jointly; this contribution is related to recent work using Siamese CNNs, though we are able to show improvements over state-of-the-art recommendation techniques such as BPR and variants that\u00a0\u2026",
        "total_citations": 328
      },
      {
        "title": "BERT Loses Patience: Fast and robust inference with early exit",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:sNmaIFBj_lkC",
        "authors": [
          "Wangchunshu Zhou",
          "Canwen Xu",
          "Tao Ge",
          "Julian McAuley",
          "Ke Xu",
          "Furu Wei"
        ],
        "publication_date": "2020-10-17",
        "conference": "Neural Information Processing Systems",
        "description": "In this paper, we propose Patience-based Early Exit, a straightforward yet effective inference method that can be used as a plug-and-play technique to simultaneously improve the efficiency and robustness of a pretrained language model (PLM). To achieve this, our approach couples an internal-classifier with each layer of a PLM and dynamically stops inference when the intermediate predictions of the internal classifiers do not change for a pre-defined number of steps. Our approach improves inference efficiency as it allows the model to make a prediction with fewer layers. Meanwhile, experimental results with an ALBERT model show that our method can improve the accuracy and robustness of the model by preventing it from overthinking and exploiting multiple classifiers for prediction, yielding a better accuracy-speed trade-off compared to existing early exit methods.",
        "total_citations": 309
      },
      {
        "title": "Rezero is all you need: Fast convergence at large depth",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:_5tno0g5mFcC",
        "authors": [
          "Thomas Bachlechner",
          "Bodhisattwa Prasad Majumder",
          "Huanru Henry Mao",
          "Garrison W Cottrell",
          "Julian McAuley"
        ],
        "publication_date": "2021-10-17",
        "conference": "Uncertainty in Artificial Intelligence",
        "description": "Deep networks often suffer from vanishing or exploding gradients due to inefficient signal propagation, leading to long training times or convergence difficulties. Various architecture designs, sophisticated residual-style networks, and initialization schemes have been shown to improve deep signal propagation. Recently, Pennington et al.[2017] used free probability theory to show that dynamical isometry plays an integral role in efficient deep learning. We show that the simplest architecture change of gating each residual connection using a single zero-initialized parameter satisfies initial dynamical isometry and outperforms more complex approaches. Although much simpler than its predecessors, this gate enables training thousands of fully connected layers with fast convergence and better test performance for ResNets trained on an image recognition task. We apply this technique to language modeling and find that we can easily train 120-layer Transformers. When applied to 12 layer Transformers, it converges 56% faster.",
        "total_citations": 307
      },
      {
        "title": "Item recommendation on monotonic behavior chains",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:mvPsJ3kp5DgC",
        "authors": [
          "Mengting Wan",
          "Julian McAuley"
        ],
        "publication_date": "2018-10-17",
        "conference": "ACM Conference on Recommender Systems",
        "description": "'Explicit' and 'implicit' feedback in recommender systems have been studied for many years, as two relatively isolated areas. However many real-world systems involve a spectrum of both implicit and explicit signals, ranging from clicks and purchases, to ratings and reviews. A natural question is whether implicit signals (which are dense but noisy) might help to predict explicit signals (which are sparse but reliable), or vice versa. Thus in this paper, we propose an item recommendation framework which jointly models this full spectrum of interactions. Our main observation is that in many settings, feedback signals exhibit monotonic dependency structures, i.e., any signal necessarily implies the presence of a weaker (or more implicit) signal (a 'review' action implies a 'purchase' action, which implies a 'click' action, etc.). We refer to these structures as 'monotonic behavior chains,' for which we develop new algorithms that\u00a0\u2026",
        "total_citations": 294
      },
      {
        "title": "Does mitigating ML's disparate impact require disparate treatment?",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:t6usbXjVLHcC",
        "authors": [
          "Zachary C Lipton",
          "Alexandra Chouldechova",
          "Julian McAuley"
        ],
        "publication_date": "2018-10-17",
        "conference": "Neural Information Processing Systems",
        "description": "Following related work in law and policy, two notions of prejudice have come to shape the study of fairness in algorithmic decision-making. Algorithms exhibit disparate treatment if they formally treat people differently according to a protected characteristic, like race, or if they intentionally discriminate (even if via proxy variables). Algorithms exhibit disparate impact if they affect subgroups differently. Disparate impact can arise unintentionally and absent disparate treatment. The natural way to reduce disparate impact would be to apply disparate treatment in favor of the disadvantaged group, ie to apply affirmative action. However, owing to the practice\u2019s contested legal status, several papers have proposed trying to eliminate both forms of unfairness simultaneously, introducing a family of algorithms that we denote disparate learning processes (DLPs). These processes incorporate the protected characteristic as an input to the learning algorithm (eg via a regularizer) but produce a model that cannot directly access the protected characteristic as an input. In this paper, we make the following arguments:(i) DLPs can be functionally equivalent to disparate treatment, and thus should carry the same legal status;(ii) when the protected characteristic is redundantly encoded in the nonsensitive features, DLPs can exactly apply any disparate treatment protocol;(iii) when the characteristic is only partially encoded, DLPs may induce within-class discrimination. Finally, we argue the normative point that rather than masking efforts towards proportional representation, it is preferable to undertake them transparently.",
        "total_citations": 269
      },
      {
        "title": "Large language models are zero-shot rankers for recommender systems",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:UmS_249rOGwC",
        "authors": [
          "Yupeng Hou",
          "Junjie Zhang",
          "Zihan Lin",
          "Hongyu Lu",
          "Ruobing Xie",
          "Julian McAuley",
          "Wayne Xin Zhao"
        ],
        "publication_date": "2023-10-17",
        "conference": "European Conference on Information Retrieval",
        "description": "Recently, large language models\u00a0(LLMs) (e.g., GPT-4) have demonstrated impressive general-purpose task-solving abilities, including the potential to approach recommendation tasks. Along this line of research, this work aims to investigate the capacity of LLMs that act as the ranking model for recommender systems. We first formalize the recommendation problem as a conditional ranking task, considering sequential interaction histories as conditions and the items retrieved by other candidate generation models as candidates. To solve the ranking task by LLMs, we carefully design the prompting template and conduct extensive experiments on two widely-used datasets. We show that LLMs have promising zero-shot ranking abilities but (1) struggle to perceive the order of historical interactions, and (2) can be biased by popularity or item positions in the prompts. We demonstrate that these issues can be alleviated\u00a0\u2026",
        "total_citations": 252
      },
      {
        "title": "Baize: An open-source chat model with parameter-efficient tuning on self-chat data",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:QsaTk4IG4EwC",
        "authors": [
          "Canwen Xu",
          "Daya Guo",
          "Nan Duan",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-17",
        "conference": "EMNLP",
        "description": "Chat models, such as ChatGPT, have shown impressive capabilities and have been rapidly adopted across numerous domains. However, these models are only accessible through a restricted API, creating barriers for new research and progress in the field. We propose a pipeline that can automatically generate a high-quality multi-turn chat corpus by leveraging ChatGPT to engage in a conversation with itself. Subsequently, we employ parameter-efficient tuning to enhance LLaMA, an open-source large language model. The resulting model, named Baize, demonstrates good performance in multi-turn dialogues with guardrails that minimize potential risks. Furthermore, we propose a new technique called Self-Distill with Feedback, to further improve the performance of the Baize models with feedback from ChatGPT. The Baize models and data are released for research purposes only at https://github.com/project-baize/baize-chatbot. An online demo is also available at https://huggingface.co/spaces/project-baize/chat-with-baize.",
        "total_citations": 244
      },
      {
        "title": "Intent contrastive learning for sequential recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:QD3KBmkZPeQC",
        "authors": [
          "Yongjun Chen",
          "Zhiwei Liu",
          "Jia Li",
          "Julian McAuley",
          "Caiming Xiong"
        ],
        "publication_date": "2022-02-05",
        "conference": "World Wide Web",
        "description": "Users\u2019 interactions with items are driven by various intents (e.g., preparing for holiday gifts, shopping for fishing equipment, etc.). However, users\u2019 underlying intents are often unobserved/latent, making it challenging to leverage such latent intents for Sequential recommendation (SR). To investigate the benefits of latent intents and leverage them effectively for recommendation, we propose Intent Contrastive Learning (ICL), a general learning paradigm that leverages a latent intent variable into SR. The core idea is to learn users\u2019 intent distribution functions from unlabeled user behavior sequences and optimize SR models with contrastive self-supervised learning (SSL) by considering the learnt intents to improve recommendation. Specifically, we introduce a latent variable to represent users\u2019 intents and learn the distribution function of the latent variable via clustering. We propose to leverage the learnt intents into SR\u00a0\u2026",
        "total_citations": 235
      },
      {
        "title": "Addressing complex and subjective product-related queries with customer reviews",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:JV2RwH3_ST0C",
        "authors": [
          "Julian McAuley",
          "Alex Yang"
        ],
        "publication_date": "2016-10-17",
        "conference": "World Wide Web",
        "description": "Online reviews are often our first port of call when considering products and purchases online. When evaluating a potential purchase, we may have a specific query in mind, e.g. `will this baby seat fit in the overhead compartment of a 747?' or `will I like this album if I liked Taylor Swift's 1989?'. To answer such questions we must either wade through huge volumes of consumer reviews hoping to find one that is relevant, or otherwise pose our question directly to the community via a Q/A system. In this paper we hope to fuse these two paradigms: given a large volume of previously answered queries about products, we hope to automatically learn whether a review of a product is relevant to a given query. We formulate this as a machine learning problem using a mixture-of-experts-type framework---here each review is an `expert' that gets to vote on the response to a particular query; simultaneously we learn a relevance\u00a0\u2026",
        "total_citations": 226
      },
      {
        "title": "Modeling consumer preferences and price sensitivities from large-scale grocery shopping transaction logs",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:3s1wT3WcHBgC",
        "authors": [
          "Mengting Wan",
          "Di Wang",
          "Matt Goldman",
          "Matt Taddy",
          "Justin Rao",
          "Jie Liu",
          "Dimitrios Lymberopoulos",
          "Julian McAuley"
        ],
        "publication_date": "2017-10-17",
        "conference": "World Wide Web",
        "description": "In order to match shoppers with desired products and provide personalized promotions, whether in online or offline shopping worlds, it is critical to model both consumer preferences and price sensitivities simultaneously. Personalized preferences have been thoroughly studied in the field of recommender systems, though price (and price sensitivity) has received relatively little attention. At the same time, price sensitivity has been richly explored in the area of economics, though typically not in the context of developing scalable, working systems to generate recommendations. In this study, we seek to bridge the gap between large-scale recommender systems and established consumer theories from economics, and propose a nested feature-based matrix factorization framework to model both preferences and price sensitivities. Quantitative and qualitative results indicate the proposed personalized, interpretable and\u00a0\u2026",
        "total_citations": 225
      },
      {
        "title": "Image labeling on a network: using social-network metadata for image classification",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:L8Ckcad2t8MC",
        "authors": [
          "Julian McAuley",
          "Jure Leskovec"
        ],
        "publication_date": "2012-01-01",
        "pages": "828-841",
        "publisher": "Springer Berlin Heidelberg",
        "description": " Large-scale image retrieval benchmarks invariably consist of images from the Web. Many of these benchmarks are derived from online photo sharing networks, like Flickr, which in addition to hosting images also provide a highly interactive social community. Such communities generate rich metadata that can naturally be harnessed for image classification and retrieval. Here we study four popular benchmark datasets, extending them with social-network metadata, such as the groups to which each image belongs, the comment thread associated with the image, who uploaded it, their location, and their network of friends. Since these types of data are inherently relational, we propose a model that explicitly accounts for the interdependencies between images sharing common properties. We model the task as a binary labeling problem on a network, and use structured learning techniques to learn model\u00a0\u2026",
        "total_citations": 212
      },
      {
        "title": "Adversarial deepfakes: Evaluating vulnerability of deepfake detectors to adversarial examples",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:6ZxmRoH8BuwC",
        "authors": [
          "Paarth Neekhara",
          "Shehzeen Hussain",
          "Malhar Jere",
          "Farinaz Koushanfar",
          "Julian McAuley"
        ],
        "publication_date": "2021-10-17",
        "conference": "Winter Conference on Applications of Computer Vision",
        "total_citations": 204
      },
      {
        "title": "The rich-club phenomenon across complex network hierarchies",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:9yKSN-GCB0IC",
        "authors": [
          "Julian J McAuley",
          "Luciano da Fontoura Costa",
          "Tib\u00e9rio S Caetano"
        ],
        "publication_date": "2007-08-20",
        "pages": "084103",
        "publisher": "American Institute of Physics",
        "description": "The \u201crich-club phenomenon\u201d in complex networks is characterized when nodes of higher degree are more interconnected than nodes with lower degree. The presence of this phenomenon may indicate several interesting high-level network properties, such as tolerance to hub failures. Here, the authors investigate the existence of this phenomenon across the hierarchies of several real-world networks. Their simulations reveal that the presence or absence of this phenomenon in a network does not imply its presence or absence in the network\u2019s successive hierarchies, and that this behavior is even nonmonotonic in some cases.The so-called rich-club phenomenon in complex networks is characterized when the hubs (ie, nodes with high degrees) are on average more intensely interconnected than the nodes with smaller degrees. More precisely, it happens when the nodes with degree larger than k tend to be more\u00a0\u2026",
        "total_citations": 198
      },
      {
        "title": "Understanding the interplay between titles, content, and communities in social media",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:aqlVkmm33-oC",
        "authors": [
          "Himabindu Lakkaraju",
          "Julian McAuley",
          "Jure Leskovec"
        ],
        "publication_date": "2013-06-28",
        "conference": "AAAI International Conference on Weblogs and Social Media",
        "total_citations": 195
      },
      {
        "title": "Contrastive self-supervised sequential recommendation with robust augmentation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:1taIhTC69MYC",
        "authors": [
          "Zhiwei Liu",
          "Yongjun Chen",
          "Jia Li",
          "Philip S Yu",
          "Julian McAuley",
          "Caiming Xiong"
        ],
        "publication_date": "2021-08-14",
        "description": "Sequential Recommendationdescribes a set of techniques to model dynamic user behavior in order to predict future interactions in sequential user data. At their core, such approaches model transition probabilities between items in a sequence, whether through Markov chains, recurrent networks, or more recently, Transformers. However both old and new issues remain, including data-sparsity and noisy data; such issues can impair the performance, especially in complex, parameter-hungry models. In this paper, we investigate the application of contrastive Self-Supervised Learning (SSL) to the sequential recommendation, as a way to alleviate some of these issues. Contrastive SSL constructs augmentations from unlabelled instances, where agreements among positive pairs are maximized. It is challenging to devise a contrastive SSL framework for a sequential recommendation, due to its discrete nature, correlations among items, and skewness of length distributions. To this end, we propose a novel framework, Contrastive Self-supervised Learning for sequential Recommendation (CoSeRec). We introduce two informative augmentation operators leveraging item correlations to create high-quality views for contrastive learning. Experimental results on three real-world datasets demonstrate the effectiveness of the proposed method on improving model performance and the robustness against sparse and noisy data. Our implementation is available online at \\url{https://github.com/YChen1993/CoSeRec}",
        "total_citations": 178
      },
      {
        "title": "A visually, socially, and temporally-aware model for artistic recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:35N4QoGY0k4C",
        "authors": [
          "Ruining He",
          "Chen Fang",
          "Zhaowen Wang",
          "Julian McAuley"
        ],
        "publication_date": "2016-10-17",
        "conference": "ACM Conference on Recommender Systems",
        "description": "Understanding users' interactions with highly subjective content---like artistic images---is challenging due to the complex semantics that guide our preferences. On the one hand one has to overcome `standard' recommender systems challenges, such as dealing with large, sparse, and long-tailed datasets. On the other, several new challenges present themselves, such as the need to model content in terms of its visual appearance, or even social dynamics, such as a preference toward a particular artist that is independent of the art they create. In this paper we build large-scale recommender systems to model the dynamics of a vibrant digital art community, Behance, consisting of tens of millions of interactions (clicks and 'appreciates') of users toward digital art. Methodologically, our main contributions are to model (a) rich content, especially in terms of its visual appearance; (b) temporal dynamics, in terms of how\u00a0\u2026",
        "total_citations": 170
      },
      {
        "title": "Fine-grained spoiler detection from large-scale review corpora",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:0KyAp5RtaNEC",
        "authors": [
          "Mengting Wan",
          "Rishabh Misra",
          "Ndapa Nakashole",
          "Julian McAuley"
        ],
        "publication_date": "2019-10-17",
        "conference": "Association for Computational Linguistics",
        "description": "This paper presents computational approaches for automatically detecting critical plot twists in reviews of media products. First, we created a large-scale book review dataset that includes fine-grained spoiler annotations at the sentence-level, as well as book and (anonymized) user information. Second, we carefully analyzed this dataset, and found that: spoiler language tends to be book-specific; spoiler distributions vary greatly across books and review authors; and spoiler sentences tend to jointly appear in the latter part of reviews. Third, inspired by these findings, we developed an end-to-end neural network architecture to detect spoiler sentences in review corpora. Quantitative and qualitative results demonstrate that the proposed method substantially outperforms existing baselines.",
        "total_citations": 154
      },
      {
        "title": "LakhNES: Improving multi-instrumental music generation with cross-domain pre-training",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:ipzZ9siozwsC",
        "authors": [
          "Chris Donahue",
          "Huanru Henry Mao",
          "Yiting Ethan Li",
          "Garrison W Cottrell",
          "Julian McAuley"
        ],
        "publication_date": "2019-10-17",
        "conference": "International Society for Music Information Retrieval Conference",
        "description": "We are interested in the task of generating multi-instrumental music scores. The Transformer architecture has recently shown great promise for the task of piano score generation; here we adapt it to the multi-instrumental setting. Transformers are complex, high-dimensional language models which are capable of capturing long-term structure in sequence data, but require large amounts of data to fit. Their success on piano score generation is partially explained by the large volumes of symbolic data readily available for that domain. We leverage the recently-introduced NES-MDB dataset of four-instrument scores from an early video game sound synthesis chip (the NES), which we find to be well-suited to training with the Transformer architecture. To further improve the performance of our model, we propose a pre-training technique to leverage the information in a large collection of heterogeneous music, namely the Lakh MIDI dataset. Despite differences between the two corpora, we find that this transfer learning procedure improves both quantitative and qualitative performance for our primary task.",
        "total_citations": 151
      },
      {
        "title": "Universal adversarial perturbations for speech recognition systems",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:EkHepimYqZsC",
        "authors": [
          "Paarth Neekhara",
          "Shehzeen Hussain",
          "Prakhar Pandey",
          "Shlomo Dubnov",
          "Julian McAuley",
          "Farinaz Koushanfar"
        ],
        "publication_date": "2019-10-17",
        "conference": "Interspeech",
        "description": "In this work, we demonstrate the existence of universal adversarial audio perturbations that cause mis-transcription of audio signals by automatic speech recognition (ASR) systems. We propose an algorithm to find a single quasi-imperceptible perturbation, which when added to any arbitrary speech signal, will most likely fool the victim speech recognition model. Our experiments demonstrate the application of our proposed technique by crafting audio-agnostic universal perturbations for the state-of-the-art ASR system -- Mozilla DeepSpeech. Additionally, we show that such perturbations generalize to a significant extent across models that are not available during training, by performing a transferability test on a WaveNet based ASR system.",
        "total_citations": 139
      },
      {
        "title": "Semantically decomposing the latent spaces of generative adversarial networks",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:SP6oXDckpogC",
        "authors": [
          "Chris Donahue",
          "Zachary C Lipton",
          "Akshay Balsubramani",
          "Julian McAuley"
        ],
        "publication_date": "2018-10-17",
        "conference": "International Conference on Learning Representations",
        "description": "We propose a new algorithm for training generative adversarial networks that jointly learns latent codes for both identities (e.g. individual humans) and observations (e.g. specific photographs). By fixing the identity portion of the latent codes, we can generate diverse images of the same subject, and by fixing the observation portion, we can traverse the manifold of subjects while maintaining contingent aspects such as lighting and pose. Our algorithm features a pairwise training scheme in which each sample from the generator consists of two images with a common identity code. Corresponding samples from the real dataset consist of two distinct photographs of the same subject. In order to fool the discriminator, the generator must produce pairs that are photorealistic, distinct, and appear to depict the same individual. We augment both the DCGAN and BEGAN approaches with Siamese discriminators to facilitate pairwise training. Experiments with human judges and an off-the-shelf face verification system demonstrate our algorithm's ability to generate convincing, identity-matched photographs.",
        "total_citations": 136
      },
      {
        "title": "Estimating reactions and recommending products with generative models of reviews",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:_xSYboBqXhAC",
        "authors": [
          "Jianmo Ni",
          "Zachary C Lipton",
          "Sharad Vikram",
          "Julian McAuley"
        ],
        "publication_date": "2017-10-17",
        "conference": "International Joint Conference on Natural Language Processing",
        "pages": "783-791",
        "description": "Traditional approaches to recommendation focus on learning from large volumes of historical feedback to estimate simple numerical quantities (Will a user click on a product? Make a purchase? etc.). Natural language approaches that model information like product reviews have proved to be incredibly useful in improving the performance of such methods, as reviews provide valuable auxiliary information that can be used to better estimate latent user preferences and item properties. In this paper, rather than using reviews as an inputs to a recommender system, we focus on generating reviews as the model\u2019s output. This requires us to efficiently model text (at the character level) to capture the preferences of the user, the properties of the item being consumed, and the interaction between them (ie, the user\u2019s preference). We show that this can model can be used to (a) generate plausible reviews and estimate nuanced reactions;(b) provide personalized rankings of existing reviews; and (c) recommend existing products more effectively.",
        "total_citations": 134
      },
      {
        "title": "Representing and recommending shopping baskets with complementarity, compatibility, and loyalty",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:J-pR_7NvFogC",
        "authors": [
          "Mengting Wan",
          "Di Wang",
          "Jie Liu",
          "Paul N Bennett",
          "Julian McAuley"
        ],
        "publication_date": "2018-10-17",
        "conference": "Conference on Information and Knowledge Management",
        "description": "We study the problem of representing and recommending products for grocery shopping. We carefully investigate grocery transaction data and observe three important patterns: products within the same basket complement each other in terms of functionality (complementarity); users tend to purchase products that match their preferences (compatibility); and a significant fraction of users repeatedly purchase the same products over time (loyalty). Unlike conventional e-commerce settings, complementarity and loyalty are particularly predominant in the grocery shopping domain. This motivates a new representation learning approach to leverage complementarity and compatibility holistically, as well as a new recommendation approach to explicitly account for users' 'must-buy' purchases in addition to their overall preferences and needs. Doing so not only improves product classification and recommendation\u00a0\u2026",
        "total_citations": 130
      },
      {
        "title": "Generating and personalizing bundle recommendations on Steam",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:4OULZ7Gr8RgC",
        "authors": [
          "Apurva Pathak",
          "Kshitiz Gupta",
          "Julian McAuley"
        ],
        "publication_date": "2017-10-17",
        "conference": "SIGIR",
        "description": "Many websites offer promotions in terms of bundled items that can be purchased together, usually at a discounted rate. 'Bundling' may be a means of increasing sales revenue, but may also be a means for content creators to expose users to new items that they may not have considered in isolation. In this paper, we seek to understand the semantics of what constitutes a 'good' bundle, in order to recommend existing bundles to users on the basis of their constituent products, as well the more difficult task of generating new bundles that are personalized to a user. To do so we collect a new dataset from the Steam video game distribution platform, which is unique in that it contains both 'traditional' recommendation data (rating and purchase histories between users and items), as well as bundle purchase information. We assess issues such as bundle size and item compatibility, and show that these features, when\u00a0\u2026",
        "total_citations": 130
      },
      {
        "title": "Text Is All You Need: Learning language representations for sequential recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:DyXnQzXoVgIC",
        "authors": [
          "Jiacheng Li",
          "Ming Wang",
          "Jin Li",
          "Jinmiao Fu",
          "Xin Shen",
          "Jingbo Shang",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-17",
        "conference": "KDD",
        "description": "Sequential recommendation aims to model dynamic user behavior from historical interactions. Existing methods rely on either explicit item IDs or general textual features for sequence modeling to understand user preferences. While promising, these approaches still struggle to model cold-start items or transfer knowledge to new datasets. In this paper, we propose to model user preferences and item features as language representations that can be generalized to new items and datasets. To this end, we present a novel framework, named Recformer, which effectively learns language representations for sequential recommendation. Specifically, we propose to formulate an item as a \"sentence\" (word sequence) by flattening item key-value attributes described by text so that an item sequence for a user becomes a sequence of sentences. For recommendation, Recformer is trained to understand the \"sentence\"\u00a0\u2026",
        "total_citations": 128
      },
      {
        "title": "2D Convolutional neural networks for sequential recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:uWiczbcajpAC",
        "authors": [
          "An Yan",
          "Shuo Cheng",
          "Wang-Cheng Kang",
          "Mengting Wan",
          "Julian McAuley"
        ],
        "publication_date": "2019-10-17",
        "conference": "Conference on Information and Knowledge Management",
        "total_citations": 125
      },
      {
        "title": "Generating personalized recipes from historical user preferences",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:BUYA1_V_uYcC",
        "authors": [
          "Bodhisattwa Prasad Majumder",
          "Shuyang Li",
          "Jianmo Ni",
          "Julian McAuley"
        ],
        "publication_date": "2019-10-17",
        "conference": "Empirical Methods in Natural Language Processing",
        "description": "Existing approaches to recipe generation are unable to create recipes for users with culinary preferences but incomplete knowledge of ingredients in specific dishes. We propose a new task of personalized recipe generation to help these users: expanding a name and incomplete ingredient details into complete natural-text instructions aligned with the user's historical preferences. We attend on technique- and recipe-level representations of a user's previously consumed recipes, fusing these 'user-aware' representations in an attention fusion layer to control recipe text generation. Experiments on a new dataset of 180K recipes and 700K interactions show our model's ability to generate plausible and personalized recipes compared to non-personalized baselines.",
        "total_citations": 124
      },
      {
        "title": "Learning compatibility across categories for heterogeneous item recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:2P1L_qKh6hAC",
        "authors": [
          "Ruining He",
          "Charles Packer",
          "Julian McAuley"
        ],
        "publication_date": "2016-10-17",
        "conference": "International Conference on Data Mining",
        "description": "Identifying relationships between items is a key task of an online recommender system, in order to help users discover items that are functionally complementary or visually compatible. In domains like clothing recommendation, this task is particularly challenging since a successful system should be capable of handling a large corpus of items, a huge amount of relationships among them, as well as the high-dimensional and semantically complicated features involved. Furthermore, the human notion of \"compatibility\" to capture goes beyond mere similarity: For two items to be compatible-whether jeans and a t-shirt, or a laptop and a charger-they should be similar in some ways, but systematically different in others. In this paper we propose a novel method, Monomer, to learn complicated and heterogeneous relationships between items in product recommendation settings. Recently, scalable methods have been\u00a0\u2026",
        "total_citations": 116
      },
      {
        "title": "Modeling heart rate and activity data for personalized fitness recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:35r97b3x0nAC",
        "authors": [
          "Jianmo Ni",
          "Larry Muhlstein",
          "Julian McAuley"
        ],
        "publication_date": "2019-10-17",
        "conference": "World Wide Web",
        "description": "Activity logs collected from wearable devices (e.g. Apple Watch, Fitbit, etc.) are a promising source of data to facilitate a wide range of applications such as personalized exercise scheduling, workout recommendation, and heart rate anomaly detection. However, such data are heterogeneous, noisy, diverse in scale and resolution, and have complex interdependencies, making them challenging to model. In this paper, we develop context-aware sequential models to capture the personalized and temporal patterns of fitness data. Specifically, we propose FitRec - an LSTM-based model that captures two levels of context information: context within a specific activity, and context across a user's activity history. We are specifically interested in (a) estimating a user's heart rate profile for a candidate activity; and (b) predicting and recommending suitable activities on this basis. We evaluate our model on a novel dataset\u00a0\u2026",
        "total_citations": 111
      },
      {
        "title": "Consistent hierarchical labeling of image and image regions",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:tKAzc9rXhukC",
        "publication_date": "2016-05-31",
        "description": "Classification of image regions comprises: recursively partitioning an image into a tree of image regions having the image as a tree root and at least one image patch in each leaf image region of the tree, the tree having nodes defined by the image regions and edges defined by pairs of nodes connected by edges of the tree; assigning unary classification potentials to nodes of the tree; assigning pairwise classification potentials to edges of the tree; and labeling the image regions of the tree of image regions based on optimizing an objective function comprising an aggregation of the unary classification potentials and the pairwise classification potentials.",
        "total_citations": 110
      },
      {
        "title": "Modeling ambiguity, subjectivity, and diverging viewpoints in opinion question answering systems",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:ldfaerwXgEUC",
        "authors": [
          "Mengting Wan",
          "Julian McAuley"
        ],
        "publication_date": "2016-10-17",
        "conference": "International Conference on Data Mining",
        "description": "Product review websites provide an incredible lens into the wide variety of opinions and experiences of different people, and play a critical role in helping users discover products that match their personal needs and preferences. To help address questions that can't easily be answered by reading others' reviews, some review websites also allow users to pose questions to the community via a question-answering (QA) system. As one would expect, just as opinions diverge among different reviewers, answers to such questions may also be subjective, opinionated, and divergent. This means that answering such questions automatically is quite different from traditional QA tasks, where it is assumed that a single 'correct' answer is available. While recent work introduced the idea of question-answering using product reviews, it did not account for two aspects that we consider in this paper: (1) Questions have multiple\u00a0\u2026",
        "total_citations": 110
      },
      {
        "title": "Learning vector-quantized item representations for transferable sequential recommenders",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:An6A6Jpfc1oC",
        "authors": [
          "Yupeng Hou",
          "Zhankui He",
          "Julian McAuley",
          "Wayne Xin Zhao"
        ],
        "publication_date": "2023-10-17",
        "conference": "World Wide Web",
        "description": " Recently, the generality of natural language text has been leveraged to develop transferable recommender systems. The basic idea is to employ pre-trained language models\u00a0(PLM) to encode item text into item representations. Despite the promising transferability, the binding between item text and item representations might be too tight, leading to potential problems such as over-emphasizing the effect of text features and exaggerating the negative impact of domain gap. To address this issue, this paper proposes VQ-Rec, a novel approach to learning Vector-Quantized item representations for transferable sequential Recommenders. The main novelty of our approach lies in the new item representation scheme: it first maps item text into a vector of discrete indices (called item code), and then employs these indices to lookup the code embedding table for deriving item representations. Such a scheme can be denoted\u00a0\u2026",
        "total_citations": 107
      },
      {
        "title": "Translation-based factorization machines for sequential recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:BrmTIyaxlBUC",
        "authors": [
          "Rajiv Pasricha",
          "Julian McAuley"
        ],
        "publication_date": "2018-10-17",
        "conference": "ACM Conference on Recommender Systems",
        "description": "Sequential recommendation algorithms aim to predict users' future behavior given their historical interactions. A recent line of work has achieved state-of-the-art performance on sequential recommendation tasks by adapting ideas from metric learning and knowledge-graph completion. These algorithms replace inner products with low-dimensional embeddings and distance functions, employing a simple translation dynamic to model user behavior over time. In this paper, we propose TransFM, a model that combines translation and metric-based approaches for sequential recommendation with Factorization Machines (FMs). Doing so allows us to reap the benefits of FMs (in particular, the ability to straightforwardly incorporate content-based features), while enhancing the state-of-the-art performance of translation-based models in sequential settings. Specifically, we learn an embedding and translation space for each\u00a0\u2026",
        "total_citations": 106
      },
      {
        "title": "Recommender systems datasets",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:NXb4pA-qfm4C",
        "authors": [
          "Julian McAuley"
        ],
        "publication_date": "2016-10-17",
        "total_citations": 106
      },
      {
        "title": "Large language models as zero-shot conversational recommenders",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:zdjWy_NXXwUC",
        "authors": [
          "Zhankui He",
          "Zhouhang Xie",
          "Rahul Jha",
          "Harald Steck",
          "Dawen Liang",
          "Yesu Feng",
          "Bodhisattwa Prasad Majumder",
          "Nathan Kallus",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-21",
        "pages": "720-730",
        "description": "In this paper, we present empirical studies on conversational recommendation tasks using representative large language models in a zero-shot setting with three primary contributions. (1) Data: To gain insights into model behavior in \"in-the-wild\" conversational recommendation scenarios, we construct a new dataset of recommendation-related conversations by scraping a popular discussion website. This is the largest public real-world conversational recommendation dataset to date. (2) Evaluation: On the new dataset and two existing conversational recommendation datasets, we observe that even without fine-tuning, large language models can outperform existing fine-tuned conversational recommendation models. (3) Analysis: We propose various probing tasks to investigate the mechanisms behind the remarkable performance of large language models in conversational recommendation. We analyze both the\u00a0\u2026",
        "total_citations": 105
      },
      {
        "title": "Finding progression stages in time-evolving event sequences",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:-f6ydRqryjwC",
        "authors": [
          "Jaewon Yang",
          "Julian McAuley",
          "Jure Leskovec",
          "Paea LePendu",
          "Nigam Shah"
        ],
        "publication_date": "2014-10-17",
        "conference": "World Wide Web",
        "description": "Event sequences, such as patients' medical histories or users' sequences of product reviews, trace how individuals progress over time. Identifying common patterns, or progression stages, in such event sequences is a challenging task because not every individual follows the same evolutionary pattern, stages may have very different lengths, and individuals may progress at different rates. In this paper, we develop a model-based method for discovering common progression stages in general event sequences. We develop a generative model in which each sequence belongs to a class, and sequences from a given class pass through a common set of stages, where each sequence evolves at its own rate. We then develop a scalable algorithm to infer classes of sequences, while also segmenting each sequence into a set of stages. We evaluate our method on event sequences, ranging from patients' medical histories\u00a0\u2026",
        "total_citations": 100
      },
      {
        "title": "Detecting cohesive and 2-mode communities in directed and undirected networks",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:hC7cP41nSMkC",
        "authors": [
          "Jaewon Yang",
          "Julian McAuley",
          "Jure Leskovec"
        ],
        "publication_date": "2014-10-17",
        "conference": "Web Search and Data Mining",
        "description": "Networks are a general language for representing relational information among objects. An effective way to model, reason about, and summarize networks, is to discover sets of nodes with common connectivity patterns. Such sets are commonly referred to as network communities. Research on network community detection has predominantly focused on identifying communities of densely connected nodes in undirected networks. In this paper we develop a novel overlapping community detection method that scales to networks of millions of nodes and edges and advances research along two dimensions: the connectivity structure of communities, and the use of edge directedness for community detection. First, we extend traditional definitions of network communities by building on the observation that nodes can be densely interlinked in two different ways: In cohesive communities nodes link to each other, while in 2\u00a0\u2026",
        "total_citations": 99
      },
      {
        "title": "RadBERT: adapting transformer-based language models to radiology",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:CdxZDUztZiMC",
        "authors": [
          "An Yan",
          "Julian McAuley",
          "Xing Lu",
          "Jiang Du",
          "Eric Y Chang",
          "Amilcare Gentili",
          "Chun-Nan Hsu"
        ],
        "publication_date": "2022-06-15",
        "pages": "e210258",
        "publisher": "Radiological Society of North America",
        "description": " Purpose To investigate if tailoring a transformer-based language model to                             radiology is beneficial for radiology natural language processing (NLP)                             applications. Materials and Methods This retrospective study presents a family of bidirectional encoder                             representations from transformers (BERT)\u2013based language models                             adapted for radiology, named RadBERT. Transformers were pretrained with                             either 2.16 or 4.42 million radiology reports from U.S. Department of                             Veterans Affairs health care systems nationwide on top of four different                             initializations (BERT-base, Clinical-BERT, robustly optimized BERT                             pretraining approach [RoBERTa], and BioMed-RoBERTa) to create six                             variants of RadBERT\u00a0\u2026",
        "total_citations": 98
      },
      {
        "title": "Starcoder 2 and the stack v2: The next generation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:oPLKW5k6eA4C",
        "authors": [
          "Anton Lozhkov",
          "Raymond Li",
          "Loubna Ben Allal",
          "Federico Cassano",
          "Joel Lamy-Poirier",
          "Nouamane Tazi",
          "Ao Tang",
          "Dmytro Pykhtar",
          "Jiawei Liu",
          "Yuxiang Wei",
          "Tianyang Liu",
          "Max Tian",
          "Denis Kocetkov",
          "Arthur Zucker",
          "Younes Belkada",
          "Zijian Wang",
          "Qian Liu",
          "Dmitry Abulkhanov",
          "Indraneil Paul",
          "Zhuang Li",
          "Wen-Ding Li",
          "Megan Risdal",
          "Jia Li",
          "Jian Zhu",
          "Terry Yue Zhuo",
          "Evgenii Zheltonozhskii",
          "Nii Osae Osae Dade",
          "Wenhao Yu",
          "Lucas Krau\u00df",
          "Naman Jain",
          "Yixuan Su",
          "Xuanli He",
          "Manan Dey",
          "Edoardo Abati",
          "Yekun Chai",
          "Niklas Muennighoff",
          "Xiangru Tang",
          "Muhtasham Oblokulov",
          "Christopher Akiki",
          "Marc Marone",
          "Chenghao Mou",
          "Mayank Mishra",
          "Alex Gu",
          "Binyuan Hui",
          "Tri Dao",
          "Armel Zebaze",
          "Olivier Dehaene",
          "Nicolas Patry",
          "Canwen Xu",
          "Julian McAuley",
          "Han Hu",
          "Torsten Scholak",
          "Sebastien Paquet",
          "Jennifer Robinson",
          "Carolyn Jane Anderson",
          "Nicolas Chapados",
          "Mostofa Patwary",
          "Nima Tajbakhsh",
          "Yacine Jernite",
          "Carlos Mu\u00f1oz Ferrandis",
          "Lingming Zhang",
          "Sean Hughes",
          "Thomas Wolf",
          "Arjun Guha",
          "Leandro von Werra",
          "Harm de Vries"
        ],
        "publication_date": "2024-02-29",
        "description": "The BigCode project, an open-scientific collaboration focused on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder2. In partnership with Software Heritage (SWH), we build The Stack v2 on top of the digital commons of their source code archive. Alongside the SWH repositories spanning 619 programming languages, we carefully select other high-quality data sources, such as GitHub pull requests, Kaggle notebooks, and code documentation. This results in a training set that is 4x larger than the first StarCoder dataset. We train StarCoder2 models with 3B, 7B, and 15B parameters on 3.3 to 4.3 trillion tokens and thoroughly evaluate them on a comprehensive set of Code LLM benchmarks. We find that our small model, StarCoder2-3B, outperforms other Code LLMs of similar size on most benchmarks, and also outperforms StarCoderBase-15B. Our large model, StarCoder2- 15B, significantly outperforms other models of comparable size. In addition, it matches or outperforms CodeLlama-34B, a model more than twice its size. Although DeepSeekCoder- 33B is the best-performing model at code completion for high-resource languages, we find that StarCoder2-15B outperforms it on math and code reasoning benchmarks, as well as several low-resource languages. We make the model weights available under an OpenRAIL license and ensure full transparency regarding the training data by releasing the SoftWare Heritage persistent IDentifiers (SWHIDs) of the source code data.",
        "total_citations": 97
      },
      {
        "title": "Scalable and accurate dialogue state tracking via hierarchical sequence generation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:Z5m8FVwuT1cC",
        "authors": [
          "Liliang Ren",
          "Jianmo Ni",
          "Julian McAuley"
        ],
        "publication_date": "2019-10-17",
        "conference": "Empirical Methods in Natural Language Processing",
        "description": "Existing approaches to dialogue state tracking rely on pre-defined ontologies consisting of a set of all possible slot types and values. Though such approaches exhibit promising performance on single-domain benchmarks, they suffer from computational complexity that increases proportionally to the number of pre-defined slots that need tracking. This issue becomes more severe when it comes to multi-domain dialogues which include larger numbers of slots. In this paper, we investigate how to approach DST using a generation framework without the pre-defined ontology list. Given each turn of user utterance and system response, we directly generate a sequence of belief states by applying a hierarchical encoder-decoder structure. In this way, the computational complexity of our model will be a constant regardless of the number of pre-defined slots. Experiments on both the multi-domain and the single domain dialogue state tracking dataset show that our model not only scales easily with the increasing number of pre-defined domains and slots but also reaches the state-of-the-art performance.",
        "total_citations": 95
      },
      {
        "title": "Complete the Look: Scene-based complementary product recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:yB1At4FlUx8C",
        "authors": [
          "Wang-Cheng Kang",
          "Eric Kim",
          "Jure Leskovec",
          "Charles Rosenberg",
          "Julian McAuley"
        ],
        "publication_date": "2019-10-17",
        "conference": "Computer Vision and Pattern Recognition",
        "description": "Modeling fashion compatibility is challenging due to its complexity and subjectivity. Existing work focuses on predicting compatibility between product images (eg an image containing a t-shirt and an image containing a pair of jeans). However, these approaches ignore real-world'scene'images (eg selfies); such images are hard to deal with due to their complexity, clutter, variations in lighting and pose (etc.) but on the other hand could potentially provide key context (eg the user's body type, or the season) for making more accurate recommendations. In this work, we propose a new task called'Complete the Look', which seeks to recommend visually compatible products based on scene images. We design an approach to extract training data for this task, and propose a novel way to learn the scene-product compatibility from fashion or interior design images. Our approach measures compatibility both globally and locally via CNNs and attention mechanisms. Extensive experiments show that our method achieves significant performance gains over alternative systems. Human evaluation and qualitative analysis are also conducted to further understand model behavior. We hope this work could lead to useful applications which link large corpora of real-world scenes with shoppable products.",
        "total_citations": 93
      },
      {
        "title": "Attentive sequential models of latent intent for next item recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:Ug5p-4gJ2f0C",
        "authors": [
          "Md Mehrab Tanjim",
          "Congzhe Su",
          "Ethan Benjamin",
          "Diane Hu",
          "Liangjie Hong",
          "Julian McAuley"
        ],
        "publication_date": "2020-10-17",
        "conference": "World Wide Web",
        "description": "Users exhibit different intents across e-commerce services (e.g.\u00a0discovering items, purchasing gifts, etc.) which drives them to interact with a wide variety of items in multiple ways (e.g.\u00a0click, add-to-cart, add-to-favorites, purchase). To give better recommendations, it is important to capture user intent, in addition to considering their historic interactions. However these intents are by definition latent, as we observe only a user\u2019s interactions, and not their underlying intent. To discover such latent intents, and use them effectively for recommendation, in this paper we propose an Attentive Sequential model of Latent Intent (ASLI in short). Our model first learns item similarities from users\u2019 interaction histories via a self-attention layer, then uses a Temporal Convolutional Network layer to obtain a latent representation of the user\u2019s intent from her actions on a particular category. We use this representation to guide an attentive\u00a0\u2026",
        "total_citations": 91
      },
      {
        "title": "Personalized review generation by expanding phrases and attending on aspect-aware representations",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:WbkHhVStYXYC",
        "authors": [
          "Jianmo Ni",
          "Julian McAuley"
        ],
        "publication_date": "2018-10-17",
        "conference": "Association for Computational Linguistics",
        "description": "In this paper, we focus on the problem of building assistive systems that can help users to write reviews. We cast this problem using an encoder-decoder framework that generates personalized reviews by expanding short phrases (eg review summaries, product titles) provided as input to the system. We incorporate aspect-level information via an aspect encoder that learns aspect-aware user and item representations. An attention fusion layer is applied to control generation by attending on the outputs of multiple encoders. Experimental results show that our model successfully learns representations capable of generating coherent and diverse reviews. In addition, the learned aspect-aware representations discover those aspects that users are more inclined to discuss and bias the generated text toward their personalized aspect preferences.",
        "total_citations": 84
      },
      {
        "title": "Improving latent factor models via personalized feature projection for one-class recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:iH-uZ7U-co4C",
        "authors": [
          "Tong Zhao",
          "Julian McAuley",
          "Irwin King"
        ],
        "publication_date": "2015-10-17",
        "conference": "Conference on Information and Knowledge Management",
        "description": "Latent Factor models, which transform both users and items into the same latent feature space, are one of the most successful and ubiquitous models in recommender systems. Most existing models in this paradigm define both users' and items' latent factors to be of the same size and use an inner product to represent a user's \"compatibility\" with an item. Intuitively, users' factors encode \"preferences\" while item factors encode \"properties\", so that the inner product encodes how well an item matches a user's preferences. However, a user's opinion of an item may be more complex, for example each dimension of each user's opinion may depend on a combination of multiple item factors simultaneously. Thus it may be better to view each dimension of a user's preference as a personalized projection of an item's properties so that the preference model can capture complex relationships between items' properties and\u00a0\u2026",
        "total_citations": 84
      },
      {
        "title": "Like hiking? You probably enjoy nature: Persona-grounded dialog with commonsense expansions",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:XvxMoLDsR5gC",
        "authors": [
          "Bodhisattwa Prasad Majumder",
          "Harsh Jhamtani",
          "Taylor Berg-Kirkpatrick",
          "Julian McAuley"
        ],
        "publication_date": "2020-10-17",
        "conference": "Empirical Methods in Natural Language Processing",
        "description": "Existing persona-grounded dialog models often fail to capture simple implications of given persona descriptions, something which humans are able to do seamlessly. For example, state-of-the-art models cannot infer that interest in hiking might imply love for nature or longing for a break. In this paper, we propose to expand available persona sentences using existing commonsense knowledge bases and paraphrasing resources to imbue dialog models with access to an expanded and richer set of persona descriptions. Additionally, we introduce fine-grained grounding on personas by encouraging the model to make a discrete choice among persona sentences while synthesizing a dialog response. Since such a choice is not observed in the data, we model it using a discrete latent random variable and use variational learning to sample from hundreds of persona expansions. Our model outperforms competitive\u00a0\u2026",
        "total_citations": 83
      },
      {
        "title": "Sparse hierarchical embeddings for visually-aware one-class collaborative filtering",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:J_g5lzvAfSwC",
        "authors": [
          "Ruining He",
          "Chunbin Lin",
          "Jianguo Wang",
          "Julian McAuley"
        ],
        "publication_date": "2016-10-17",
        "conference": "IJCAI",
        "total_citations": 79
      },
      {
        "title": "BERT Learns to Teach: Knowledge distillation with meta learning",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:j7_hQOaDUrUC",
        "authors": [
          "Wangchunshu Zhou",
          "Canwen Xu",
          "Julian McAuley"
        ],
        "publication_date": "2022-10-17",
        "conference": "Annual Meeting of the Association for Computational Linguistics",
        "description": "We present Knowledge Distillation with Meta Learning (MetaDistil), a simple yet effective alternative to traditional knowledge distillation (KD) methods where the teacher model is fixed during training. We show the teacher network can learn to better transfer knowledge to the student network (i.e., learning to teach) with the feedback from the performance of the distilled student network in a meta learning framework. Moreover, we introduce a pilot update mechanism to improve the alignment between the inner-learner and meta-learner in meta learning algorithms that focus on an improved inner-learner. Experiments on various benchmarks show that MetaDistil can yield significant improvements compared with traditional KD algorithms and is less sensitive to the choice of different student capacity and hyperparameters, facilitating the use of KD on different tasks and models.",
        "total_citations": 77
      },
      {
        "title": "Deep reinforcement learning in recommender systems: A survey and new perspectives",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:Hck25ST_3aIC",
        "authors": [
          "Xiaocong Chen",
          "Lina Yao",
          "Julian McAuley",
          "Guanglin Zhou",
          "Xianzhi Wang"
        ],
        "publication_date": "2023-03-15",
        "pages": "110335",
        "publisher": "Elsevier",
        "description": "In light of the emergence of deep reinforcement learning (DRL) in recommender systems research and several fruitful results in recent years, this survey aims to provide a timely and comprehensive overview of recent trends of deep reinforcement learning in recommender systems. We start by motivating the application of DRL in recommender systems, followed by a taxonomy of current DRL-based recommender systems and a summary of existing methods. We discuss emerging topics, open issues, and provide our perspective on advancing the domain. The survey serves as introductory material for readers from academia and industry to the topic and identifies notable opportunities for further research.",
        "total_citations": 76
      },
      {
        "title": "A review of modern fashion recommender systems",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:jL-93Qbq4QoC",
        "authors": [
          "Yashar Deldjoo",
          "Fatemeh Nazary",
          "Arnau Ramisa",
          "Julian McAuley",
          "Giovanni Pellegrini",
          "Alejandro Bellogin",
          "Tommaso Di Noia"
        ],
        "publication_date": "2023-10-17",
        "description": "The textile and apparel industries have grown tremendously over the past few years. Customers no longer have to visit many stores, stand in long queues, or try on garments in dressing rooms, as millions of products are now available in online catalogs. However, given the plethora of options available, an effective recommendation system is necessary to properly sort, order, and communicate relevant product material or information to users. Effective fashion recommender systems (RSs) can have a noticeable impact on billions of customers\u2019 shopping experiences and increase sales and revenues on the provider side. The goal of this survey is to provide a review of RSs that operate in the specific vertical domain of garment and fashion products. We have identified the most pressing challenges in fashion RS research and created a taxonomy that categorizes the literature according to the objective they are trying to\u00a0\u2026",
        "total_citations": 75
      },
      {
        "title": "WaveGuard: Understanding and mitigating audio adversarial examples",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:bKqednn6t2AC",
        "authors": [
          "Shehzeen Hussain",
          "Paarth Neekhara",
          "Shlomo Dubnov",
          "Julian McAuley",
          "Farinaz Koushanfar"
        ],
        "publication_date": "2021-10-17",
        "conference": "USENIX Security Symposium",
        "description": "There has been a recent surge in adversarial attacks on deep learning based automatic speech recognition (ASR) systems. These attacks pose new challenges to deep learning security and have raised significant concerns in deploying ASR systems in safety-critical applications. In this work, we introduce WaveGuard: a framework for detecting adversarial inputs that are crafted to attack ASR systems. Our framework incorporates audio transformation functions and analyses the ASR transcriptions of the original and transformed audio to detect adversarial inputs. We demonstrate that our defense framework is able to reliably detect adversarial examples constructed by four recent audio adversarial attacks, with a variety of audio transformation functions. With careful regard for best practices in defense evaluations, we analyze our proposed defense and its strength to withstand adaptive and robust attacks in the audio domain. We empirically demonstrate that audio transformations that recover audio from perceptually informed representations can lead to a strong defense that is robust against an adaptive adversary even in a complete white-box setting. Furthermore, WaveGuard can be used out-of-the box and integrated directly with any ASR model to efficiently detect audio adversarial examples, without the need for model retraining.",
        "total_citations": 75
      },
      {
        "title": "MusPy: A toolkit for symbolic music generation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:FAceZFleit8C",
        "authors": [
          "Hao-Wen Dong",
          "Ke Chen",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick"
        ],
        "publication_date": "2020-10-17",
        "conference": "International Society for Music Information Retrieval Conference",
        "description": "In this paper, we present MusPy, an open source Python library for symbolic music generation. MusPy provides easy-to-use tools for essential components in a music generation system, including dataset management, data I/O, data preprocessing and model evaluation. In order to showcase its potential, we present statistical analysis of the eleven datasets currently supported by MusPy. Moreover, we conduct a cross-dataset generalizability experiment by training an autoregressive model on each dataset and measuring held-out likelihood on the others---a process which is made easier by MusPy's dataset management system. The results provide a map of domain overlap between various commonly used datasets and show that some datasets contain more representative cross-genre samples than others. Along with the dataset analysis, these results might serve as a guide for choosing datasets in future research. Source code and documentation are available at https://github.com/salu133445/muspy .",
        "total_citations": 75
      },
      {
        "title": "Black-box attacks on sequential recommenders via data-free model extraction",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:5icHVeHT4IsC",
        "authors": [
          "Zhenrui Yue",
          "Zhankui He",
          "Huimin Zeng",
          "Julian McAuley"
        ],
        "publication_date": "2021-09-01",
        "conference": "ACM Conference on Recommender Systems",
        "description": "We investigate whether model extraction can be used to \u2018steal\u2019 the weights of sequential recommender systems, and the potential threats posed to victims of such attacks. This type of risk has attracted attention in image and text classification, but to our knowledge not in recommender systems. We argue that sequential recommender systems are subject to unique vulnerabilities due to the specific autoregressive regimes used to train them. Unlike many existing recommender attackers, which assume the dataset used to train the victim model is exposed to attackers, we consider a data-free setting, where training data are not accessible. Under this setting, we propose an API-based model extraction method via limited-budget synthetic data generation and knowledge distillation. We investigate state-of-the-art models for sequential recommendation and show their vulnerability under model extraction and downstream\u00a0\u2026",
        "total_citations": 72
      },
      {
        "title": "Chils: Zero-shot image classification with hierarchical label sets",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:k_7cPK9k7w8C",
        "authors": [
          "Zachary Novack",
          "Saurabh Garg",
          "Julian McAuley",
          "Zachary C Lipton"
        ],
        "publication_date": "2023-02-06",
        "conference": "ICML",
        "description": "Open vocabulary models (eg CLIP) have shown strong performance on zero-shot classification through their ability generate embeddings for each class based on their (natural language) names. Prior work has focused on improving the accuracy of these models through prompt engineering or by incorporating a small amount of labeled downstream data (via finetuning). However, there has been little focus on improving the richness of the class names themselves, which can pose issues when class labels are coarsely-defined and are uninformative. We propose Classification with Hierarchical Label Sets (or CHiLS), an alternative strategy for zero-shot classification specifically designed for datasets with implicit semantic hierarchies. CHiLS proceeds in three steps:(i) for each class, produce a set of subclasses, using either existing label hierarchies or by querying GPT-3;(ii) perform the standard zero-shot CLIP procedure as though these subclasses were the labels of interest;(iii) map the predicted subclass back to its parent to produce the final prediction. Across numerous datasets with underlying hierarchical structure, CHiLS leads to improved accuracy in situations both with and without ground-truth hierarchical information. CHiLS is simple to implement within existing zero-shot pipelines and requires no additional training cost. Code is available at: https://github. com/acmi-lab/CHILS.",
        "total_citations": 71
      },
      {
        "title": "Weakly supervised contrastive learning for chest x-ray report generation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:artPoR2Yc-kC",
        "authors": [
          "An Yan",
          "Zexue He",
          "Xing Lu",
          "Jiang Du",
          "Eric Chang",
          "Amilcare Gentili",
          "Julian McAuley",
          "Chun-Nan Hsu"
        ],
        "publication_date": "2021-10-17",
        "conference": "Findings of EMNLP",
        "description": "Radiology report generation aims at generating descriptive text from radiology images automatically, which may present an opportunity to improve radiology reporting and interpretation. A typical setting consists of training encoder-decoder models on image-report pairs with a cross entropy loss, which struggles to generate informative sentences for clinical diagnoses since normal findings dominate the datasets. To tackle this challenge and encourage more clinically-accurate text outputs, we propose a novel weakly supervised contrastive loss for medical report generation. Experimental results demonstrate that our method benefits from contrasting target reports with incorrect but semantically-close ones. It outperforms previous work on both clinical correctness and text generation metrics for two public benchmarks.",
        "total_citations": 71
      },
      {
        "title": "Dance Dance Convolution",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:zA6iFVUQeVQC",
        "authors": [
          "Chris Donahue",
          "Zachary C Lipton",
          "Julian McAuley"
        ],
        "publication_date": "2017-10-17",
        "conference": "International Conference on Machine Learning",
        "description": "Dance Dance Revolution (DDR) is a popular rhythm-based video game. Players perform steps on a dance platform in synchronization with music as directed by on-screen step charts. While many step charts are available in standardized packs, players may grow tired of existing charts, or wish to dance to a song for which no chart exists. We introduce the task of learning to choreograph. Given a raw audio track, the goal is to produce a new step chart. This task decomposes naturally into two subtasks: deciding when to place steps and deciding which steps to select. For the step placement task, we combine recurrent and convolutional neural networks to ingest spectrograms of low-level audio features to predict steps, conditioned on chart difficulty. For step selection, we present a conditional LSTM generative model that substantially outperforms n-gram and fixed-window approaches.",
        "total_citations": 71
      },
      {
        "title": "SPMC: Socially-aware personalized markov chains for sparse sequential recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:fPk4N6BV_jEC",
        "authors": [
          "Chenwei Cai",
          "Ruining He",
          "Julian McAuley"
        ],
        "publication_date": "2017-10-17",
        "conference": "International Joint Conference on Artificial Intelligence",
        "description": "Dealing with sparse, long-tailed datasets, and cold-start problems is always a challenge for recommender systems. These issues can partly be dealt with by making predictions not in isolation, but by leveraging information from related events; such information could include signals from social relationships or from the sequence of recent activities. Both types of additional information can be used to improve the performance of state-of-the-art matrix factorization-based techniques. In this paper, we propose new methods to combine both social and sequential information simultaneously, in order to further improve recommendation performance. We show these techniques to be particularly effective when dealing with sparsity and cold-start issues in several large, real-world datasets.",
        "total_citations": 70
      },
      {
        "title": "Data distillation: A survey",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:rTD5ala9j4wC",
        "authors": [
          "Noveen Sachdeva",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-17",
        "description": "The popularity of deep learning has led to the curation of a vast number of massive and multifarious datasets. Despite having close-to-human performance on individual tasks, training parameter-hungry models on large datasets poses multi-faceted problems such as (a) high model-training time; (b) slow research iteration; and (c) poor eco-sustainability. As an alternative, data distillation approaches aim to synthesize terse data summaries, which can serve as effective drop-in replacements of the original dataset for scenarios like model training, inference, architecture search, etc. In this survey, we present a formal framework for data distillation, along with providing a detailed taxonomy of existing approaches. Additionally, we cover data distillation approaches for different data modalities, namely images, graphs, and user-item interactions (recommender systems), while also identifying current challenges and future research directions.",
        "total_citations": 69
      },
      {
        "title": "Addressing marketing bias in product recommendations",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:b1wdh0AR-JQC",
        "authors": [
          "Mengting Wan",
          "Jianmo Ni",
          "Rishabh Misra",
          "Julian McAuley"
        ],
        "publication_date": "2020-10-17",
        "conference": "Web Search and Data Mining",
        "description": "Modern collaborative filtering algorithms seek to provide personalized product recommendations by uncovering patterns in consumer-product interactions. However, these interactions can be biased by how the product is marketed, for example due to the selection of a particular human model in a product image. These correlations may result in the underrepresentation of particular niche markets in the interaction data; for example, a female user who would potentially like motorcycle products may be less likely to interact with them if they are promoted using stereotypically 'male' images. In this paper, we first investigate this correlation between users' interaction feedback and products' marketing images on two real-world e-commerce datasets. We further examine the response of several standard collaborative filtering algorithms to the distribution of consumer-product market segments in the input interaction data\u00a0\u2026",
        "total_citations": 68
      },
      {
        "title": "Recommendation on live-streaming platforms: Dynamic availability and repeat consumption",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:nVrZBo8bIpAC",
        "authors": [
          "J\u00e9r\u00e9mie Rappaz",
          "Julian McAuley",
          "Karl Aberer"
        ],
        "publication_date": "2021-10-17",
        "conference": "ACM Conference on Recommender Systems",
        "description": " Live-streaming platforms broadcast user-generated video in real-time. Recommendation on these platforms shares similarities with traditional settings, such as a large volume of heterogeneous content and highly skewed interaction distributions. However, several challenges must be overcome to adapt recommendation algorithms to live-streaming platforms: first, content availability is dynamic which restricts users to choose from only a subset of items at any given time; during training and inference we must carefully handle this factor in order to properly account for such signals, where \u2018non-interactions\u2019 reflect availability as much as implicit preference. Streamers are also fundamentally different from \u2018items\u2019 in traditional settings: repeat consumption of specific channels plays a significant role, though the content itself is fundamentally ephemeral.  In this work, we study recommendation in this setting of a dynamically\u00a0\u2026",
        "total_citations": 66
      },
      {
        "title": "Candidate generation with binary codes for large-scale Top-N recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:p__nRnzSRKYC",
        "authors": [
          "Wang-Cheng Kang",
          "Julian McAuley"
        ],
        "publication_date": "2019-10-17",
        "conference": "Conference on Information and Knowledge Management",
        "description": "Generating the Top-N recommendations from a large corpus is computationally expensive to perform at scale. Candidate generation and re-ranking based approaches are often adopted in industrial settings to alleviate efficiency problems. However it remains to be fully studied how well such schemes approximate complete rankings (or how many candidates are required to achieve a good approximation), or to develop systematic approaches to generate high-quality candidates efficiently. In this paper, we seek to investigate these questions via proposing a candidate generation and re-ranking based framework (CIGAR), which first learns a preference-preserving binary embedding for building a hash table to retrieve candidates, and then learns to re-rank the candidates using real-valued ranking models with a candidate-oriented objective. We perform a comprehensive study on several large-scale real-world\u00a0\u2026",
        "total_citations": 66
      },
      {
        "title": "Decomposing fit semantics for product size recommendation in metric spaces",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:eflP2zaiRacC",
        "authors": [
          "Rishabh Misra",
          "Mengting Wan",
          "Julian McAuley"
        ],
        "publication_date": "2018-10-17",
        "conference": "ACM Conference on Recommender Systems",
        "description": "Product size recommendation and fit prediction are critical in order to improve customers' shopping experiences and to reduce product return rates. Modeling customers' fit feedback is challenging due to its subtle semantics, arising from the subjective evaluation of products, and imbalanced label distribution. In this paper, we propose a new predictive framework to tackle the product fit problem, which captures the semantics behind customers' fit feedback, and employs a metric learning technique to resolve label imbalance issues. We also contribute two public datasets collected from online clothing retailers.",
        "total_citations": 64
      },
      {
        "title": "Pairwise matching through max-weight bipartite belief propagation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:RYcK_YlVTxYC",
        "authors": [
          "Zhen Zhang",
          "Qinfeng Shi",
          "Julian McAuley",
          "Wei Wei",
          "Yanning Zhang",
          "Anton Van Den Hengel"
        ],
        "publication_date": "2016-10-17",
        "conference": "Computer Vision and Pattern Recognition, IEEE Conference on",
        "description": "Feature matching is a key problem in computer vision and pattern recognition. One way to encode the essential interdependence between potential feature matches is to cast the problem as inference in a graphical model, though recently alternatives such as spectral methods, or approaches based on the convex-concave procedure have achieved the state-of-the-art. Here we revisit the use of graphical models for feature matching, and propose a belief propagation scheme which exhibits the following advantages:(1) we explicitly enforce one-to-one matching constraints;(2) we offer a tighter relaxation of the original cost function than previous graphical-model-based approaches; and (3) our sub-problems decompose into max-weight bipartite matching, which can be solved efficiently, leading to orders-of-magnitude reductions in execution time. Experimental results show that the proposed algorithm produces results superior to those of the current state-of-the-art.",
        "total_citations": 64
      },
      {
        "title": "Gpt-4v in wonderland: Large multimodal models for zero-shot smartphone gui navigation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:D_tqNUsBuKoC",
        "authors": [
          "An Yan",
          "Zhengyuan Yang",
          "Wanrong Zhu",
          "Kevin Lin",
          "Linjie Li",
          "Jianfeng Wang",
          "Jianwei Yang",
          "Yiwu Zhong",
          "Julian McAuley",
          "Jianfeng Gao",
          "Zicheng Liu",
          "Lijuan Wang"
        ],
        "publication_date": "2023-11-13",
        "description": "We present MM-Navigator, a GPT-4V-based agent for the smartphone graphical user interface (GUI) navigation task. MM-Navigator can interact with a smartphone screen as human users, and determine subsequent actions to fulfill given instructions. Our findings demonstrate that large multimodal models (LMMs), specifically GPT-4V, excel in zero-shot GUI navigation through its advanced screen interpretation, action reasoning, and precise action localization capabilities. We first benchmark MM-Navigator on our collected iOS screen dataset. According to human assessments, the system exhibited a 91\\% accuracy rate in generating reasonable action descriptions and a 75\\% accuracy rate in executing the correct actions for single-step instructions on iOS. Additionally, we evaluate the model on a subset of an Android screen navigation dataset, where the model outperforms previous GUI navigators in a zero-shot fashion. Our benchmark and detailed analyses aim to lay a robust groundwork for future research into the GUI navigation task. The project page is at https://github.com/zzxslp/MM-Navigator.",
        "total_citations": 62
      },
      {
        "title": "How useful are reviews for recommendation? A critical review and potential improvements",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:hCrLmN-GePgC",
        "authors": [
          "Noveen Sachdeva",
          "Julian McAuley"
        ],
        "publication_date": "2020-10-17",
        "conference": "SIGIR",
        "description": "We investigate a growing body of work that seeks to improve recommender systems through the use of review text. Generally, these papers argue that since reviews 'explain' users' opinions, they ought to be useful to infer the underlying dimensions that predict ratings or purchases. Schemes to incorporate reviews range from simple regularizers to neural network approaches. Our initial findings reveal several discrepancies in reported results, partly due to (e.g.) copying results across papers despite changes in experimental settings or data pre-processing. First, we attempt a comprehensive analysis to resolve these ambiguities. Further investigation calls for discussion on a much larger problem about the \"importance\" of user reviews for recommendation. Through a wide range of experiments, we observe several cases where state-of-the-art methods fail to outperform existing baselines, especially as we deviate from\u00a0\u2026",
        "total_citations": 62
      },
      {
        "title": "RepoBench: Benchmarking repository-level code auto-completion systems",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:Xz60mAmATU4C",
        "authors": [
          "Tianyang Liu",
          "Canwen Xu",
          "Julian McAuley"
        ],
        "publication_date": "2024-10-17",
        "conference": "ICLR",
        "description": "Large Language Models (LLMs) have greatly advanced code auto-completion systems, with a potential for substantial productivity enhancements for developers. However, current benchmarks mainly focus on single-file tasks, leaving an assessment gap for more complex, real-world, multi-file programming scenarios. To fill this gap, we introduce RepoBench, a new benchmark specifically designed for evaluating repository-level code auto-completion systems. RepoBench supports both Python and Java and consists of three interconnected evaluation tasks: RepoBench-R (Retrieval), RepoBench-C (Code Completion), and RepoBench-P (Pipeline). Each task respectively measures the system's ability to retrieve the most relevant code snippets from other files as cross-file context, predict the next line of code with cross-file and in-file context, and handle complex tasks that require a combination of both retrieval and next-line prediction. RepoBench aims to facilitate a more complete comparison of performance and encouraging continuous improvement in auto-completion systems. RepoBench is publicly available at https://github.com/Leolty/repobench.",
        "total_citations": 61
      },
      {
        "title": "A survey on model compression and acceleration for pretrained language models",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:hSRAE-fF4OAC",
        "authors": [
          "Canwen Xu",
          "Julian McAuley"
        ],
        "publication_date": "2023-06-26",
        "conference": "AAAI Conference on Artificial Intelligence",
        "pages": "10566-10575",
        "description": "Despite achieving state-of-the-art performance on many NLP tasks, the high energy cost and long inference delay prevent Transformer-based pretrained language models (PLMs) from seeing broader adoption including for edge and mobile computing. Efficient NLP research aims to comprehensively consider computation, time and carbon emission for the entire life-cycle of NLP, including data preparation, model training and inference. In this survey, we focus on the inference stage and review the current state of model compression and acceleration for pretrained language models, including benchmarks, metrics and methodology.",
        "total_citations": 61
      },
      {
        "title": "Learning high-order MRF priors of color images",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:u-x6o8ySG0sC",
        "authors": [
          "Julian J McAuley",
          "Tib\u00e9rio S Caetano",
          "Alex J Smola",
          "Matthias O Franz"
        ],
        "publication_date": "2006-06-25",
        "conference": "International Conference on Machine Learning",
        "pages": "617-624",
        "publisher": "ACM",
        "description": "In this paper, we use large neighborhood Markov random fields to learn rich prior models of color images. Our approach extends the monochromatic Fields of Experts model (Roth & Black, 2005a) to color images. In the Fields of Experts model, the curse of dimensionality due to very large clique sizes is circumvented by parameterizing the potential functions according to a product of experts. We introduce simplifications to the original approach by Roth and Black which allow us to cope with the increased clique size (typically 3x3x3 or 5x5x3 pixels) of color images. Experimental results are presented for image denoising which evidence improvements over state-of-the-art monochromatic image priors.",
        "total_citations": 61
      },
      {
        "title": "A survey of deep reinforcement learning in recommender systems: A systematic review and future directions",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:gKiMpY-AVTkC",
        "authors": [
          "Xiaocong Chen",
          "Lina Yao",
          "Julian McAuley",
          "Guangling Zhou",
          "Xianzhi Wang"
        ],
        "publication_date": "2023-10-17",
        "description": "In light of the emergence of deep reinforcement learning (DRL) in recommender systems research and several fruitful results in recent years, this survey aims to provide a timely and comprehensive overview of the recent trends of deep reinforcement learning in recommender systems. We start with the motivation of applying DRL in recommender systems. Then, we provide a taxonomy of current DRL-based recommender systems and a summary of existing methods. We discuss emerging topics and open issues, and provide our perspective on advancing the domain. This survey serves as introductory material for readers from academia and industry into the topic and identifies notable opportunities for further research.",
        "total_citations": 59
      },
      {
        "title": "Locker: Locally constrained self-attentive sequential recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:BJbdYPG6LGMC",
        "authors": [
          "Zhankui He",
          "Handong Zhao",
          "Zhe Lin",
          "Zhaowen Wang",
          "Ajinkya Kale",
          "Julian McAuley"
        ],
        "publication_date": "2021-10-26",
        "pages": "3088-3092",
        "description": "Recently, self-attentive models have shown promise in sequential recommendation, given their potential to capture user long-term preferences and short-term dynamics simultaneously. Despite their success, we argue that self-attention modules, as a non-local operator, often fail to capture short-term user dynamics accurately due to a lack of inductive local bias. To examine our hypothesis, we conduct an analytical experiment on controlled 'short-term' scenarios. We observe a significant performance gap between self-attentive recommenders with and without local constraints, which implies that short-term user dynamics are not sufficiently learned by existing self-attentive recommenders. Motivated by this observation, we propose a simple framework, (Locker) for self-attentive recommenders in a plug-and-play fashion. By combining the proposed local encoders with existing global attention heads, Locker enhances\u00a0\u2026",
        "total_citations": 57
      },
      {
        "title": "Top-N recommendation with missing implicit feedback",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:r0BpntZqJG4C",
        "authors": [
          "Daryl Lim",
          "Julian McAuley",
          "Gert Lanckriet"
        ],
        "publication_date": "2015-10-17",
        "conference": "ACM Conference on Recommender Systems",
        "description": "In implicit feedback datasets, non-interaction of a user with an item does not necessarily indicate that an item is irrelevant for the user. Thus, evaluation measures computed on the observed feedback may not accurately reflect performance on the complete data. In this paper, we discuss a missing data model for implicit feedback and propose a novel evaluation measure oriented towards Top-N recommendation. Our evaluation measure admits unbiased estimation under our missing data model, unlike the popular Normalized Discounted Cumulative Gain (NDCG) measure. We also derive an efficient algorithm to optimize the measure on the training data. We run several experiments which demonstrate the utility of our proposed measure.",
        "total_citations": 57
      },
      {
        "title": "Multitrack music transformer",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:1Ye0OR6EYb4C",
        "authors": [
          "Hao-Wen Dong",
          "Ke Chen",
          "Shlomo Dubnov",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick"
        ],
        "publication_date": "2023-10-17",
        "conference": "ICASSP",
        "description": "Existing approaches for generating multitrack music with transformer models have been limited in terms of the number of instruments, the length of the music segments and slow inference. This is partly due to the memory requirements of the lengthy input sequences necessitated by existing representations. In this work, we propose a new multitrack music representation that allows a diverse set of instruments while keeping a short sequence length. Our proposed Multitrack Music Transformer (MMT) achieves comparable performance with state-of-the-art systems, landing in between two recently proposed models in a subjective listening test, while achieving substantial speedups and memory reductions over both, making the method attractive for real time improvisation or near real time creative applications. Further, we propose a new measure for analyzing musical self-attention and show that the trained model\u00a0\u2026",
        "total_citations": 56
      },
      {
        "title": "Speech recognition and multi-speaker diarization of long conversations",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:mlAyqtXpCwEC",
        "authors": [
          "Huanru Henry Mao",
          "Shuyang Li",
          "Julian McAuley",
          "Garrison Cottrell"
        ],
        "publication_date": "2020-10-17",
        "conference": "Interspeech",
        "description": "Speech recognition (ASR) and speaker diarization (SD) models have traditionally been trained separately to produce rich conversation transcripts with speaker labels. Recent advances have shown that joint ASR and SD models can learn to leverage audio-lexical inter-dependencies to improve word diarization performance. We introduce a new benchmark of hour-long podcasts collected from the weekly This American Life radio program to better compare these approaches when applied to extended multi-speaker conversations. We find that training separate ASR and SD models perform better when utterance boundaries are known but otherwise joint models can perform better. To handle long conversations with unknown utterance boundaries, we introduce a striding attention decoding algorithm and data augmentation techniques which, combined with model pre-training, improves ASR and SD.",
        "total_citations": 55
      },
      {
        "title": "Translation-based recommendation: A scalable method for modeling sequential behavior",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:738O_yMBCRsC",
        "authors": [
          "Ruining He",
          "Wang-Cheng Kang",
          "Julian McAuley"
        ],
        "publication_date": "2018-10-17",
        "conference": "International Joint Conference on Artificial Intelligence",
        "description": "Modeling the complex interactions between users and items is at the core of designing successful recommender systems. One key task consists of predicting users\u2019 personalized sequential behavior, where the challenge mainly lies in modeling \u2018third-order\u2019interactions between a user, her previously visited item (s), and the next item to consume. In this paper, we propose a unified method, TransRec, to model such interactions for largescale sequential prediction. Methodologically, we embed items into a \u2018transition space\u2019where users are modeled as translation vectors operating on item sequences. Empirically, this approach outperforms the state-of-the-art on a wide spectrum of real-world datasets.",
        "total_citations": 55
      },
      {
        "title": "Scrabble: Transferrable semi-automated semantic metadata normalization using an intermediate representation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:_B80troHkn4C",
        "authors": [
          "Jason Koh",
          "Bharathan Balaji",
          "Dhiman Sengupta",
          "Julian McAuley",
          "Rajesh Gupta",
          "Yuvraj Agarwal"
        ],
        "publication_date": "2018-10-17",
        "conference": "BuildSys",
        "description": "Interoperability in the Internet of Things relies on a common data model that captures the necessary semantics for vendor independent application development and data exchange. However, traditional systems such as those in building management are vertically integrated and do not use a standard schema. A typical building can consist of thousands of data points. Third party vendors who seek to deploy applications like fault diagnosis need to manually map the building information into a common schema. This mapping process requires deep domain expertise and a detailed understanding of intricacies of each building's system. Our framework - Scrabble - reduces the mapping effort significantly by using a multi-stage active learning mechanism that exploits the structure present in a standard schema and learns from buildings that have already been mapped to the schema. Scrabble uses conditional random\u00a0\u2026",
        "total_citations": 52
      },
      {
        "title": "Improving neural story generation by targeted common sense grounding",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:vDijr-p_gm4C",
        "authors": [
          "Huanru Henry Mao",
          "Bodhisattwa Prasad Majumder",
          "Julian McAuley",
          "Garrison W Cottrell"
        ],
        "publication_date": "2019-10-17",
        "conference": "Empirical Methods in Natural Language Processing",
        "description": "Stories generated with neural language models have shown promise in grammatical and stylistic consistency. However, the generated stories are still lacking in common sense reasoning, e.g., they often contain sentences deprived of world knowledge. We propose a simple multi-task learning scheme to achieve quantitatively better common sense reasoning in language models by leveraging auxiliary training signals from datasets designed to provide common sense grounding. When combined with our two-stage fine-tuning pipeline, our method achieves improved common sense reasoning and state-of-the-art perplexity on the Writing Prompts (Fan et al., 2018) story generation dataset.",
        "total_citations": 51
      },
      {
        "title": "Learning to attend on essential terms: An enhanced retriever-reader model for scientific question answering",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:nrtMV_XWKgEC",
        "authors": [
          "Jianmo Ni",
          "Chenguang Zhu",
          "Weizhu Chen",
          "Julian McAuley"
        ],
        "publication_date": "2019-10-17",
        "conference": "NAACL",
        "description": "Scientific Question Answering (SQA) is a challenging open-domain task which requires the capability to understand questions and choices, collect useful information, and reason over evidence. Previous work typically formulates this task as a reading comprehension or entailment problem given evidence retrieved from search engines. However, existing techniques struggle to retrieve indirectly related evidence when no directly related evidence is provided, especially for complex questions where it is hard to parse precisely what the question asks. In this paper we propose a retriever-reader model that learns to attend on essential terms during the question answering process. We build 1) an essential-term-aware \u2018retriever\u2019which first identifies the most important words in a question, then reformulates the queries and searches for related evidence 2) an enhanced \u2018reader\u2019to distinguish between essential terms and distracting words to predict the answer. We experimentally evaluate our model on the ARC dataset where it outperforms the existing state-of-the-art model by 7.4%.",
        "total_citations": 51
      },
      {
        "title": "UCTopic: Unsupervised contrastive learning for phrase representations and topic mining",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:wKETBy42zhYC",
        "authors": [
          "Jiacheng Li",
          "Jingbo Shang",
          "Julian McAuley"
        ],
        "publication_date": "2022-02-27",
        "conference": "Annual Meeting of the Association for Computational Linguistics",
        "description": "High-quality phrase representations are essential to finding topics and related terms in documents (a.k.a. topic mining). Existing phrase representation learning methods either simply combine unigram representations in a context-free manner or rely on extensive annotations to learn context-aware knowledge. In this paper, we propose UCTopic, a novel unsupervised contrastive learning framework for context-aware phrase representations and topic mining. UCTopic is pretrained in a large scale to distinguish if the contexts of two phrase mentions have the same semantics. The key to pretraining is positive pair construction from our phrase-oriented assumptions. However, we find traditional in-batch negatives cause performance decay when finetuning on a dataset with small topic numbers. Hence, we propose cluster-assisted contrastive learning(CCL) which largely reduces noisy negatives by selecting negatives from clusters and further improves phrase representations for topics accordingly. UCTopic outperforms the state-of-the-art phrase representation model by 38.2% NMI in average on four entity cluster-ing tasks. Comprehensive evaluation on topic mining shows that UCTopic can extract coherent and diverse topical phrases.",
        "total_citations": 49
      },
      {
        "title": "Knowledge-grounded self-rationalization via extractive and natural language explanations",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:7BrZ7Jt4UNcC",
        "authors": [
          "Bodhisattwa Prasad Majumder",
          "Oana-Maria Camburu",
          "Thomas Lukasiewicz",
          "Julian McAuley"
        ],
        "publication_date": "2022-10-17",
        "conference": "ICML",
        "description": "Models that generate extractive rationales (i.e., subsets of features) or natural language explanations (NLEs) for their predictions are important for explainable AI. While an extractive rationale provides a quick view of the features most responsible for a prediction, an NLE allows for a comprehensive description of the decision-making process behind a prediction. However, current models that generate the best extractive rationales or NLEs often fall behind the state-of-the-art (SOTA) in terms of task performance. In this work, we bridge this gap by introducing RExC, a self-rationalizing framework that grounds its predictions and two complementary types of explanations (NLEs and extractive rationales) in background knowledge. Our framework improves over previous methods by: (i) reaching SOTA task performance while also providing explanations, (ii) providing two types of explanations, while existing models usually provide only one type, and (iii) beating by a large margin the previous SOTA in terms of quality of both types of explanations. Furthermore, a perturbation analysis in RExC shows a high degree of association between explanations and predictions, a necessary property of faithful explanations.",
        "total_citations": 49
      },
      {
        "title": "Generating user-customized items using a visually-aware image generation network",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:vbGhcppDl1QC",
        "publication_date": "2021-04-06",
        "description": "The present disclosure relates to a personalized fashion generation system that synthesizes user-customized images using deep learning techniques based on visually-aware user preferences. In particular, the personalized fashion genera tion system employs an image generative adversarial neural network and a personalized preference network to synthe size new fashion items that are individually customized for a user. Additionally, the personalized fashion generation system can modify existing fashion items to tailor the fashion items to a user's tastes and preferences.",
        "total_citations": 46
      },
      {
        "title": "Recommendation through mixtures of heterogeneous item relationships",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:V3AGJWp-ZtQC",
        "authors": [
          "Wang-Cheng Kang",
          "Mengting Wan",
          "Julian McAuley"
        ],
        "publication_date": "2018-10-17",
        "conference": "Conference on Information and Knowledge Management",
        "description": "Recommender Systems have proliferated as general-purpose approaches to model a wide variety of consumer interaction data. Specific instances make use of signals ranging from user feedback, item relationships, geographic locality, social influence (etc.). Typically, research proceeds by showing that making use of a specific signal (within a carefully designed model) allows for higher-fidelity recommendations on a particular dataset. Of course, the real situation is more nuanced, in which a combination of many signals may be at play, or favored in different proportion by individual users. Here we seek to develop a framework that is capable of combining such heterogeneous item relationships by simultaneously modeling (a) what modality of recommendation is a user likely to be susceptible to at a particular point in time; and (b) what is the best recommendation from each modality. Our method borrows ideas from\u00a0\u2026",
        "total_citations": 46
      },
      {
        "title": "Learning concise and descriptive attributes for visual recognition",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:X9ykpCP0fEIC",
        "authors": [
          "An Yan",
          "Yu Wang",
          "Yiwu Zhong",
          "Chengyu Dong",
          "Zexue He",
          "Yujie Lu",
          "William Yang Wang",
          "Jingbo Shang",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-17",
        "conference": "International Conference on Computer Vision",
        "pages": "3090-3100",
        "description": "Recent advances in foundation models present new opportunities for interpretable visual recognition--one can first query Large Language Models (LLMs) to obtain a set of attributes that describe each class, then apply vision-language models to classify images via these attributes. Pioneering work shows that querying thousands of attributes can achieve performance competitive with image features. However, our further investigation on 8 datasets reveals that LLM-generated attributes in a large quantity perform almost the same as random words. This surprising finding suggests that significant noise may be present in these attributes. We hypothesize that there exist subsets of attributes that can maintain the classification performance with much smaller sizes, and propose a novel learning-to-search method to discover those concise sets of attributes. As a result, on the CUB dataset, our method achieves performance close to that of massive LLM-generated attributes (eg, 10k attributes for CUB), yet using only 32 attributes in total to distinguish 200 bird species. Furthermore, our new paradigm demonstrates several additional benefits: higher interpretability and interactivity for humans, and the ability to summarize knowledge for a recognition task.",
        "total_citations": 45
      },
      {
        "title": "LaPraDoR: Unsupervised pretrained dense retriever for zero-shot text retrieval",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&pagesize=100&citation_for_view=icbo4M0AAAAJ:CB2v5VPnA5kC",
        "authors": [
          "Canwen Xu",
          "Daya Guo",
          "Nan Duan",
          "Julian McAuley"
        ],
        "publication_date": "2022-03-11",
        "conference": "Findings of ACL",
        "description": "In this paper, we propose LaPraDoR, a pretrained dual-tower dense retriever that does not require any supervised data for training. Specifically, we first present Iterative Contrastive Learning (ICoL) that iteratively trains the query and document encoders with a cache mechanism. ICoL not only enlarges the number of negative instances but also keeps representations of cached examples in the same hidden space. We then propose Lexicon-Enhanced Dense Retrieval (LEDR) as a simple yet effective way to enhance dense retrieval with lexical matching. We evaluate LaPraDoR on the recently proposed BEIR benchmark, including 18 datasets of 9 zero-shot text retrieval tasks. Experimental results show that LaPraDoR achieves state-of-the-art performance compared with supervised dense retrieval models, and further analysis reveals the effectiveness of our training strategy and objectives. Compared to re-ranking, our lexicon-enhanced approach can be run in milliseconds (22.5x faster) while achieving superior performance.",
        "total_citations": 45
      },
      {
        "title": "Graph rigidity, cyclic belief propagation, and point pattern matching",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:d1gkVwhDpl0C",
        "authors": [
          "Julian J McAuley",
          "Tib\u00e9rio S Caetano",
          "Marconi S Barbosa"
        ],
        "publication_date": "2008-05-23",
        "pages": "2047-2054",
        "publisher": "IEEE",
        "description": "A recent paper (Caetano et al., 2006) proposed a provably optimal, polynomial time method for performing near-isometric point pattern matching by means of exact probabilistic inference in a chordal graphical model. Its fundamental result is that the chordal graph in question is shown to be globally rigid, implying that exact inference provides the same matching solution as exact inference in a complete graphical model. This implies that the algorithm is optimal when there is no noise in the point patterns. In this paper, we present a new graph which is also globally rigid but has an advantage over the graph, its maximal clique size is smaller, rendering inference significantly more efficient. However, this graph is not chordal and thus standard junction tree algorithms cannot be directly applied. Nevertheless, we show that loopy belief propagation in such a graph converges to the optimal solution. This allows us to retain\u00a0\u2026",
        "total_citations": 45
      },
      {
        "title": "Beyond preserved accuracy: Evaluating loyalty and robustness of BERT compression",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:gVv57TyPmFsC",
        "authors": [
          "Canwen Xu",
          "Wangchunshu Zhou",
          "Tao Ge",
          "Ke Xu",
          "Julian McAuley",
          "Furu Wei"
        ],
        "publication_date": "2021-10-17",
        "conference": "Empirical Methods in Natural Language Processing",
        "description": "Recent studies on compression of pretrained language models (e.g., BERT) usually use preserved accuracy as the metric for evaluation. In this paper, we propose two new metrics, label loyalty and probability loyalty that measure how closely a compressed model (i.e., student) mimics the original model (i.e., teacher). We also explore the effect of compression with regard to robustness under adversarial attacks. We benchmark quantization, pruning, knowledge distillation and progressive module replacing with loyalty and robustness. By combining multiple compression techniques, we provide a practical strategy to achieve better accuracy, loyalty and robustness.",
        "total_citations": 44
      },
      {
        "title": "Small models are valuable plug-ins for large language models",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:SIv7DqKytYAC",
        "authors": [
          "Canwen Xu",
          "Yichong Xu",
          "Shuohang Wang",
          "Yang Liu",
          "Chenguang Zhu",
          "Julian McAuley"
        ],
        "publication_date": "2023-05-15",
        "description": "Large language models (LLMs) such as GPT-3 and GPT-4 are powerful but their weights are often publicly unavailable and their immense sizes make the models difficult to be tuned with common hardware. As a result, effectively tuning these models with large-scale supervised data can be challenging. As an alternative, In-Context Learning (ICL) can only use a small number of supervised examples due to context length limits. In this paper, we propose Super In-Context Learning (SuperICL) which allows black-box LLMs to work with locally fine-tuned smaller models, resulting in superior performance on supervised tasks. Our experiments demonstrate that SuperICL can improve performance beyond state-of-the-art fine-tuned models while addressing the instability problem of in-context learning. Furthermore, SuperICL can enhance the capabilities of smaller models, such as multilinguality and interpretability.",
        "total_citations": 43
      },
      {
        "title": "Zero-shot generalization in dialog state tracking through generative question answering",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:9c2xU6iGI7YC",
        "authors": [
          "Shuyang Li",
          "Jin Cao",
          "Mukund Sridhar",
          "Henghui Zhu",
          "Shang-Wen Li",
          "Wael Hamza",
          "Julian McAuley"
        ],
        "publication_date": "2021-01-20",
        "conference": "European Chapter of the Association for Computational Linguistics",
        "description": "Dialog State Tracking (DST), an integral part of modern dialog systems, aims to track user preferences and constraints (slots) in task-oriented dialogs. In real-world settings with constantly changing services, DST systems must generalize to new domains and unseen slot types. Existing methods for DST do not generalize well to new slot names and many require known ontologies of slot types and values for inference. We introduce a novel ontology-free framework that supports natural language queries for unseen constraints and slots in multi-domain task-oriented dialogs. Our approach is based on generative question-answering using a conditional language model pre-trained on substantive English sentences. Our model improves joint goal accuracy in zero-shot domain adaptation settings by up to 9% (absolute) over the previous state-of-the-art on the MultiWOZ 2.1 dataset.",
        "total_citations": 41
      },
      {
        "title": "Ask what's missing and what's useful: Improving clarification question generation using global knowledge",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:OcBU2YAGkTUC",
        "authors": [
          "Bodhisattwa Prasad Majumder",
          "Sudha Rao",
          "Michel Galley",
          "Julian McAuley"
        ],
        "publication_date": "2021-10-17",
        "conference": "North American Chapter of the Association for Computational Linguistics",
        "description": "The ability to generate clarification questions ie, questions that identify useful missing information in a given context, is important in reducing ambiguity. Humans use previous experience with similar contexts to form a global view and compare it to the given context to ascertain what is missing and what is useful in the context. Inspired by this, we propose a model for clarification question generation where we first identify what is missing by taking a difference between the global and the local view and then train a model to identify what is useful and generate a question about it. Our model outperforms several baselines as judged by both automatic metrics and humans.",
        "total_citations": 40
      },
      {
        "title": "Expressive neural voice cloning",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:AHdEip9mkN0C",
        "authors": [
          "Paarth Neekhara",
          "Shehzeen Hussain",
          "Shlomo Dubnov",
          "Farinaz Koushanfar",
          "Julian McAuley"
        ],
        "publication_date": "2021-10-17",
        "conference": "Asian Conference on Machine Learning",
        "description": "Voice cloning is the task of learning to synthesize the voice of an unseen speaker from a few samples. While current voice cloning methods achieve promising results in Text-to-Speech (TTS) synthesis for a new voice, these approaches lack the ability to control the expressiveness of synthesized audio. In this work, we propose a controllable voice cloning method that allows fine-grained control over various style aspects of the synthesized speech for an unseen speaker. We achieve this by explicitly conditioning the speech synthesis model on a speaker encoding, pitch contour and latent style tokens during training. Through both quantitative and qualitative evaluations, we show that our framework can be used for various expressive voice cloning tasks using only a few transcribed or untranscribed speech samples for a new speaker. These cloning tasks include style transfer from a reference speech, synthesizing speech directly from text, and fine-grained style control by manipulating the style conditioning variables during inference.",
        "total_citations": 38
      },
      {
        "title": "Weakly supervised named entity tagging with learnable logical rules",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:GFxP56DSvIMC",
        "authors": [
          "Jiacheng Li",
          "Haibo Ding",
          "Jingbo Shang",
          "Julian McAuley",
          "Zhe Feng"
        ],
        "publication_date": "2021-10-17",
        "conference": "Association for Computational Linguistics",
        "description": "We study the problem of building entity tagging systems by using a few rules as weak supervision. Previous methods mostly focus on disambiguation entity types based on contexts and expert-provided rules, while assuming entity spans are given. In this work, we propose a novel method TALLOR that bootstraps high-quality logical rules to train a neural tagger in a fully automated manner. Specifically, we introduce compound rules that are composed from simple rules to increase the precision of boundary detection and generate more diverse pseudo labels. We further design a dynamic label selection strategy to ensure pseudo label quality and therefore avoid overfitting the neural tagger. Experiments on three datasets demonstrate that our method outperforms other weakly supervised methods and even rivals a state-of-the-art distantly supervised tagger with a lexicon of over 2,000 terms when starting from only 20 simple rules. Our method can serve as a tool for rapidly building taggers in emerging domains and tasks. Case studies show that learned rules can potentially explain the predicted entities.",
        "total_citations": 38
      },
      {
        "title": "Identifying and characterizing highly similar notes in big clinical note datasets",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:u9iWguZQMMsC",
        "authors": [
          "Rodney A Gabriel",
          "Tsung-Ting Kuo",
          "Julian McAuley",
          "Chun-Nan Hsu"
        ],
        "publication_date": "2018-04-19",
        "description": "BackgroundBig clinical note datasets found in electronic health records (EHR) present substantial opportunities to train accurate statistical models that identify patterns in patient diagnosis and outcomes. However, near-to-exact duplication in note texts is a common issue in many clinical note datasets. We aimed to use a scalable algorithm to de-duplicate notes and further characterize the sources of duplication.MethodsWe use an approximation algorithm to minimize pairwise comparisons consisting of three phases: (1) Minhashing with Locality Sensitive Hashing; (2) a clustering method using tree-structured disjoint sets; and (3) classification of near-duplicates (exact copies, common machine output notes, or similar notes) via pairwise comparison of notes in each cluster. We use the Jaccard Similarity (JS) to measure similarity between two documents. We analyzed two big clinical note datasets: our institutional\u00a0\u2026",
        "total_citations": 38
      },
      {
        "title": "The NES Music Database: A multi-instrumental dataset with expressive performance attributes",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:K3LRdlH-MEoC",
        "authors": [
          "Chris Donahue",
          "Huanru Henry Mao",
          "Julian McAuley"
        ],
        "publication_date": "2018-10-17",
        "conference": "International Society for Music Information Retrieval Conference",
        "description": "Existing research on music generation focuses on composition, but often ignores the expressive performance characteristics required for plausible renditions of resultant pieces. In this paper, we introduce the Nintendo Entertainment System Music Database (NES-MDB), a large corpus allowing for separate examination of the tasks of composition and performance. NES-MDB contains thousands of multi-instrumental songs composed for playback by the compositionally-constrained NES audio synthesizer. For each song, the dataset contains a musical score for four instrument voices as well as expressive attributes for the dynamics and timbre of each voice. Unlike datasets comprised of General MIDI files, NES-MDB includes all of the information needed to render exact acoustic performances of the original compositions. Alongside the dataset, we provide a tool that renders generated compositions as NES-style audio by emulating the device's audio processor. Additionally, we establish baselines for the tasks of composition, which consists of learning the semantics of composing for the NES synthesizer, and performance, which involves finding a mapping between a composition and realistic expressive attributes.",
        "total_citations": 38
      },
      {
        "title": "LongCoder: A long-range pre-trained language model for code completion",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:8Xgff_V0N9gC",
        "authors": [
          "Daya Guo",
          "Canwen Xu",
          "Nan Duan",
          "Jian Yin",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-17",
        "conference": "International Conference on Machine Learning",
        "description": "In this paper, we introduce a new task for code completion that focuses on handling long code input and propose a sparse Transformer model, called LongCoder, to address this task. LongCoder employs a sliding window mechanism for self-attention and introduces two types of globally accessible tokens-bridge tokens and memory tokens-to improve performance and efficiency. Bridge tokens are inserted throughout the input sequence to aggregate local information and facilitate global interaction, while memory tokens are included to highlight important statements that may be invoked later and need to be memorized, such as package imports and definitions of classes, functions, or structures. We conduct experiments on a newly constructed dataset that contains longer code context and the publicly available CodeXGLUE benchmark. Experimental results demonstrate that LongCoder achieves superior performance on code completion tasks compared to previous models while maintaining comparable efficiency in terms of computational resources during inference.",
        "total_citations": 37
      },
      {
        "title": "Large-scale modeling of media dialog with discourse patterns and knowledge grounding",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:umqufdRvDiIC",
        "authors": [
          "Bodhisattwa Prasad Majumder",
          "Shuyang Li",
          "Jianmo Ni",
          "Julian McAuley"
        ],
        "publication_date": "2020-10-17",
        "conference": "Empirical Methods in Natural Language Processing",
        "total_citations": 35
      },
      {
        "title": "Learning visual-semantic embeddings for reporting abnormal findings on chest x-rays",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:a9-T7VOCCH8C",
        "authors": [
          "Jianmo Ni",
          "Chun-Nan Hsu",
          "Amilcare Gentili",
          "Julian McAuley"
        ],
        "publication_date": "2020-10-17",
        "conference": "Findings of EMNLP",
        "description": "Automatic medical image report generation has drawn growing attention due to its potential to alleviate radiologists' workload. Existing work on report generation often trains encoder-decoder networks to generate complete reports. However, such models are affected by data bias (e.g.~label imbalance) and face common issues inherent in text generation models (e.g.~repetition). In this work, we focus on reporting abnormal findings on radiology images; instead of training on complete radiology reports, we propose a method to identify abnormal findings from the reports in addition to grouping them with unsupervised clustering and minimal rules. We formulate the task as cross-modal retrieval and propose Conditional Visual-Semantic Embeddings to align images and fine-grained abnormal findings in a joint embedding space. We demonstrate that our method is able to retrieve abnormal findings and outperforms existing generation models on both clinical correctness and text generation metrics.",
        "total_citations": 34
      },
      {
        "title": "On sampling collaborative filtering datasets",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:NyGDZy8z5eUC",
        "authors": [
          "Noveen Sachdeva",
          "Carole-Jean Wu",
          "Julian McAuley"
        ],
        "publication_date": "2022-10-17",
        "conference": "Web Search and Data Mining",
        "description": "We study the practical consequences of dataset sampling strategies on the ranking performance of recommendation algorithms. Recommender systems are generally trained and evaluated on samples of larger datasets. Samples are often taken in a naive or ad-hoc fashion: e.g. by sampling a dataset randomly or by selecting users or items with many interactions. As we demonstrate, commonly-used data sampling schemes can have significant consequences on algorithm performance. Following this observation, this paper makes three main contributions: (1) characterizing the effect of sampling on algorithm performance, in terms of algorithm and dataset characteristics (e.g. sparsity characteristics, sequential dynamics, etc.); (2) designing SVP-CF, which is a data-specific sampling strategy, that aims to preserve the relative performance of models after sampling, and is especially suited to long-tailed interaction data\u00a0\u2026",
        "total_citations": 33
      },
      {
        "title": "Predicting surgery duration with neural heteroscedastic regression",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:b0M2c_1WBrUC",
        "authors": [
          "Nathan Ng",
          "Rodney A Gabriel",
          "Julian McAuley",
          "Charles Elkan",
          "Zachary C Lipton"
        ],
        "publication_date": "2017-10-17",
        "conference": "Machine Learning for Healthcare",
        "description": "Scheduling surgeries is a challenging task due to the fundamental uncertainty of the clinical environment, as well as the risks and costs associated with under-and over-booking. We investigate neural regression algorithms to estimate the parameters of surgery case durations, focusing on the issue of heteroscedasticity. We seek to simultaneously estimate the duration of each surgery, as well as a surgery-specific notion of our uncertainty about its duration. Estimating this uncertainty can lead to more nuanced and effective scheduling strategies, as we are able to schedule surgeries more efficiently while allowing an informed and case-specific margin of error. Using surgery records from a large United States health system we demonstrate potential improvements on the order of 20%(in terms of minutes overbooked) compared to current scheduling techniques. Moreover, we demonstrate that surgery durations are indeed heteroscedastic. We show that models that estimate case-specific uncertainty better fit the data (log likelihood). Additionally, we show that the heteroscedastic predictions can more optimally trade off between over and under-booking minutes, especially when idle minutes and scheduling collisions confer disparate costs.",
        "total_citations": 33
      },
      {
        "title": "Faster algorithms for max-product message-passing",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:dhFuZR0502QC",
        "authors": [
          "Julian J McAuley",
          "Tib\u00e9rio S Caetano"
        ],
        "publication_date": "2011-07-01",
        "pages": "1349-1388",
        "publisher": "JMLR",
        "description": "Maximum A Posteriori inference in graphical models is often solved via message-passing algorithms, such as the junction-tree algorithm or loopy belief-propagation. The exact solution to this problem is well-known to be exponential in the size of the maximal cliques of the triangulated model, while approximate inference is typically exponential in the size of the model\u2019s factors. In this paper, we take advantage of the fact that many models have maximal cliques that are larger than their constituent factors, and also of the fact that many factors consist only of latent variables (ie, they do not depend on an observation). This is a common case in a wide variety of applications that deal with grid-, tree-, and ring-structured models. In such cases, we are able to decrease the exponent of complexity for message-passing by 0.5 for both exact and approximate inference. We demonstrate that message-passing operations in such models are equivalent to some variant of matrix multiplication in the tropical semiring, for which we offer an O (N2. 5) expected-case solution.",
        "total_citations": 33
      },
      {
        "title": "Exponential family graph matching and ranking",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:IWHjjKOFINEC",
        "authors": [
          "James Petterson",
          "Tiberio Caetano",
          "Julian McAuley",
          "Jin Yu"
        ],
        "publication_date": "2009-04-17",
        "conference": "Neural Information Processing Systems",
        "description": "We present a method for learning max-weight matching predictors in bipartite graphs. The method consists of performing maximum a posteriori estimation in exponential families with sufficient statistics that encode permutations and data features. Although inference is in general hard, we show that for one very relevant application-document ranking-exact inference is efficient. For general model instances, an appropriate sampler is readily available. Contrary to existing max-margin matching models, our approach is statistically consistent and, in addition, experiments with increasing sample sizes indicate superior improvement over such models. We apply the method to graph matching in computer vision as well as to a standard benchmark dataset for learning document ranking, in which we obtain state-of-the-art results, in particular improving on max-margin variants. The drawback of this method with respect to max-margin alternatives is its runtime for large graphs, which is high comparatively.",
        "total_citations": 33
      },
      {
        "title": "Bridging language and items for retrieval and recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:zUl2_INMlC4C",
        "authors": [
          "Yupeng Hou",
          "Jiacheng Li",
          "Zhankui He",
          "An Yan",
          "Xiusi Chen",
          "Julian McAuley"
        ],
        "publication_date": "2024-03-06",
        "description": "This paper introduces BLaIR, a series of pretrained sentence embedding models specialized for recommendation scenarios. BLaIR is trained to learn correlations between item metadata and potential natural language context, which is useful for retrieving and recommending items. To pretrain BLaIR, we collect Amazon Reviews 2023, a new dataset comprising over 570 million reviews and 48 million items from 33 categories, significantly expanding beyond the scope of previous versions. We evaluate the generalization ability of BLaIR across multiple domains and tasks, including a new task named complex product search, referring to retrieving relevant items given long, complex natural language contexts. Leveraging large language models like ChatGPT, we correspondingly construct a semi-synthetic evaluation set, Amazon-C4. Empirical results on the new task, as well as conventional retrieval and recommendation tasks, demonstrate that BLaIR exhibit strong text and item representation capacity. Our datasets, code, and checkpoints are available at: https://github.com/hyp1231/AmazonReviews2023.",
        "total_citations": 31
      },
      {
        "title": "AgentCF: Collaborative learning with autonomous language agents for recommender systems",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:L_l9e5I586QC",
        "authors": [
          "Junjie Zhang",
          "Yupeng Hou",
          "Ruobing Xie",
          "Wenqi Sun",
          "Julian McAuley",
          "Wayne Xin Zhao",
          "Leyu Lin",
          "Ji-Rong Wen"
        ],
        "publication_date": "2024-10-17",
        "conference": "WWW",
        "description": "Recently, there has been an emergence of employing LLM-powered agents as believable human proxies, based on their remarkable decision-making capability. However, existing studies mainly focus on simulating human dialogue. Human non-verbal behaviors, such as item clicking in recommender systems, although implicitly exhibiting user preferences and could enhance the modeling of users, have not been deeply explored. The main reasons lie in the gap between language modeling and behavior modeling, as well as the incomprehension of LLMs about user-item relations. To address this issue, we propose AgentCF for simulating user-item interactions in recommender systems through agent-based collaborative filtering. We creatively consider not only users but also items as agents, and develop a collaborative learning approach that optimizes both kinds of agents together. Specifically, at each time step\u00a0\u2026",
        "total_citations": 30
      },
      {
        "title": "Rank list sensitivity of recommender systems to interaction perturbations",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:sszUF3NjhM4C",
        "authors": [
          "Sejoon Oh",
          "Berk Ustun",
          "Julian McAuley",
          "Srijan Kumar"
        ],
        "publication_date": "2022-10-17",
        "conference": "ACM International Conference on Information & Knowledge Management",
        "pages": "1584-1594",
        "description": "Prediction models can exhibit sensitivity with respect to training data: small changes in the training data can produce models that assign conflicting predictions to individual data points during test time. In this work, we study this sensitivity in recommender systems, where users' recommendations are drastically altered by minor perturbations in other unrelated users' interactions. We introduce a measure of stability for recommender systems, called Rank List Sensitivity (RLS), which measures how rank lists generated by a given recommender system at test time change as a result of a perturbation in the training data. We develop a method, CASPER, which uses cascading effect to identify the minimal and systematical perturbation to induce higher instability in a recommender system. Experiments on four datasets show that recommender models are overly sensitive to minor perturbations introduced randomly or via\u00a0\u2026",
        "total_citations": 30
      },
      {
        "title": "Visually-aware personalized recommendation using interpretable image representations",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:0izLItjtcgwC",
        "authors": [
          "Charles Packer",
          "Julian McAuley",
          "Arnau Ramisa"
        ],
        "publication_date": "2018-10-17",
        "conference": "Workshop on fashion and KDD",
        "description": "Visually-aware recommender systems use visual signals present in the underlying data to model the visual characteristics of items and users' preferences towards them. In the domain of clothing recommendation, incorporating items' visual information (e.g., product images) is particularly important since clothing item appearance is often a critical factor in influencing the user's purchasing decisions. Current state-of-the-art visually-aware recommender systems utilize image features extracted from pre-trained deep convolutional neural networks, however these extremely high-dimensional representations are difficult to interpret, especially in relation to the relatively low number of visual properties that may guide users' decisions. In this paper we propose a novel approach to personalized clothing recommendation that models the dynamics of individual users' visual preferences. By using interpretable image representations generated with a unique feature learning process, our model learns to explain users' prior feedback in terms of their affinity towards specific visual attributes and styles. Our approach achieves state-of-the-art performance on personalized ranking tasks, and the incorporation of interpretable visual features allows for powerful model introspection, which we demonstrate by using an interactive recommendation algorithm and visualizing the rise and fall of fashion trends over time.",
        "total_citations": 30
      },
      {
        "title": "A survey on dynamic neural networks for natural language processing",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:buQ7SEKw-1sC",
        "authors": [
          "Canwen Xu",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-17",
        "conference": "Findings of EACL",
        "description": "Effectively scaling large Transformer models is a main driver of recent advances in natural language processing. Dynamic neural networks, as an emerging research direction, are capable of scaling up neural networks with sub-linear increases in computation and time by dynamically adjusting their computational path based on the input. Dynamic neural networks could be a promising solution to the growing parameter numbers of pretrained language models, allowing both model pretraining with trillions of parameters and faster inference on mobile devices. In this survey, we summarize progress of three types of dynamic neural networks in NLP: skimming, mixture of experts, and early exit. We also highlight current challenges in dynamic neural networks and directions for future research.",
        "total_citations": 29
      },
      {
        "title": "Cross-modal adversarial reprogramming",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:2tRrZ1ZAMYUC",
        "authors": [
          "Paarth Neekhara",
          "Shehzeen Hussain",
          "Jinglong Du",
          "Shlomo Dubnov",
          "Farinaz Koushanfar",
          "Julian McAuley"
        ],
        "publication_date": "2021-10-17",
        "conference": "Winter Conference on Applications of Computer Vision",
        "description": "With the abundance of large-scale deep learning models, it has become possible to repurpose pre-trained networks for new tasks. Recent works on adversarial reprogramming have shown that it is possible to repurpose neural networks for alternate tasks without modifying the network architecture or parameters. However these works only consider original and target tasks within the same data domain. In this work, we broaden the scope of adversarial reprogramming beyond the data modality of the original task. We analyze the feasibility of adversarially repurposing image classification neural networks for Natural Language Processing (NLP) and other sequence classification tasks. We design an efficient adversarial program that maps a sequence of discrete tokens into an image which can be classified to the desired class by an image classification model. We demonstrate that by using highly efficient adversarial programs, we can reprogram image classifiers to achieve competitive performance on a variety of text and sequence classification benchmarks without retraining the network.",
        "total_citations": 29
      },
      {
        "title": "Generating visually-aware item recommendations using a personalized preference ranking network",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:BwyfMAYsbu0C",
        "publication_date": "2019-08-15",
        "description": "The present disclosure relates to a fashion recommendation system that employs a task-guided learning framework to jointly train a visually-aware personalized preference ranking network. In addition, the fashion recommendation system employs implicit feedback and generated user-based triplets to learn variances in the user's fashion preferences for items with which the user has not yet interacted. In particular, the fashion recommendation system uses triplets generated from implicit user data to jointly train a Siamese convolutional neural network and a personalized ranking model, which together produce a user preference predictor that determines personalized fashion recommendations for a user.",
        "total_citations": 29
      },
      {
        "title": "Expediting TTS synthesis with adversarial vocoding",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:4MWp96NkSFoC",
        "authors": [
          "Paarth Neekhara",
          "Chris Donahue",
          "Miller Puckette",
          "Shlomo Dubnov",
          "Julian McAuley"
        ],
        "publication_date": "2019-10-17",
        "conference": "Interspeech",
        "description": "Recent approaches in text-to-speech (TTS) synthesis employ neural network strategies to vocode perceptually-informed spectrogram representations directly into listenable waveforms. Such vocoding procedures create a computational bottleneck in modern TTS pipelines. We propose an alternative approach which utilizes generative adversarial networks (GANs) to learn mappings from perceptually-informed spectrograms to simple magnitude spectrograms which can be heuristically vocoded. Through a user study, we show that our approach significantly outperforms na\\\"ive vocoding strategies while being hundreds of times faster than neural network vocoders used in state-of-the-art TTS systems. We also show that our method can be used to achieve state-of-the-art results in unsupervised synthesis of individual words of speech.",
        "total_citations": 29
      },
      {
        "title": "Improving recommendation accuracy using networks of substitutable and complementary products",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:GtLg2Ama23sC",
        "authors": [
          "Tong Zhao",
          "Julian McAuley",
          "Mengya Li",
          "Irwin King"
        ],
        "publication_date": "2017-10-17",
        "conference": "International Joint Conference on Neural Networks",
        "pages": "3649-3655",
        "publisher": "IEEE",
        "description": "Recommender systems are ubiquitous in applications ranging from e-commerce to social media, helping users to navigate a huge selection of items and to meet a variety of special needs and user tastes. Incorporating contextual knowledge into such systems - such as relational information - has proven to be an effective way to improve recommendation accuracy. A popular line of research aims to model relationships between users, through their connections in a social network. In contrast, we aim to model complex relationships between products, using data based on co-purchase and co-browsing behavior. Modeling such networks presents a variety of challenges, in particular because the features that make two items complementary (or likely to be co-purchased) are far more complex than mere similarity. To model these complex relationships we develop a method based on pairwise ranking and embedding\u00a0\u2026",
        "total_citations": 29
      },
      {
        "title": "Personalized Showcases: Generating multi-modal explanations for recommendations",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:AXkvAH5U_nMC",
        "authors": [
          "An Yan",
          "Zhankui He",
          "Jiacheng Li",
          "Tianyang Zhang",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-17",
        "conference": "SIGIR",
        "description": "Existing explanation models generate only text for recommendations but still struggle to produce diverse contents. In this paper, to further enrich explanations, we propose a new task named personalized showcases, in which we provide both textual and visual information to explain our recommendations. Specifically, we first select a personalized image set that is the most relevant to a user's interest toward a recommended item. Then, natural language explanations are generated accordingly given our selected images. For this new task, we collect a large-scale dataset from Google Maps and construct a high-quality subset for generating multi-modal explanations. We propose a personalized multi-modal framework which can generate diverse and visually-aligned explanations via contrastive learning. Experiments show that our framework benefits from different modalities as inputs, and is able to produce more\u00a0\u2026",
        "total_citations": 28
      },
      {
        "title": "Personalized machine learning",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:6yz0xqPARnAC",
        "authors": [
          "Julian McAuley"
        ],
        "publication_date": "2022-02-03",
        "publisher": "Cambridge University Press",
        "description": "Every day we interact with machine learning systems offering individualized predictions for our entertainment, social connections, purchases, or health. These involve several modalities of data, from sequences of clicks to text, images, and social interactions. This book introduces common principles and methods that underpin the design of personalized predictive models for a variety of settings and modalities. The book begins by revising'traditional'machine learning models, focusing on adapting them to settings involving user data, then presents techniques based on advanced principles such as matrix factorization, deep learning, and generative modeling, and concludes with a detailed study of the consequences and risks of deploying personalized predictive systems. A series of case studies in domains ranging from e-commerce to health plus hands-on projects and code examples will give readers understanding and experience with large-scale real-world datasets and the ability to design models and systems for a wide range of applications.",
        "total_citations": 28
      },
      {
        "title": "Personalized complementary product recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:PYBJJbyH-FwC",
        "authors": [
          "An Yan",
          "Chaosheng Dong",
          "Yan Gao",
          "Jinmiao Fu",
          "Tong Zhao",
          "Yi Sun",
          "Julian McAuley"
        ],
        "publication_date": "2022-10-17",
        "conference": "World Wide Web (Industry Track)",
        "description": " Complementary product recommendation aims at providing product suggestions that are often bought together to serve a joint demand. Existing work mainly focuses on modeling product relationships at a population level, but does not consider personalized preferences of different customers. In this paper, we propose a framework for personalized complementary product recommendation capable of recommending products that fit the demand and preferences of the customers. Specifically, we model product relations and user preferences with a graph attention network and a sequential behavior transformer, respectively. Two networks are cast together through personalized re-ranking and contrastive learning, in which the user and product embedding are learned jointly in an end-to-end fashion. The system recognizes different customer interests by learning from their purchase history and the correlations among\u00a0\u2026",
        "total_citations": 28
      },
      {
        "title": "A longitudinal evaluation of a best practices CS1",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:8d8msizDQcsC",
        "authors": [
          "Adrian Salguero",
          "Julian McAuley",
          "Beth Simon",
          "Leo Porter"
        ],
        "publication_date": "2020-08-10",
        "conference": "International Computing Education Research Conference",
        "pages": "182-193",
        "description": "Over a decade ago, the CS1 course for students without prior programming experience at a large research-intensive university was redesigned to incorporate three best practices in teaching programming: Media Computation, Pair Programming, and Peer Instruction. The purpose of this revision was to improve the quality of the course, appeal to a larger student body, and improve retention in the major. An initial analysis of the course indicated an increase in pass rates and 1-yr retention of students in the major. Now that time has passed and those students impacted by the revision have had time to graduate, this longitudinal study revisits and expands on these prior findings through examining student outcomes over a twelve year period (2001 through 2013). The student outcomes examined include failure rates in CS1, retention rates in the major, rates of switching into the major, time to degree, and performance in\u00a0\u2026",
        "total_citations": 28
      },
      {
        "title": "Large language models and causal inference in collaboration: A comprehensive survey",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:s85pQhAUCrAC",
        "authors": [
          "Xiaoyu Liu",
          "Paiheng Xu",
          "Junda Wu",
          "Jiaxin Yuan",
          "Yifan Yang",
          "Yuhang Zhou",
          "Fuxiao Liu",
          "Tianrui Guan",
          "Haoliang Wang",
          "Tong Yu",
          "Julian McAuley",
          "Wei Ai",
          "Furong Huang"
        ],
        "publication_date": "2024-03-14",
        "description": "Causal inference has shown potential in enhancing the predictive accuracy, fairness, robustness, and explainability of Natural Language Processing (NLP) models by capturing causal relationships among variables. The emergence of generative Large Language Models (LLMs) has significantly impacted various NLP domains, particularly through their advanced reasoning capabilities. This survey focuses on evaluating and improving LLMs from a causal view in the following areas: understanding and improving the LLMs' reasoning capacity, addressing fairness and safety issues in LLMs, complementing LLMs with explanations, and handling multimodality. Meanwhile, LLMs' strong reasoning capacities can in turn contribute to the field of causal inference by aiding causal relationship discovery and causal effect estimations. This review explores the interplay between causal inference frameworks and LLMs from both perspectives, emphasizing their collective potential to further the development of more advanced and equitable artificial intelligence systems.",
        "total_citations": 27
      },
      {
        "title": "FaceSigns: semi-fragile neural watermarks for media authentication and countering deepfakes",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:SjuI4pbJlxcC",
        "authors": [
          "Paarth Neekhara",
          "Shehzeen Hussain",
          "Xinqiao Zhang",
          "Ke Huang",
          "Julian McAuley",
          "Farinaz Koushanfar"
        ],
        "publication_date": "2024-10-17",
        "description": "Deepfakes and manipulated media are becoming a prominent threat due to the recent advances in realistic image and video synthesis techniques. There have been several attempts at combating Deepfakes using machine learning classifiers. However, such classifiers do not generalize well to black-box image synthesis techniques and have been shown to be vulnerable to adversarial examples. To address these challenges, we introduce a deep learning based semi-fragile watermarking technique that allows media authentication by verifying an invisible secret message embedded in the image pixels. Instead of identifying and detecting fake media using visual artifacts, we propose to proactively embed a semi-fragile watermark into a real image so that we can prove its authenticity when needed. Our watermarking framework is designed to be fragile to facial manipulations or tampering while being robust to benign image-processing operations such as image compression, scaling, saturation, contrast adjustments etc. This allows images shared over the internet to retain the verifiable watermark as long as face-swapping or any other Deepfake modification technique is not applied. We demonstrate that FaceSigns can embed a 128 bit secret as an imperceptible image watermark that can be recovered with a high bit recovery accuracy at several compression levels, while being non-recoverable when unseen Deepfake manipulations are applied. For a set of unseen benign and Deepfake manipulations studied in our work, FaceSigns can reliably detect manipulated content with an AUC score of 0.996 which is significantly higher than prior image\u00a0\u2026",
        "total_citations": 27
      },
      {
        "title": "Infinite recommendation networks: A data-centric approach",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:65Yg0jNCQDAC",
        "authors": [
          "Noveen Sachdeva",
          "Mehak Preet Dhaliwal",
          "Carole-Jean Wu",
          "Julian McAuley"
        ],
        "publication_date": "2022-10-17",
        "conference": "Neural Information Processing Systems",
        "description": "We leverage the Neural Tangent Kernel and its equivalence to training infinitely-wide neural networks to devise -AE: an autoencoder with infinitely-wide bottleneck layers. The outcome is a highly expressive yet simplistic recommendation model with a single hyper-parameter and a closed-form solution. Leveraging -AE's simplicity, we also develop Distill-CF for synthesizing tiny, high-fidelity data summaries which distill the most important knowledge from the extremely large and sparse user-item interaction matrix for efficient and accurate subsequent data-usage like model training, inference, architecture search, etc. This takes a data-centric approach to recommendation, where we aim to improve the quality of logged user-feedback data for subsequent modeling, independent of the learning algorithm. We particularly utilize the concept of differentiable Gumbel-sampling to handle the inherent data heterogeneity, sparsity, and semi-structuredness, while being scalable to datasets with hundreds of millions of user-item interactions. Both of our proposed approaches significantly outperform their respective state-of-the-art and when used together, we observe % of -AE's performance on the full dataset with as little as % of the original dataset size, leading us to explore the counter-intuitive question: Is more data what you need for better recommendation?",
        "total_citations": 27
      },
      {
        "title": "Fast inference with min-sum matrix product",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:roLk4NBRz8UC",
        "authors": [
          "P Felzenszwalb",
          "J McAuley"
        ],
        "publication_date": "2011-10-17",
        "publisher": "IEEE",
        "description": "The MAP inference problem in many graphical models can be solved efficiently using a fast algorithm for computing min-sum products of n \u00d7 n matrices. The class of models in question includes cyclic and skip-chain models that arise in many applications. Although the worst-case complexity of the min-sum product operation is not known to be much better than O(n 3 ), an O(n 2.5 ) expected time algorithm was recently given, subject to some constraints on the input matrices. In this paper, we give an algorithm that runs in O(n 2  log n) expected time, assuming that the entries in the input matrices are independent samples from a uniform distribution. We also show that two variants of our algorithm are quite fast for inputs that arise in several applications. This leads to significant performance gains over previous methods in applications within computer vision and natural language processing.",
        "total_citations": 27
      },
      {
        "title": "Bundle MCR: Towards conversational bundle recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:-jrNzM816MMC",
        "authors": [
          "Zhankui He",
          "Handong Zhao",
          "Tong Yu",
          "Sungchul Kim",
          "Fan Du",
          "Julian McAuley"
        ],
        "publication_date": "2022-09-18",
        "pages": "288-298",
        "description": "Bundle recommender systems recommend sets of items (e.g.,\u00a0pants, shirt, and shoes) to users, but they often suffer from two issues: significant interaction sparsity and a large output space. In this work, we extend multi-round conversational recommendation (MCR) to alleviate these issues. MCR\u2014which uses a conversational paradigm to elicit user interests by asking user preferences on tags (e.g.,\u00a0categories or attributes) and handling user feedback across multiple rounds\u2014is an emerging recommendation setting to acquire user feedback and narrow down the output space, but has not been explored in the context of bundle recommendation.  In this work, we propose a novel recommendation task named Bundle MCR. Unlike traditional bundle recommendation (a bundle-aware user model and bundle generation), Bundle MCR studies how to encode user feedback as conversation states and how to post questions\u00a0\u2026",
        "total_citations": 26
      },
      {
        "title": "Help-seeking behavior by women experiencing intimate partner violence in india: A machine learning approach to identifying risk factors",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:PVgj2kMGcgYC",
        "authors": [
          "Nabamallika Dehingia",
          "Arnab K Dey",
          "Lotus McDougal",
          "Julian McAuley",
          "Abhishek Singh",
          "Anita Raj"
        ],
        "publication_date": "2022-02-03",
        "pages": "e0262538",
        "publisher": "Public Library of Science",
        "description": " Background Despite the low prevalence of help-seeking behavior among victims of intimate partner violence (IPV) in India, quantitative evidence on risk factors, is limited. We use a previously validated exploratory approach, to examine correlates of help-seeking from anyone (e.g. family, friends, police, doctor etc.), as well as help-seeking from any formal sources. Methods We used data from a nationally-representative health survey conducted in 2015\u201316 in India, and included all variables in the dataset (~6000 variables) as independent variables. Two machine learning (ML) models were used- L-1, and L-2 regularized logistic regression models. The results from these models were qualitatively coded by researchers to identify broad themes associated with help-seeking behavior. This process of implementing ML models followed by qualitative coding was repeated until pre-specified criteria were met. Results Identified themes associated with help-seeking behavior included experience of injury from violence, husband\u2019s controlling behavior, husband\u2019s consumption of alcohol, and being currently separated from husband. Themes related to women\u2019s access to social and economic resources, such as women\u2019s employment, and receipt of maternal and reproductive health services were also noted to be related factors. We observed similarity in correlates for seeking help from anyone, vs from formal sources, with a greater focus on women being separated for help-seeking from formal sources. Conclusion Findings highlight the need for community programs to reach out to women trapped in abusive relationships, as well as the importance of\u00a0\u2026",
        "total_citations": 26
      },
      {
        "title": "Unsupervised enrichment of persona-grounded dialog with background stories",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:r_AWSJRzSzQC",
        "authors": [
          "Bodhisattwa Prasad Majumder",
          "Taylor Berg-Kirkpatrick",
          "Julian McAuley",
          "Harsh Jhamtani"
        ],
        "publication_date": "2021-10-17",
        "conference": "Association for Computational Linguistics",
        "description": "Humans often refer to personal narratives, life experiences, and events to make a conversation more engaging and rich. While persona-grounded dialog models are able to generate responses that follow a given persona, they often miss out on stating detailed experiences or events related to a persona, often leaving conversations shallow and dull. In this work, we equip dialog models with'background stories' related to a persona by leveraging fictional narratives from existing story datasets (eg ROCStories). Since current dialog datasets do not contain such narratives as responses, we perform an unsupervised adaptation of a retrieved story for generating a dialog response using a gradient-based rewriting technique. Our proposed method encourages the generated response to be fluent (ie, highly likely) with the dialog history, minimally different from the retrieved story to preserve event ordering and consistent with\u00a0\u2026",
        "total_citations": 26
      },
      {
        "title": "Automatic multi-label prompting: Simple and interpretable few-shot classification",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:-mN3Mh-tlDkC",
        "authors": [
          "Han Wang",
          "Canwen Xu",
          "Julian McAuley"
        ],
        "publication_date": "2022-04-13",
        "conference": "NAACL",
        "description": "Prompt-based learning (i.e., prompting) is an emerging paradigm for exploiting knowledge learned by a pretrained language model. In this paper, we propose Automatic Multi-Label Prompting (AMuLaP), a simple yet effective method to automatically select label mappings for few-shot text classification with prompting. Our method exploits one-to-many label mappings and a statistics-based algorithm to select label mappings given a prompt template. Our experiments demonstrate that AMuLaP achieves competitive performance on the GLUE benchmark without human effort or external resources.",
        "total_citations": 25
      },
      {
        "title": "Deep Performer: Score-to-audio music performance synthesis",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:otzGkya1bYkC",
        "authors": [
          "Hao-Wen Dong",
          "Cong Zhou",
          "Taylor Berg-Kirkpatrick",
          "Julian McAuley"
        ],
        "publication_date": "2022-02-12",
        "conference": "International Conference on Acoustics Speech and Signal Processing",
        "description": "Music performance synthesis aims to synthesize a musical score into a natural performance. In this paper, we borrow recent advances in text-to-speech synthesis and present the Deep Performer\u2014a novel system for score-to-audio music performance synthesis. Unlike speech, music often contains polyphony and long notes. Hence, we propose two new techniques for handling polyphonic inputs and providing a fine-grained conditioning in a transformer encoder-decoder model. To train our proposed system, we present a new violin dataset consisting of paired recordings and scores along with estimated alignments between them. We show that our proposed model can synthesize music with clear polyphony and harmonic structures. In a listening test, we achieve competitive quality against the baseline model, a conditional generative audio model, in terms of pitch accuracy, timbre and noise level. Moreover, our\u00a0\u2026",
        "total_citations": 25
      },
      {
        "title": "Fast matching of large point sets under occlusions",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:_FxGoFyzp5QC",
        "authors": [
          "Julian J McAuley",
          "Tib\u00e9rio S Caetano"
        ],
        "publication_date": "2012-01-31",
        "pages": "563-569",
        "publisher": "Pergamon",
        "description": "The problem of isometric point-pattern matching can be modeled as inference in small tree-width graphical models whose embeddings in the plane are said to be \u2018globally rigid\u2019. Although such graphical models lead to efficient and exact solutions, they cannot generally handle occlusions, as even a single missing point may \u2018break\u2019 the rigidity of the graph in question. In addition, such models can efficiently handle point sets of only moderate size. In this paper, we propose a new graphical model that is not only adapted to handle occlusions but is much faster than previous approaches for solving the isometric point-pattern matching problem. We can match point-patterns with thousands of points in a few seconds.",
        "total_citations": 25
      },
      {
        "title": "An entropy-guided reinforced partial convolutional network for zero-shot learning",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:uDGL6kOW6j0C",
        "authors": [
          "Yun Li",
          "Zhe Liu",
          "Lina Yao",
          "Xianzhi Wang",
          "Julian McAuley",
          "Xiaojun Chang"
        ],
        "publication_date": "2022-01-31",
        "publisher": "IEEE",
        "description": "Zero-Shot Learning (ZSL) aims to transfer learned knowledge from observed classes to unseen classes via semantic correlations. A promising strategy is to learn a global-local representation that incorporates global information with extra localities (i.e., small parts/regions of inputs). However, existing methods discover localities based on explicit features without digging into the inherent properties and relationships among regions. In this work, we propose a novel Entropy-guided Reinforced Partial Convolutional Network (ERPCNet), which extracts and aggregates localities progressively based on semantic relevance and visual correlations without human-annotated regions. ERPCNet uses reinforced partial convolution and entropy guidance; it not only discovers global-cooperative localities dynamically but also converges faster for policy gradient optimization. We conduct extensive experiments to demonstrate\u00a0\u2026",
        "total_citations": 24
      },
      {
        "title": "Exposing vulnerabilities of Deepfake detection systems with robust attacks",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:KbBQZpvPDL4C",
        "authors": [
          "Shehzeen Hussain",
          "Paarth Neekhara",
          "Brian Dolhansky",
          "Joanna Bitton",
          "Cristian Canton Ferrer",
          "Julian McAuley",
          "Farinaz Koushanfar"
        ],
        "publication_date": "2021-04-29",
        "publisher": "ACM",
        "description": "Recent advances in video manipulation techniques have made the generation of fake videos more accessible than ever before. Manipulated videos can fuel disinformation and reduce trust in media. Therefore detection of fake videos has garnered immense interest in academia and industry. Recently developed Deepfake detection methods rely on Deep Neural Networks (DNNs) to distinguish AI-generated fake videos from real videos. In this work, we demonstrate that it is possible to bypass such detectors by adversarially modifying fake videos synthesized using existing Deepfake generation methods. We further demonstrate that our adversarial perturbations are robust to image and video compression codecs, making them a real-world threat. We present pipelines in both white-box and black-box attack scenarios that can fool DNN-based Deepfake detectors into classifying fake videos as real. Finally, we study the\u00a0\u2026",
        "total_citations": 24
      },
      {
        "title": "Stacked mixed-order graph convolutional networks for collaborative filtering",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:S16KYo8Pm5AC",
        "authors": [
          "Hengrui Zhang",
          "Julian McAuley"
        ],
        "publication_date": "2020-10-17",
        "conference": "SIAM International Conference on Data Mining",
        "description": " Graph-based recommendation algorithms treat user-item interactions as bipartite graphs, based on which low-dimensional vector representations of users and items seek to preserve the relationships among them. Previous methods usually capture users' preferences by directly learning first-order neighborhood patterns for each node, which limits their ability to exploit the similarity between two distant users/items as well as a user's preferences toward distant items. To address this potential weakness, in this paper, we propose SMOG-CF (Stacked Mixed-Order Graph Convolutional Networks for Collaborative Filtering), a GCN-based framework that can directly capture high-order connectivity among nodes. Instead of implicitly capturing high-order connectivity through embedding propagation, SMOG-CF facilitates \u2018path-level\u2019 information propagation between neighboring nodes at any order. The matrix form of our\u00a0\u2026",
        "total_citations": 24
      },
      {
        "title": "Embryo staging with weakly-supervised region selection and dynamically-decoded predictions",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:ML0RJ9NH7IQC",
        "authors": [
          "Tingfung Lau",
          "Nathan Ng",
          "Julian Gingold",
          "Nina Desai",
          "Julian McAuley",
          "Zachary C Lipton"
        ],
        "publication_date": "2019-10-17",
        "conference": "Machine Learning for Healthcare",
        "description": "To optimize clinical outcomes, fertility clinics must strategically select which embryos to transfer. Common selection heuristics are formulas expressed in terms of the durations required to reach various developmental milestones, quantities historically annotated manually by experienced embryologists based on time-lapse EmbryoScope videos. We propose a new method for automatic embryo staging that exploits several sources of structure in this time-lapse data. First, noting that in each image the embryo occupies a small subregion, we jointly train a region proposal network with the downstream classier to isolate the embryo. Notably, because we lack ground-truth bounding boxes, our we weakly supervise the region proposal network optimizing its parameters via reinforcement learning to improve the downstream classier\u2019s loss. Moreover, noting that embryos reaching the blastocyst stage progress monotonically through earlier stages, we develop a dynamic-programming-based decoder that post-processes our predictions to select the most likely monotonic sequence of developmental stages. Our methods outperform vanilla residual networks and rival the best numbers in contemporary papers, as measured by both per-frame accuracy and transition prediction error, despite operating on smaller data than many.",
        "total_citations": 24
      },
      {
        "title": "Factual and Informative Review Generation for Explainable Recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:uVUOdF_882EC",
        "authors": [
          "Zhouhang Xie",
          "Sameer Singh",
          "Julian McAuley",
          "Bodhisattwa Prasad Majumder"
        ],
        "publication_date": "2023-10-17",
        "conference": "AAAI Conference on Artificial Intelligence",
        "description": "Recent models can generate fluent and grammatical synthetic reviews while accurately predicting user ratings. The generated reviews, expressing users' estimated opinions towards related products, are often viewed as natural language \u2018rationales\u2019 for the jointly predicted rating. However, previous studies found that existing models often generate repetitive, universally applicable, and generic explanations, resulting in uninformative rationales. Further, our analysis shows that previous models' generated content often contain factual hallucinations. These issues call for novel solutions that could generate both informative and factually grounded explanations. Inspired by recent success in using retrieved content in addition to parametric knowledge for generation, we propose to augment the generator with a personalized retriever, where the retriever's output serves as external knowledge for enhancing the generator. Experiments on Yelp, TripAdvisor, and Amazon Movie Reviews dataset show our model could generate explanations that more reliably entail existing reviews, are more diverse, and are rated more informative by human evaluators.",
        "total_citations": 23
      },
      {
        "title": "Controlling bias exposure for fair interpretable predictions",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:FiDNX6EVdGUC",
        "authors": [
          "Zexue He",
          "Yu Wang",
          "Julian McAuley",
          "Bodhisattwa Prasad Majumder"
        ],
        "publication_date": "2022-10-17",
        "conference": "Findings of EMNLP",
        "description": "Recent work on reducing bias in NLP models usually focuses on protecting or isolating information related to a sensitive attribute (like gender or race). However, when sensitive information is semantically entangled with the task information of the input, e.g., gender information is predictive for a profession, a fair trade-off between task performance and bias mitigation is difficult to achieve. Existing approaches perform this trade-off by eliminating bias information from the latent space, lacking control over how much bias is necessarily required to be removed. We argue that a favorable debiasing method should use sensitive information 'fairly', rather than blindly eliminating it (Caliskan et al., 2017; Sun et al., 2019; Bogen et al., 2020). In this work, we provide a novel debiasing algorithm by adjusting the predictive model's belief to (1) ignore the sensitive information if it is not useful for the task; (2) use sensitive information minimally as necessary for the prediction (while also incurring a penalty). Experimental results on two text classification tasks (influenced by gender) and an open-ended generation task (influenced by race) indicate that our model achieves a desirable trade-off between debiasing and task performance along with producing debiased rationales as evidence.",
        "total_citations": 23
      },
      {
        "title": "Detect and Perturb: Neutral rewriting of biased and sensitive text via gradient-based decoding",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:vDZJ-YLwNdEC",
        "authors": [
          "Zexue He",
          "Bodhisattwa Prasad Majumder",
          "Julian McAuley"
        ],
        "publication_date": "2021-10-17",
        "conference": "Findings of EMNLP",
        "description": "Written language carries explicit and implicit biases that can distract from meaningful signals. For example, letters of reference may describe male and female candidates differently, or their writing style may indirectly reveal demographic characteristics. At best, such biases distract from the meaningful content of the text; at worst they can lead to unfair outcomes. We investigate the challenge of re-generating input sentences to 'neutralize' sensitive attributes while maintaining the semantic meaning of the original text (e.g. is the candidate qualified?). We propose a gradient-based rewriting framework, Detect and Perturb to Neutralize (DEPEN), that first detects sensitive components and masks them for regeneration, then perturbs the generation model at decoding time under a neutralizing constraint that pushes the (predicted) distribution of sensitive attributes towards a uniform distribution. Our experiments in two different scenarios show that DEPEN can regenerate fluent alternatives that are neutral in the sensitive attribute while maintaining the semantics of other attributes.",
        "total_citations": 23
      },
      {
        "title": "A survey on model compression for natural language processing",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:wMgC3FpKEyYC",
        "authors": [
          "Canwen Xu",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-17",
        "conference": "AAAI",
        "description": "With recent developments in new architectures like Transformer and pretraining techniques, significant progress has been made in applications of natural language processing (NLP). However, the high energy cost and long inference delay of Transformer is preventing NLP from entering broader scenarios including edge and mobile computing. Efficient NLP research aims to comprehensively consider computation, time and carbon emission for the entire life-cycle of NLP, including data preparation, model training and inference. In this survey, we focus on the inference stage and review the current state of model compression for NLP, including the benchmarks, metrics and methodology. We outline the current obstacles and future research directions.",
        "total_citations": 22
      },
      {
        "title": "Coarse-to-fine sparse sequential recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:XUvXOeBm_78C",
        "authors": [
          "Jiacheng Li",
          "Tong Zhao",
          "Jin Li",
          "Jim Chan",
          "Christos Faloutsos",
          "George Karypis",
          "Soo-Min Pantel",
          "Julian McAuley"
        ],
        "publication_date": "2022-04-04",
        "conference": "SIGIR",
        "description": "Sequential recommendation aims to model dynamic user behavior from historical interactions. Self-attentive methods have proven effective at capturing short-term dynamics and long-term preferences. Despite their success, these approaches still struggle to model sparse data, on which they struggle to learn high-quality item representations. We propose to model user dynamics from shopping intents and interacted items simultaneously. The learned intents are coarse-grained and work as prior knowledge for item recommendation. To this end, we present a coarse-to-fine self-attention framework, namely CaFe, which explicitly learns coarse-grained and fine-grained sequential dynamics. Specifically, CaFe first learns intents from coarse-grained sequences which are dense and hence provide high-quality user intent representations. Then, CaFe fuses intent representations into item encoder outputs to obtain\u00a0\u2026",
        "total_citations": 22
      },
      {
        "title": "Modeling dynamic attributes for next basket recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:BzfGm06jWhQC",
        "authors": [
          "Yongjun Chen",
          "Jia Li",
          "Chenghao Liu",
          "Chenxi Li",
          "Markus Anderle",
          "Julian McAuley",
          "Caiming Xiong"
        ],
        "publication_date": "2021-09-23",
        "description": "Traditional approaches to next item and next basket recommendation typically extract users' interests based on their past interactions and associated static contextual information (e.g. a user id or item category). However, extracted interests can be inaccurate and become obsolete. Dynamic attributes, such as user income changes, item price changes (etc.), change over time. Such dynamics can intrinsically reflect the evolution of users' interests. We argue that modeling such dynamic attributes can boost recommendation performance. However, properly integrating them into user interest models is challenging since attribute dynamics can be diverse such as time-interval aware, periodic patterns (etc.), and they represent users' behaviors from different perspectives, which can happen asynchronously with interactions. Besides dynamic attributes, items in each basket contain complex interdependencies which might be beneficial but nontrivial to effectively capture. To address these challenges, we propose a novel Attentive network to model Dynamic attributes (named AnDa). AnDa separately encodes dynamic attributes and basket item sequences. We design a periodic aware encoder to allow the model to capture various temporal patterns from dynamic attributes. To effectively learn useful item relationships, intra-basket attention module is proposed. Experimental results on three real-world datasets demonstrate that our method consistently outperforms the state-of-the-art.",
        "total_citations": 22
      },
      {
        "title": "SkipBERT: Efficient inference with shallow layer skipping",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:3NQIlFlcGxIC",
        "authors": [
          "Jue Wang",
          "Ke Chen",
          "Gang Chen",
          "Lidan Shou",
          "Julian McAuley"
        ],
        "publication_date": "2022-05-17",
        "conference": "Annual Meeting of the Association for Computational Linguistics",
        "pages": "7287-7301",
        "description": "In this paper, we propose SkipBERT to accelerate BERT inference by skipping the computation of shallow layers. To achieve this, our approach encodes small text chunks into independent representations, which are then materialized to approximate the shallow representation of BERT. Since the use of such approximation is inexpensive compared with transformer calculations, we leverage it to replace the shallow layers of BERT to skip their runtime overhead. With off-the-shelf early exit mechanisms, we also skip redundant computation from the highest few layers to further improve inference efficiency. Results on GLUE show that our approach can reduce latency by 65% without sacrificing performance. By using only two-layer transformer calculations, we can still maintain 95% accuracy of BERT.",
        "total_citations": 21
      },
      {
        "title": "A review of modern recommender systems using generative models (gen-recsys)",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:X0DADzN9RKwC",
        "authors": [
          "Yashar Deldjoo",
          "Zhankui He",
          "Julian McAuley",
          "Anton Korikov",
          "Scott Sanner",
          "Arnau Ramisa",
          "Ren\u00e9 Vidal",
          "Maheswaran Sathiamoorthy",
          "Atoosa Kasirzadeh",
          "Silvia Milano"
        ],
        "publication_date": "2024-08-25",
        "pages": "6448-6458",
        "description": "Traditional recommender systems typically use user-item rating histories as their main data source. However, deep generative models now have the capability to model and sample from complex data distributions, including user-item interactions, text, images, and videos, enabling novel recommendation tasks. This comprehensive, multidisciplinary survey connects key advancements in RS using Generative Models (Gen-RecSys), covering: interaction-driven generative models; the use of large language models (LLM) and textual data for natural language recommendation; and the integration of multimodal models for generating and processing images/videos in RS. Our work highlights necessary paradigms for evaluating the impact and harm of Gen-RecSys and identifies open challenges. This survey accompanies a \"tutorial\" presented at ACM KDD'24, with supporting materials provided at: https://encr.pw/vDhLq.",
        "total_citations": 20
      },
      {
        "title": "Robust and interpretable medical image classifiers via concept bottleneck models",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:eGYfIraVYiQC",
        "authors": [
          "An Yan",
          "Yu Wang",
          "Yiwu Zhong",
          "Zexue He",
          "Petros Karypis",
          "Zihan Wang",
          "Chengyu Dong",
          "Amilcare Gentili",
          "Chun-Nan Hsu",
          "Jingbo Shang",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-04",
        "description": "Medical image classification is a critical problem for healthcare, with the potential to alleviate the workload of doctors and facilitate diagnoses of patients. However, two challenges arise when deploying deep learning models to real-world healthcare applications. First, neural models tend to learn spurious correlations instead of desired features, which could fall short when generalizing to new domains (e.g., patients with different ages). Second, these black-box models lack interpretability. When making diagnostic predictions, it is important to understand why a model makes a decision for trustworthy and safety considerations. In this paper, to address these two limitations, we propose a new paradigm to build robust and interpretable medical image classifiers with natural language concepts. Specifically, we first query clinical concepts from GPT-4, then transform latent image features into explicit concepts with a vision-language model. We systematically evaluate our method on eight medical image classification datasets to verify its effectiveness. On challenging datasets with strong confounding factors, our method can mitigate spurious correlations thus substantially outperform standard visual encoders and other baselines. Finally, we show how classification with a small number of concepts brings a level of interpretability for understanding model decisions through case studies in real medical data.",
        "total_citations": 20
      },
      {
        "title": "CLIPSep: Learning Text-queried Sound Separation with Noisy Unlabeled Videos",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:pS0ncopqnHgC",
        "authors": [
          "Hao-Wen Dong",
          "Naoya Takahashi",
          "Yuki Mitsufuji",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick"
        ],
        "publication_date": "2023-10-17",
        "conference": "ICLR",
        "description": "Recent years have seen progress beyond domain-specific sound separation for speech or music towards universal sound separation for arbitrary sounds. Prior work on universal sound separation has investigated separating a target sound out of an audio mixture given a text query. Such text-queried sound separation systems provide a natural and scalable interface for specifying arbitrary target sounds. However, supervised text-queried sound separation systems require costly labeled audio-text pairs for training. Moreover, the audio provided in existing datasets is often recorded in a controlled environment, causing a considerable generalization gap to noisy audio in the wild. In this work, we aim to approach text-queried universal sound separation by using only unlabeled data. We propose to leverage the visual modality as a bridge to learn the desired audio-textual correspondence. The proposed CLIPSep model first encodes the input query into a query vector using the contrastive language-image pretraining (CLIP) model, and the query vector is then used to condition an audio separation model to separate out the target sound. While the model is trained on image-audio pairs extracted from unlabeled videos, at test time we can instead query the model with text inputs in a zero-shot setting, thanks to the joint language-image embedding learned by the CLIP model. Further, videos in the wild often contain off-screen sounds and background noise that may hinder the model from learning the desired audio-textual correspondence. To address this problem, we further propose an approach called noise invariant training for training a query-based\u00a0\u2026",
        "total_citations": 20
      },
      {
        "title": "AI-moderated decision-making: Capturing and balancing anchoring bias in sequential decision tasks",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:yxmsSjX2EkcC",
        "authors": [
          "Jessica Maria Echterhoff",
          "Matin Yarmand",
          "Julian McAuley"
        ],
        "publication_date": "2022-04-27",
        "conference": "CHI Conference on Human Factors in Computing Systems",
        "description": "Decision-making involves biases from past experiences, which are difficult to perceive and eliminate. We investigate a specific type of anchoring bias, in which decision-makers are anchored by their own recent decisions, e.g.\u00a0a college admission officer sequentially reviewing students. We propose an algorithm that identifies existing anchored decisions, reduces sequential dependencies to previous decisions, and mitigates decision inaccuracies post-hoc with 2% increased agreement to ground-truth on a large-scale college admission decision data set. A crowd-sourced study validates this algorithm on product preferences (5% increased agreement). To avoid biased decisions ex-ante, we propose a procedure that presents instances in an order that reduces anchoring bias in real-time. Tested in another crowd-sourced study, it reduces bias and increases agreement to ground-truth by 7%. Our work reinforces\u00a0\u2026",
        "total_citations": 20
      },
      {
        "title": "Optimization of robust loss functions for weakly-labeled image taxonomies",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:Se3iqnhoufwC",
        "authors": [
          "Julian J McAuley",
          "Arnau Ramisa",
          "Tib\u00e9rio S Caetano"
        ],
        "publication_date": "2012-10-17",
        "pages": "1-19",
        "publisher": "Springer Netherlands",
        "description": " The recently proposed ImageNet dataset consists of several million images, each annotated with a single object category. These annotations may be imperfect, in the sense that many images contain multiple objects belonging to the label vocabulary. In other words, we have a multi-label problem but the annotations include only a single label (which is not necessarily the most prominent). Such a setting motivates the use of a robust evaluation measure, which allows for a limited number of labels to be predicted and, so long as one of the predicted labels is correct, the overall prediction should be considered correct. This is indeed the type of evaluation measure used to assess algorithm performance in a recent competition on ImageNet data. Optimizing such types of performance measures presents several hurdles even with existing structured output learning methods. Indeed, many of the current state-of-the\u00a0\u2026",
        "total_citations": 20
      },
      {
        "title": "Exploiting within-clique factorizations in junction-tree algorithms",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:7PzlFSSx8tAC",
        "authors": [
          "Julian John McAuley",
          "Tib\u00e9rio S Caetano"
        ],
        "publication_date": "2010-10-17",
        "conference": "AISTATS",
        "pages": "525-532",
        "description": "We show that the expected computational complexity of the Junction-Tree Algorithm for maximum a posteriori inference in graphical models can be improved. Our results apply whenever the potentials over maximal cliques of the triangulated graph are factored over subcliques. This is common in many real applications, as we illustrate with several examples. The new algorithms are easily implemented, and experiments show substantial speed-ups over the classical Junction-Tree Algorithm. This enlarges the class of models for which exact inference is efficient.",
        "total_citations": 19
      },
      {
        "title": "Cognitive bias in high-stakes decision-making with LLMs",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:nPT8s1NX_-sC",
        "authors": [
          "Jessica Echterhoff",
          "Yao Liu",
          "Abeer Alessa",
          "Julian McAuley",
          "Zexue He"
        ],
        "publication_date": "2024-02-25",
        "description": "Large language models (LLMs) offer significant potential as tools to support an expanding range of decision-making tasks. However, given their training on human (created) data, LLMs can inherit both societal biases against protected groups, as well as be subject to cognitive bias. Such human-like bias can impede fair and explainable decisions made with LLM assistance. Our work introduces BiasBuster, a framework designed to uncover, evaluate, and mitigate cognitive bias in LLMs, particularly in high-stakes decision-making tasks. Inspired by prior research in psychology and cognitive sciences, we develop a dataset containing 16,800 prompts to evaluate different cognitive biases (e.g., prompt-induced, sequential, inherent). We test various bias mitigation strategies, amidst proposing a novel method using LLMs to debias their own prompts. Our analysis provides a comprehensive picture on the presence and effects of cognitive bias across different commercial and open-source models. We demonstrate that our self-help debiasing effectively mitigate cognitive bias without having to manually craft examples for each bias type.",
        "total_citations": 18
      },
      {
        "title": "Linear Recurrent Units for sequential recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:0aBXIfxlw9sC",
        "authors": [
          "Zhenrui Yue",
          "Yueqi Wang",
          "Zhankui He",
          "Huimin Zeng",
          "Julian McAuley",
          "Dong Wang"
        ],
        "publication_date": "2024-10-17",
        "conference": "Web Search and Data Mining",
        "description": "State-of-the-art sequential recommendation relies heavily on self-attention-based recommender models. Yet such models are computationally expensive and often too slow for real-time recommendation. Furthermore, the self-attention operation is performed at a sequence-level, thereby making low-cost incremental inference challenging. Inspired by recent advances in efficient language modeling, we propose linear recurrent units for sequential recommendation (LRURec). Similar to recurrent neural networks, LRURec offers rapid inference and can achieve incremental inference on sequential inputs. By decomposing the linear recurrence operation and designing recursive parallelization in our framework, LRURec provides the additional benefits of reduced model size and parallelizable training. Moreover, we optimize the architecture of LRURec by implementing a series of modifications to address the lack of non\u00a0\u2026",
        "total_citations": 18
      },
      {
        "title": "Query-aware sequential recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:O0nohqN1r9EC",
        "authors": [
          "Zhankui He",
          "Handong Zhao",
          "Zhaowen Wang",
          "Zhe Lin",
          "Ajinkya Kale",
          "Julian Mcauley"
        ],
        "publication_date": "2022-10-17",
        "conference": "CIKM",
        "pages": "4019-4023",
        "description": "Sequential recommenders aim to capture users' dynamic interests from their historical action sequences, but remain challenging due to data sparsity issues, as well as the noisy and complex relationships among items in a sequence. Several approaches have sought to alleviate these issues using side-information, such as item content (e.g., images), action types (e.g., click, purchase). While useful, we argue one of the main contextual signals is largely ignored-namely users' queries. When users browse and consume products (e.g., music, movies), their sequential interactions are usually a combination of queries, clicks (etc.). Most interaction datasets discard queries, and corresponding methods simply model sequential behaviors over items and thus ignore this critical context of user interactions. In this work, we argue that user queries should be an important contextual cue for sequential recommendation. First, we\u00a0\u2026",
        "total_citations": 18
      },
      {
        "title": "Leashing the Inner Demons: Self-detoxification for language models",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:owLR8QvbtFgC",
        "authors": [
          "Canwen Xu",
          "Zexue He",
          "Zhankui He",
          "Julian McAuley"
        ],
        "publication_date": "2022-03-06",
        "conference": "AAAI Conference on Artificial Intelligence",
        "description": "Language models (LMs) can reproduce (or amplify) toxic language seen during training, which poses a risk to their practical application. In this paper, we conduct extensive experiments to study this phenomenon. We analyze the impact of prompts, decoding strategies and training corpora on the output toxicity. Based on our findings, we propose a simple yet effective unsupervised method for language models to``detoxify''themselves without an additional large corpus or external discriminator. Compared to a supervised baseline, our proposed method shows better toxicity reduction with good generation quality in the generated content under multiple settings. Warning: some examples shown in the paper may contain uncensored offensive content.",
        "total_citations": 18
      },
      {
        "title": "Shape classification through structured learning of matching measures",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:2osOgNQ5qMEC",
        "authors": [
          "Longbin Chen",
          "Julian J McAuley",
          "Rogerio S Feris",
          "Tib\u00e9rio S Caetano",
          "Matthew Turk"
        ],
        "publication_date": "2009-06-20",
        "conference": "Computer Vision and Pattern Recognition. IEEE Conference on",
        "pages": "365-372",
        "publisher": "IEEE",
        "description": "Many traditional methods for shape classification involve establishing point correspondences between shapes to produce matching scores, which are in turn used as similarity measures for classification. Learning techniques have been applied only in the second stage of this process, after the matching scores have been obtained. In this paper, instead of simply taking for granted the scores obtained by matching and then learning a classifier, we learn the matching scores themselves so as to produce shape similarity scores that minimize the classification loss. The solution is based on a max-margin formulation in the structured prediction setting. Experiments in shape databases reveal that such an integrated learning algorithm substantially improves on existing methods.",
        "total_citations": 18
      },
      {
        "title": "Crowd entity resolution interfaces",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:nRpfm8aw39MC",
        "authors": [
          "Steven Euijong Whang",
          "Julian McAuley",
          "Hector Garcia-Molina"
        ],
        "publication_date": "2012-10-17",
        "publisher": "Stanford InfoLab",
        "description": "We study the problem of enhancing entity resolution (ER) with the help of crowdsourcing. ER is the problem of identifying records that refer to the same real-world entity and can be an extremely difficult process for computer algorithms alone. For example, figuring out which images refer to the same person can be a hard task for computers, but an easy one for humans. An important component of crowdsourcing is the interface that is used for human and algorithm interaction. In this paper, we explore how the interface design along with other factors impact the human quality of comparing records. We also propose a model for separating good human workers from bad workers. Our analysis is based on extensive experiments on Amazon Mechanical Turk using real and synthetic image datasets.",
        "total_citations": 17
      },
      {
        "title": "Ditto: Diffusion inference-time t-optimization for music generation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:mel-f30kHHgC",
        "authors": [
          "Zachary Novack",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick",
          "Nicholas J Bryan"
        ],
        "publication_date": "2024-01-22",
        "description": "We propose Diffusion Inference-Time T-Optimization (DITTO), a general-purpose frame-work for controlling pre-trained text-to-music diffusion models at inference-time via optimizing initial noise latents. Our method can be used to optimize through any differentiable feature matching loss to achieve a target (stylized) output and leverages gradient checkpointing for memory efficiency. We demonstrate a surprisingly wide-range of applications for music generation including inpainting, outpainting, and looping as well as intensity, melody, and musical structure control - all without ever fine-tuning the underlying model. When we compare our approach against related training, guidance, and optimization-based methods, we find DITTO achieves state-of-the-art performance on nearly all tasks, including outperforming comparable approaches on controllability, audio quality, and computational efficiency, thus opening the door for high-quality, flexible, training-free control of diffusion models. Sound examples can be found at https://DITTO-Music.github.io/web/.",
        "total_citations": 16
      },
      {
        "title": "SHARE: A system for hierarchical assistive recipe editing",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:7wO8s98CvbsC",
        "authors": [
          "Shuyang Li",
          "Yufei Li",
          "Jianmo Ni",
          "Julian McAuley"
        ],
        "publication_date": "2022-10-17",
        "conference": "EMNLP",
        "description": "The large population of home cooks with dietary restrictions is under-served by existing cooking resources and recipe generation models. To help them, we propose the task of controllable recipe editing: adapt a base recipe to satisfy a user-specified dietary constraint. This task is challenging, and cannot be adequately solved with human-written ingredient substitution rules or existing end-to-end recipe generation models. We tackle this problem with SHARE: a System for Hierarchical Assistive Recipe Editing, which performs simultaneous ingredient substitution before generating natural-language steps using the edited ingredients. By decoupling ingredient and step editing, our step generator can explicitly integrate the available ingredients. Experiments on the novel RecipePairs dataset -- 83K pairs of similar recipes where each recipe satisfies one of seven dietary constraints -- demonstrate that SHARE produces convincing, coherent recipes that are appropriate for a target dietary constraint. We further show through human evaluations and real-world cooking trials that recipes edited by SHARE can be easily followed by home cooks to create appealing dishes.",
        "total_citations": 16
      },
      {
        "title": "An empirical evaluation of end-to-end polyphonic optical music recognition",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:u-coK7KVo8oC",
        "authors": [
          "Sachinda Edirisooriya",
          "Hao-Wen Dong",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick"
        ],
        "publication_date": "2021-08-03",
        "conference": "International Society for Music Information Retrieval Conference",
        "description": "Previous work has shown that neural architectures are able to perform optical music recognition (OMR) on monophonic and homophonic music with high accuracy. However, piano and orchestral scores frequently exhibit polyphonic passages, which add a second dimension to the task. Monophonic and homophonic music can be described as homorhythmic, or having a single musical rhythm. Polyphonic music, on the other hand, can be seen as having multiple rhythmic sequences, or voices, concurrently. We first introduce a workflow for creating large-scale polyphonic datasets suitable for end-to-end recognition from sheet music publicly available on the MuseScore forum. We then propose two novel formulations for end-to-end polyphonic OMR -- one treating the problem as a type of multi-task binary classification, and the other treating it as multi-sequence detection. Building upon the encoder-decoder architecture and an image encoder proposed in past work on end-to-end OMR, we propose two novel decoder models -- FlagDecoder and RNNDecoder -- that correspond to the two formulations. Finally, we compare the empirical performance of these end-to-end approaches to polyphonic OMR and observe a new state-of-the-art performance with our multi-sequence detection decoder, RNNDecoder.",
        "total_citations": 16
      },
      {
        "title": "Exploiting explicit and implicit item relationships for session-based recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:mWEH9CqjF64C",
        "authors": [
          "Zihao Li",
          "Xianzhi Wang",
          "Chao Yang",
          "Lina Yao",
          "Julian McAuley",
          "Guandong Xu"
        ],
        "publication_date": "2023-02-27",
        "pages": "553-561",
        "description": "The session-based recommendation aims to predict users' immediate next actions based on their short-term behaviors reflected by past and ongoing sessions. Graph neural networks (GNNs) recently dominated the related studies, yet their performance heavily relies on graph structures, which are often predefined, task-specific, and designed heuristically. Furthermore, existing graph-based methods either neglect implicit correlations among items or consider explicit and implicit relationships altogether in the same graphs. We propose to decouple explicit and implicit relationships among items. As such, we can capture the prior knowledge encapsulated in explicit dependencies and learned implicit correlations among items simultaneously in a flexible and more interpretable manner for effective recommendations. We design a dual graph neural network that leverages the feature representations extracted by two\u00a0\u2026",
        "total_citations": 15
      },
      {
        "title": "Efficiently tuned parameters are task embeddings",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:SGW5VrABaM0C",
        "authors": [
          "Wangchunshu Zhou",
          "Canwen Xu",
          "Julian McAuley"
        ],
        "publication_date": "2022-10-17",
        "conference": "EMNLP",
        "description": "Intermediate-task transfer can benefit a wide range of NLP tasks with properly selected source datasets. However, it is computationally infeasible to experiment with all intermediate transfer combinations, making choosing a useful source task a challenging problem. In this paper, we anticipate that task-specific parameters updated in parameter-efficient tuning methods are likely to encode task-specific information. Therefore, such parameters can be predictive for inter-task transferability. Thus, we propose to exploit these efficiently tuned parameters as off-the-shelf task embeddings for the efficient selection of source datasets for intermediate-task transfer. We experiment with 11 text classification tasks and 11 question answering tasks. Experimental results show that our approach can consistently outperform existing inter-task transferability prediction methods while being conceptually simple and computationally efficient. Our analysis also reveals that the ability of efficiently tuned parameters on transferability prediction is disentangled with their in-task performance. This allows us to use parameters from early checkpoints as task embeddings to further improve efficiency.",
        "total_citations": 15
      },
      {
        "title": "Developing a recommendation benchmark for MLPerf training and inference",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:9pM33mqn1YgC",
        "authors": [
          "Carole-Jean Wu",
          "Robin Burke",
          "Ed Chi",
          "Joseph Konstan",
          "Julian McAuley",
          "Yves Raimond",
          "Hao Zhang"
        ],
        "publication_date": "2020-03-16",
        "description": "Deep learning-based recommendation models are used pervasively and broadly, for example, to recommend movies, products, or other information most relevant to users, in order to enhance the user experience. Among various application domains which have received significant industry and academia research attention, such as image classification, object detection, language and speech translation, the performance of deep learning-based recommendation models is less well explored, even though recommendation tasks unarguably represent significant AI inference cycles at large-scale datacenter fleets. To advance the state of understanding and enable machine learning system development and optimization for the commerce domain, we aim to define an industry-relevant recommendation benchmark for the MLPerf Training andInference Suites. The paper synthesizes the desirable modeling strategies for personalized recommendation systems. We lay out desirable characteristics of recommendation model architectures and data sets. We then summarize the discussions and advice from the MLPerf Recommendation Advisory Board.",
        "total_citations": 15
      },
      {
        "title": "Generative flow network for listwise recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:CYCckWUYoCcC",
        "authors": [
          "Shuchang Liu",
          "Qingpeng Cai",
          "Zhankui He",
          "Bowen Sun",
          "Julian McAuley",
          "Dong Zheng",
          "Peng Jiang",
          "Kun Gai"
        ],
        "publication_date": "2023-10-17",
        "conference": "KDD",
        "pages": "1524-1534",
        "description": "Personalized recommender systems fulfill the daily demands of customers and boost online businesses. The goal is to learn a policy that can generate a list of items that matches the user's demand or interest. While most existing methods learn a pointwise scoring model that predicts the ranking score of each individual item, recent research shows that the listwise approach can further improve the recommendation quality by modeling the intra-list correlations of items that are exposed together. This has motivated the recent list reranking and generative recommendation approaches that optimize the overall utility of the entire list. However, it is challenging to explore the combinatorial space of list actions and existing methods that use cross-entropy loss may suffer from low diversity issues. In this work, we aim to learn a policy that can generate sufficiently diverse item lists for users while maintaining high\u00a0\u2026",
        "total_citations": 14
      },
      {
        "title": "InforMask: Unsupervised informative masking for language model pretraining",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:2l5NCbZemmgC",
        "authors": [
          "Nafis Sadeq",
          "Canwen Xu",
          "Julian McAuley"
        ],
        "publication_date": "2022-10-17",
        "conference": "EMNLP",
        "description": "Masked language modeling is widely used for pretraining large language models for natural language understanding (NLU). However, random masking is suboptimal, allocating an equal masking rate for all tokens. In this paper, we propose InforMask, a new unsupervised masking strategy for training masked language models. InforMask exploits Pointwise Mutual Information (PMI) to select the most informative tokens to mask. We further propose two optimizations for InforMask to improve its efficiency. With a one-off preprocessing step, InforMask outperforms random masking and previously proposed masking strategies on the factual recall benchmark LAMA and the question answering benchmark SQuAD v1 and v2.",
        "total_citations": 14
      },
      {
        "title": "Unified graph matching in euclidean spaces",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:W7OEmFMy1HYC",
        "authors": [
          "Julian J McAuley",
          "Te\u00f3filo de Campos",
          "Tib\u00e9rio S Caetano"
        ],
        "publication_date": "2010-10-17",
        "conference": "Computer Vision and Pattern Recognition, IEEE Conference on",
        "pages": "1871-1878",
        "publisher": "IEEE",
        "description": "Graph matching is a classical problem in pattern recognition with many applications, particularly when the graphs are embedded in Euclidean spaces, as is often the case for computer vision. There are several variants of the matching problem, concerned with isometries, isomorphisms, homeomorphisms, and node attributes; different approaches exist for each variant. We show how structured estimation methods from machine learning can be used to combine such variants into a single version of graph matching. In this paradigm, the extent to which our datasets reveal isometries, isomorphisms, homeomorphisms, and other properties is automatically accounted for in the learning process so that any such specific qualification of graph matching loses meaning. We present experiments with real computer vision data showing the leverage of this unified formulation.",
        "total_citations": 14
      },
      {
        "title": "Exploiting data-independence for fast belief-propagation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:UeHWp8X0CEIC",
        "authors": [
          "Julian McAuley",
          "Tiberio Caetano"
        ],
        "publication_date": "2010-10-17",
        "pages": "767-774",
        "description": "Maximum a posteriori (MAP) inference in graphical models requires that we maximize the sum of two terms: a data-dependent term, encoding the conditional likelihood of a certain labeling given an observation, and a data-independent term, encoding some prior on labelings. Often, data-dependent factors contain fewer latent variables than dataindependent factors\u2013for instance, many grid and tree-structured models contain only firstorder conditionals despite having pairwise priors. In this paper, we note that MAP-inference in such models can be made substantially faster by appropriately preprocessing their data-independent terms. Our main result is to show that message-passing in any such pairwise model has an expected-case exponent of only 1.5 on the number of states per node, leading to significant improvements over existing quadratic-time solutions.",
        "total_citations": 14
      },
      {
        "title": "CLIPSonic: Text-to-audio synthesis with unlabeled videos and pretrained language-vision models",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:g5Ck-dwhA_QC",
        "authors": [
          "Hao-Wen Dong",
          "Xiaoyu Liu",
          "Jordi Pons",
          "Gautam Bhattacharya",
          "Santiago Pascual",
          "Joan Serr\u00e0",
          "Taylor Berg-Kirkpatrick",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-17",
        "conference": "IEEE Workshop on Applications of Signal Processing to Audio and Acoustics",
        "description": "Recent work has studied text-to-audio synthesis using large amounts of paired text-audio data. However, audio recordings with high-quality text annotations can be difficult to acquire. In this work, we approach text-to-audio synthesis using unlabeled videos and pre-trained language-vision models. We propose to learn the desired text-audio correspondence by leveraging the visual modality as a bridge. We train a conditional diffusion model to generate the audio track of a video, given a video frame encoded by a pretrained contrastive language-image pretraining (CLIP) model. At test time, we first explore performing a zero-shot modality transfer and condition the diffusion model with a CLIP-encoded text query. However, we observe a noticeable performance drop with respect to image queries. To close this gap, we further adopt a pretrained diffusion prior model to generate a CLIP image embedding given a CLIP\u00a0\u2026",
        "total_citations": 13
      },
      {
        "title": "Blow the Dog Whistle: A Chinese dataset for cant understanding with common sense and world knowledge",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:yFnVuubrUp4C",
        "authors": [
          "Canwen Xu",
          "Wangchunshu Zhou",
          "Tao Ge",
          "Ke Xu",
          "Julian McAuley",
          "Furu Wei"
        ],
        "publication_date": "2021-10-17",
        "conference": "North American Chapter of the Association for Computational Linguistics",
        "description": "Cant is important for understanding advertising, comedies and dog-whistle politics. However, computational research on cant is hindered by a lack of available datasets. In this paper, we propose a large and diverse Chinese dataset for creating and understanding cant from a computational linguistics perspective. We formulate a task for cant understanding and provide both quantitative and qualitative analysis for tested word embedding similarity and pretrained language models. Experiments suggest that such a task requires deep language understanding, common sense, and world knowledge and thus can be a good testbed for pretrained language models and help models perform better on other tasks. The code is available at https://github.com/JetRunner/dogwhistle. The data and leaderboard are available at https://competitions.codalab.org/competitions/30451.",
        "total_citations": 13
      },
      {
        "title": "The performance of an artificial neural network model in predicting the early distribution kinetics of propofol in morbidly obese and lean subjects",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:86PQX7AUzd4C",
        "authors": [
          "Jerry Ingrande",
          "Rodney A Gabriel",
          "Julian McAuley",
          "Karolina Krasinska",
          "Allis Chien",
          "Hendrikus JM Lemmens"
        ],
        "publication_date": "2020-05-29",
        "publisher": "LWW",
        "description": "A gated recurrent unit neural network had similar performance to a recirculatory model, and both had superior performance to a compartmental model in predicting the early distribution kinetics of propofol.",
        "total_citations": 13
      },
      {
        "title": "Robust near-isometric matching via structured learning of graphical models",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:e5wmG9Sq2KIC",
        "authors": [
          "Julian J Mcauley",
          "Tib\u00e9rio S Caetano",
          "Alex J Smola"
        ],
        "publication_date": "2008-10-17",
        "conference": "Neural Information Processing Systems",
        "pages": "1057-1064",
        "description": "Models for near-rigid shape matching are typically based on distance-related features, in order to infer matches that are consistent with the isometric assumption. However, real shapes from image datasets, even when expected to be related by \"almost isometric\" transformations, are actually subject not only to noise but also, to some limited degree, to variations in appearance and scale. In this paper, we introduce a graphical model that parameterises appearance, distance, and angle features and we learn all of the involved parameters via structured prediction. The outcome is a model for near-rigid shape matching which is robust in the sense that it is able to capture the possibly limited but still important scale and appearance variations. Our experimental results reveal substantial improvements upon recent successful models, while maintaining similar running times.",
        "total_citations": 13
      },
      {
        "title": "Self-supervised bot play for transcript-free conversational recommendation with rationales",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:6bLC7aUMtPcC",
        "authors": [
          "Shuyang Li",
          "Bodhisattwa Prasad Majumder",
          "Julian McAuley"
        ],
        "publication_date": "2022-10-17",
        "conference": "RecSys",
        "description": " Conversational recommender systems offer a way for users to engage in multi-turn conversations to find items they enjoy. For users to trust an agent and give effective feedback, the recommender system must be able to explain its suggestions and rationales. We develop a two-part framework for training multi-turn conversational recommenders that provide recommendation rationales that users can effectively interact with to receive better recommendations. First, we train a recommender system to jointly suggest items and explain its reasoning via subjective rationales. We then fine-tune this model to incorporate iterative user feedback via self-supervised bot-play. Experiments on three real-world datasets demonstrate that our system can be applied to different recommendation models across diverse domains to achieve state-of-the-art performance in multi-turn recommendation. Human studies show that systems\u00a0\u2026",
        "total_citations": 12
      },
      {
        "title": "Locality-sensitive state-guided experience replay optimization for sparse rewards in online recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:1yWc8FF-_SYC",
        "authors": [
          "Xiaocong Chen",
          "Lina Yao",
          "Julian McAuley",
          "Weili Guan",
          "Xiaojun Chang",
          "Xianzhi Wang"
        ],
        "publication_date": "2022-10-17",
        "conference": "SIGIR",
        "description": "Online recommendation requires handling rapidly changing user preferences. Deep reinforcement learning (DRL) is an effective means of capturing users' dynamic interest during interactions with recommender systems. Generally, it is challenging to train a DRL agent in online recommender systems because of the sparse rewards caused by the large action space (e.g., candidate item space) and comparatively fewer user interactions. Leveraging experience replay (ER) has been extensively studied to conquer the issue of sparse rewards. However, they adapt poorly to the complex environment of online recommender systems and are inefficient in learning an optimal strategy from past experience. As a step to filling this gap, we propose a novel state-aware experience replay model, in which the agent selectively discovers the most relevant and salient experiences and is guided to find the optimal policy for online\u00a0\u2026",
        "total_citations": 12
      },
      {
        "title": "One-class recommendation with asymmetric textual feedback",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:P5F9QuxV20EC",
        "authors": [
          "Mengting Wan",
          "Julian McAuley"
        ],
        "publication_date": "2018-10-17",
        "conference": "SIAM International Conference on Data Mining",
        "description": " Personalized ranking with implicit feedback (e.g. purchases, views, check-ins) is an important paradigm in recommender systems. Such feedback sometimes comes with textual information (e.g. reviews, comments, tips), which could be a useful signal to reveal item properties, identify users' tastes and interpret their behavior. Although incorporating such information is common in explicit feedback settings (such as rating prediction), it is less common when dealing with implicit feedback, as it is often not available for negative instances (e.g. there is no review associated with the item the user didn't buy). Thus our goal in this study is to propose a ranking method (PRAST) to incorporate such personalized, asymmetric textual signals in implicit feedback settings. We evaluate our model on two real-world datasets. Quantitative and qualitative results indicate that the proposed approach significantly outperforms standard\u00a0\u2026",
        "total_citations": 12
      },
      {
        "title": "Foundation models for recommender systems: A survey and new perspectives",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:BJrgspguQaEC",
        "authors": [
          "Chengkai Huang",
          "Tong Yu",
          "Kaige Xie",
          "Shuai Zhang",
          "Lina Yao",
          "Julian McAuley"
        ],
        "publication_date": "2024-02-17",
        "description": "Recently, Foundation Models (FMs), with their extensive knowledge bases and complex architectures, have offered unique opportunities within the realm of recommender systems (RSs). In this paper, we attempt to thoroughly examine FM-based recommendation systems (FM4RecSys). We start by reviewing the research background of FM4RecSys. Then, we provide a systematic taxonomy of existing FM4RecSys research works, which can be divided into four different parts including data characteristics, representation learning, model type, and downstream tasks. Within each part, we review the key recent research developments, outlining the representative models and discussing their characteristics. Moreover, we elaborate on the open problems and opportunities of FM4RecSys aiming to shed light on future research directions in this area. In conclusion, we recap our findings and discuss the emerging trends in this field.",
        "total_citations": 11
      },
      {
        "title": "Reinforcement learning for generative AI: A survey",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:wE-fMHVdjMkC",
        "authors": [
          "Yuanjiang Cao",
          "Quan Z Sheng",
          "Julian McAuley",
          "Lina Yao"
        ],
        "publication_date": "2023-08-28",
        "description": "Deep Generative AI has been a long-standing essential topic in the machine learning community, which can impact a number of application areas like text generation and computer vision. The major paradigm to train a generative model is maximum likelihood estimation, which pushes the learner to capture and approximate the target data distribution by decreasing the divergence between the model distribution and the target distribution. This formulation successfully establishes the objective of generative tasks, while it is incapable of satisfying all the requirements that a user might expect from a generative model. Reinforcement learning, serving as a competitive option to inject new training signals by creating new objectives that exploit novel signals, has demonstrated its power and flexibility to incorporate human inductive bias from multiple angles, such as adversarial learning, hand-designed rules and learned reward model to build a performant model. Thereby, reinforcement learning has become a trending research field and has stretched the limits of generative AI in both model design and application. It is reasonable to summarize and conclude advances in recent years with a comprehensive review. Although there are surveys in different application areas recently, this survey aims to shed light on a high-level review that spans a range of application areas. We provide a rigorous taxonomy in this area and make sufficient coverage on various models and applications. Notably, we also surveyed the fast-developing large language model area. We conclude this survey by showing the potential directions that might tackle the limit of current\u00a0\u2026",
        "total_citations": 11
      },
      {
        "title": "SPOT: Knowledge-enhanced language representations for information extraction",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:ce2CqMG-AY4C",
        "authors": [
          "Jiacheng Li",
          "Yannis Katsis",
          "Tyler Baldwin",
          "Ho-Cheol Kim",
          "Andrew Bartko",
          "Julian McAuley",
          "Chun-Nan Hsu"
        ],
        "publication_date": "2022-08-20",
        "conference": "CIKM",
        "description": "Knowledge-enhanced pre-trained models for language representation have been shown to be more effective in knowledge base construction tasks (i.e.,~relation extraction) than language models such as BERT. These knowledge-enhanced language models incorporate knowledge into pre-training to generate representations of entities or relationships. However, existing methods typically represent each entity with a separate embedding. As a result, these methods struggle to represent out-of-vocabulary entities and a large amount of parameters, on top of their underlying token models (i.e., the transformer), must be used and the number of entities that can be handled is limited in practice due to memory constraints. Moreover, existing models still struggle to represent entities and relationships simultaneously. To address these problems, we propose a new pre-trained model that learns representations of both\u00a0\u2026",
        "total_citations": 11
      },
      {
        "title": "Application of machine learning to understand child marriage in India",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:IUKN3-7HHlwC",
        "authors": [
          "Anita Raj",
          "Nabamallika Dehingia",
          "Abhishek Singh",
          "Lotus McDougal",
          "Julian McAuley"
        ],
        "publication_date": "2020-12-01",
        "pages": "100687",
        "publisher": "Elsevier",
        "description": "BackgroundPrior research documents that India has the greatest number of girls married as minors of any nation in the world, increasing social and health risks for both these young wives and their children. While the prevalence of child marriage has declined in the nation, more work is needed to accelerate this decline and the negative consequences of the practice. Expanded targets for intervention require greater identification of these targets. Machine learning can offer insight into identification of novel factors associated with child marriage that can serve as targets for intervention.MethodsWe applied machine learning methods to retrospective cross-sectional survey data from India on demographics and health, the nationally-representative National Family Health Survey, conducted in 2015\u201316. We analyzed data using a traditional regression model, with child marriage as the dependent variable, and 4000\u00a0\u2026",
        "total_citations": 11
      },
      {
        "title": "Fashionista: a fashion-aware graphical system for exploring visually similar items",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:ns9cj8rnVeAC",
        "authors": [
          "Ruining He",
          "Chunbin Lin",
          "Julian McAuley"
        ],
        "publication_date": "2016-10-17",
        "conference": "World Wide Web (demo track)",
        "description": "To build a fashion recommendation system, we need to help users retrieve fashionable items that are visually similar to a particular query, for reasons ranging from searching alternatives (i.e., substitutes), to generating stylish outfits that are visually consistent, among other applications. In domains like clothing and accessories, such considerations are particularly paramount as the visual appearance of items is a critical feature that guides users' decisions. However, existing systems like Amazon and eBay still rely mainly on keyword search and recommending loosely consistent items (e.g. based on co-purchasing or browsing data), without an interface that makes use of visual information to serve the above needs. In this paper, we attempt to fill this gap by designing and implementing an image-based query system, called Fashionista, which provides a graphical interface to help users efficiently explore those items\u00a0\u2026",
        "total_citations": 11
      },
      {
        "title": "Unified graph matching in euclidean spaces and applications to image comparison and retrieval",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:UHK10RUVsp4C",
        "publication_date": "2013-03-26",
        "description": "(57) ABSTRACT A first graph embedded in a Euclidean space is modeled by a globally rigid first model graph that includes all vertices and edges of the first graph and has a preselected maximum clique size. The modeling is configured to maintain the preselected maximum clique size by employing an edge adding process that replicates a vertex of a vertex pair connected by an edge. A mapping between vertices of the first graph and Vertices of a second graph is computed by optimizing a mapping between vertices of the first model graph and vertices of the Second graph.",
        "total_citations": 11
      },
      {
        "title": "M4: A Multi-level, Multi-task, and Multi-domain Medical benchmark for language model evaluation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:qE4H1tSSYIIC",
        "authors": [
          "Zexue He",
          "Yu Wang",
          "An Yan",
          "Yao Liu",
          "Eric Y Chang",
          "Amilcare Gentili",
          "Julian McAuley",
          "Chun-Nan Hsu"
        ],
        "publication_date": "2023-10-17",
        "conference": "EMNLP",
        "total_citations": 10
      },
      {
        "title": "Rethink, Revisit, Revise: A spiral reinforced self-revised network for zero-shot learning",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:FiytvqdAVhgC",
        "authors": [
          "Zhe Liu",
          "Yun Li",
          "Lina Yao",
          "Julian McAuley",
          "Sam Dixon"
        ],
        "publication_date": "2022-05-27",
        "publisher": "IEEE",
        "description": "Current approaches to zero-shot learning (ZSL) struggle to learn generalizable semantic knowledge capable of capturing complex correlations. Inspired by Spiral Curriculum, which enhances learning processes by revisiting knowledge, we propose a form of spiral learning that revisits visual representations based on a sequence of attribute groups (e.g., a combined group of color and shape). Spiral learning aims to learn generalized local correlations, enabling models to gradually enhance global learning and, thus, understand complex correlations. Our implementation is based on a two-stage reinforced self-revised (RSR) framework: preview and review. RSR first previews visual information to construct diverse attribute groups in a weakly supervised manner. Then, it spirally learns refined localities based on attribute groups and uses localities to revise global semantic correlations. Our framework outperforms state\u00a0\u2026",
        "total_citations": 10
      },
      {
        "title": "Achieving conversational goals with unsupervised post-hoc knowledge injection",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:jU7OWUQzBzMC",
        "authors": [
          "Bodhisattwa Prasad Majumder",
          "Harsh Jhamtani",
          "Taylor Berg-Kirkpatrick",
          "Julian McAuley"
        ],
        "publication_date": "2022-03-22",
        "conference": "Annual Meeting of the Association for Computational Linguistics",
        "description": "A limitation of current neural dialog models is that they tend to suffer from a lack of specificity and informativeness in generated responses, primarily due to dependence on training data that covers a limited variety of scenarios and conveys limited knowledge. One way to alleviate this issue is to extract relevant knowledge from external sources at decoding time and incorporate it into the dialog response. In this paper, we propose a post-hoc knowledge-injection technique where we first retrieve a diverse set of relevant knowledge snippets conditioned on both the dialog history and an initial response from an existing dialog model. We construct multiple candidate responses, individually injecting each retrieved snippet into the initial response using a gradient-based decoding method, and then select the final response with an unsupervised ranking step. Our experiments in goal-oriented and knowledge-grounded dialog settings demonstrate that human annotators judge the outputs from the proposed method to be more engaging and informative compared to responses from prior dialog systems. We further show that knowledge-augmentation promotes success in achieving conversational goals in both experimental settings.",
        "total_citations": 10
      },
      {
        "title": "Bartering books to beers: a recommender system for exchange platforms",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:M05iB0D1s5AC",
        "authors": [
          "J\u00e9r\u00e9mie Rappaz",
          "Maria-Luiza Vladarean",
          "Julian McAuley",
          "Michele Catasta"
        ],
        "publication_date": "2017-10-17",
        "conference": "Web Search and Data Mining",
        "description": "Bartering is a timeless practice that is becoming increasingly popular on the Web. Recommending trades for an online bartering platform shares many similarities with traditional approaches to recommendation, in particular the need to model the preferences of users and the properties of the items they consume. However, there are several aspects that make bartering problems interesting and challenging, specifically the fact that users are both suppliers and consumers, and that the trading environment is highly dynamic. Thus, a successful model of bartering requires us to understand not just users' preferences, but also the social dynamics of who trades with whom, and the temporal dynamics of when trades occur. We propose new models for bartering-based recommendation, for which we introduce three novel datasets from online bartering platforms. Surprisingly, we find that existing methods (based on matching\u00a0\u2026",
        "total_citations": 10
      },
      {
        "title": "Faster graphical models for point-pattern matching.",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:zYLM7Y9cAGgC",
        "authors": [
          "Tiberio S Caetano",
          "Julian J McAuley"
        ],
        "publication_date": "2009-09-01",
        "description": "It has been shown that isometric matching problems can be solved exactly in polynomial time, by means of a Junction Tree with small maximal clique size. Recently, an iterative algorithm was presented which converges to the same solution an order of magnitude faster. Here, we build on both of these ideas to produce an algorithm with the same asymptotic running time as the iterative solution, but which requires only a single iteration of belief propagation. Thus our algorithm is much faster in practice, while maintaining similar error rates.",
        "total_citations": 10
      },
      {
        "title": "Hierarchical image-region labeling via structured learning",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:Y0pCki6q_DkC",
        "authors": [
          "Julian McAuley",
          "Teofilo Campos",
          "Gabriela Csurka",
          "Florent Perronin"
        ],
        "publication_date": "2009-10-17",
        "conference": "British Machine Vision Conference",
        "description": "Our output space is structured Our problem can be linearly parametrised The energy minimisation problem can be efficiently solved We can solve the column generation problem (usually due to a decomposable loss)",
        "total_citations": 10
      },
      {
        "title": "MemoryLLM: Towards self-updatable large language models",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:RtRctb2lSbAC",
        "authors": [
          "Yu Wang",
          "Xiusi Chen",
          "Jingbo Shang",
          "Julian McAuley"
        ],
        "publication_date": "2024-02-07",
        "description": "Existing Large Language Models (LLMs) usually remain static after deployment, which might make it hard to inject new knowledge into the model. We aim to build models containing a considerable portion of self-updatable parameters, enabling the model to integrate new knowledge effectively and efficiently. To this end, we introduce MEMORYLLM, a model that comprises a transformer and a fixed-size memory pool within the latent space of the transformer. MEMORYLLM can self-update with text knowledge and memorize the knowledge injected earlier. Our evaluations demonstrate the ability of MEMORYLLM to effectively incorporate new knowledge, as evidenced by its performance on model editing benchmarks. Meanwhile, the model exhibits long-term information retention capacity, which is validated through our custom-designed evaluations and long-context benchmarks. MEMORYLLM also shows operational integrity without any sign of performance degradation even after nearly a million memory updates.",
        "total_citations": 9
      },
      {
        "title": "Off-policy evaluation for large action spaces via policy convolution",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:AYInfyleIOsC",
        "authors": [
          "Noveen Sachdeva",
          "Lequn Wang",
          "Dawen Liang",
          "Nathan Kallus",
          "Julian McAuley"
        ],
        "publication_date": "2024-10-17",
        "conference": "WWW",
        "description": "Developing accurate off-policy estimators is crucial for both evaluating and optimizing for new policies. The main challenge in off-policy estimation is the distribution shift between the logging policy that generates data and the target policy that we aim to evaluate. Typically, techniques for correcting distribution shift involve some form of importance sampling. This approach results in unbiased value estimation but often comes with the trade-off of high variance. Furthermore, importance sampling relies on the common support assumption, which becomes impractical when the action space is large. To address these challenges, we introduce the Policy Convolution (PC) family of estimators for the contextual bandit setting. These methods leverage latent structure within actions---made available through action embeddings---to strategically convolve the logging and target policies. This convolution introduces a unique bias\u00a0\u2026",
        "total_citations": 9
      },
      {
        "title": "Ucepic: Unifying aspect planning and lexical constraints for generating explanations in recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:27LrP4qxOz0C",
        "authors": [
          "Jiacheng Li",
          "Zhankui He",
          "Jingbo Shang",
          "Julian McAuley"
        ],
        "publication_date": "2023-08-06",
        "pages": "1248-1257",
        "description": "Personalized natural language generation for explainable recommendations plays a key role in justifying why a recommendation might match a user's interests. Existing models usually control the generation process by aspect planning. While promising, these aspect-planning methods struggle to generate specific information correctly, which prevents generated explanations from being convincing. In this paper, we claim that introducing lexical constraints can alleviate the above issues. We propose a model, UCEpic, that generates high-quality personalized explanations for recommendation results by unifying aspect planning and lexical constraints in an insertion-based generation manner. Methodologically, to ensure text generation quality and robustness to various lexical constraints, we pre-train a non-personalized text generator via our proposed robust insertion process. Then, to obtain personalized\u00a0\u2026",
        "total_citations": 9
      },
      {
        "title": "Diversity-boosted generalization-specialization balancing for zero-shot learning",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:QUX0mv85b1cC",
        "authors": [
          "Yun Li",
          "Zhe Liu",
          "Xiaojun Chang",
          "Julian McAuley",
          "Lina Yao"
        ],
        "publication_date": "2023-01-11",
        "pages": "8372-8382",
        "publisher": "IEEE",
        "description": "Zero-Shot Learning (ZSL) aims to transfer classification capability from seen to unseen classes. Recent methods have proved that generalization and specialization are two essential abilities to achieve good performance in ZSL. However, focusing on only one of the abilities may result in models that are either too general with degraded classification ability or too specialized to generalize to unseen classes. In this article, we propose an end-to-end network, termed as BGSNet, which equips and balances generalization and specialization abilities at the instance and dataset level. Specifically, BGSNet consists of two branches: the Generalization Network (GNet), which applies episodic meta-learning to learn generalized knowledge, and the Balanced Specialization Network (BSNet), which adopts multiple attentive extractors to extract discriminative features and achieve instance-level balance. A novel self-adjusted\u00a0\u2026",
        "total_citations": 9
      },
      {
        "title": "Instilling type knowledge in language models via multi-task QA",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:Br1UauaknNIC",
        "authors": [
          "Shuyang Li",
          "Mukund Sridhar",
          "Chandana Satya Prakash",
          "Jin Cao",
          "Wael Hamza",
          "Julian McAuley"
        ],
        "publication_date": "2022-04-28",
        "conference": "Findings of NAACL",
        "description": "Understanding human language often necessitates understanding entities and their place in a taxonomy of knowledge -- their types. Previous methods to learn entity types rely on training classifiers on datasets with coarse, noisy, and incomplete labels. We introduce a method to instill fine-grained type knowledge in language models with text-to-text pre-training on type-centric questions leveraging knowledge base documents and knowledge graphs. We create the WikiWiki dataset: entities and passages from 10M Wikipedia articles linked to the Wikidata knowledge graph with 41K types. Models trained on WikiWiki achieve state-of-the-art performance in zero-shot dialog state tracking benchmarks, accurately infer entity types in Wikipedia articles, and can discover new types deemed useful by human judges.",
        "total_citations": 9
      },
      {
        "title": "Machine learning analysis of non-marital sexual violence in India",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:lvd772isFD0C",
        "authors": [
          "Anita Raj",
          "Nabamallika Dehingia",
          "Abhishek Singh",
          "Julian McAuley",
          "Lotus McDougal"
        ],
        "publication_date": "2021-10-17",
        "description": "BackgroundMachine learning techniques can explore low prevalence data to offer insight into identification of factors associated with non-marital sexual violence (NMSV). NMSV in India is a health and human rights concern that disproportionately affects adolescents, is under-reported, and not well understood or addressed in the country.MethodsWe applied machine learning methods to retrospective cross-sectional data from India's nationally-representative National Family Health Survey 4, a demographic and health study conducted in 2015\u201316, which offers 4000+ variables as potential independent variables. We used Least Absolute Shrinkage and Selection Operator (lasso) or L-1 regularized logistic regression models as well as L-2 regularized logistic regression or ridge models; we conducted an iterative thematic analysis (ITA) of variables generated from a series of regularized models.FindingsThematic\u00a0\u2026",
        "total_citations": 9
      },
      {
        "title": "Learning within-session budgets from browsing trajectories",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:vRqMK49ujn8C",
        "authors": [
          "Diane Hu",
          "Raphael Louca",
          "Liangjie Hong",
          "Julian McAuley"
        ],
        "publication_date": "2018-10-17",
        "conference": "ACM Conference on Recommender Systems",
        "description": "Building price- and budget-aware recommender systems is critical in settings where one wishes to produce recommendations that balance users' preferences (what they like) with a model of purchase likelihood (what they will buy). A trivial solution consists of learning global budget terms for each user based on their past expenditure. To more accurately model user budgets, we also consider a user's within-session budget, which may deviate from their global budget depending on their shopping context. In this paper, we find that users implicitly reveal their session-specific budgets through the sequence of items they browse within that session. Specifically, we find that some users \"browse down,\" by purchasing the cheapest item among alternatives under consideration, others \"browse up\" (selecting the most expensive), and others ultimately purchase items around the middle. Surprisingly, this mixture of behaviors is\u00a0\u2026",
        "total_citations": 9
      },
      {
        "title": "InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:YB4bud6kWLwC",
        "authors": [
          "Jianing Wang",
          "Junda Wu",
          "Yupeng Hou",
          "Yao Liu",
          "Ming Gao",
          "Julian McAuley"
        ],
        "publication_date": "2024-02-13",
        "description": "Do current large language models (LLMs) better solve graph reasoning and generation tasks with parameter updates? In this paper, we propose InstructGraph, a framework that empowers LLMs with the abilities of graph reasoning and generation by instruction tuning and preference alignment. Specifically, we first propose a structured format verbalizer to unify all graph data into a universal code-like format, which can simply represent the graph without any external graph-specific encoders. Furthermore, a graph instruction tuning stage is introduced to guide LLMs in solving graph reasoning and generation tasks. Finally, we identify potential hallucination problems in graph tasks and sample negative instances for preference alignment, the target of which is to enhance the output's reliability of the model. Extensive experiments across multiple graph-centric tasks exhibit that InstructGraph can achieve the best performance and outperform GPT-4 and LLaMA2 by more than 13\\% and 38\\%, respectively.",
        "total_citations": 8
      },
      {
        "title": "Contrastive post-training large language models on data curriculum",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=100&pagesize=100&citation_for_view=icbo4M0AAAAJ:1tZ8xJnm2c8C",
        "authors": [
          "Canwen Xu",
          "Corby Rosset",
          "Luciano Del Corro",
          "Shweti Mahajan",
          "Julian McAuley",
          "Jennifer Neville",
          "Ahmed Hassan Awadallah",
          "Nikhil Rao"
        ],
        "publication_date": "2023-10-03",
        "description": "Alignment serves as an important step to steer large language models (LLMs) towards human preferences. In this paper, we explore contrastive post-training techniques for alignment by automatically constructing preference pairs from multiple models of varying strengths (e.g., InstructGPT, ChatGPT and GPT-4). We carefully compare the contrastive techniques of SLiC and DPO to SFT baselines and find that DPO provides a step-function improvement even after continueing SFT saturates. We also explore a data curriculum learning scheme for contrastive post-training, which starts by learning from \"easier\" pairs and transitioning to \"harder\" ones, which further improves alignment. Finally, we scale up our experiments to train with more data and larger models like Orca. Remarkably, contrastive post-training further improves the performance of Orca, already a state-of-the-art instruction learning model tuned with GPT-4 outputs, to exceed that of ChatGPT.",
        "total_citations": 8
      },
      {
        "title": "Contrastive learning for interactive recommendation in fashion",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:QyXJ3EUuO1IC",
        "authors": [
          "Karin Sevegnani",
          "Arjun Seshadri",
          "Tian Wang",
          "Anurag Beniwal",
          "Julian McAuley",
          "Alan Lu",
          "Gerard Medioni"
        ],
        "publication_date": "2022-07-25",
        "description": "Recommender systems and search are both indispensable in facilitating personalization and ease of browsing in online fashion platforms. However, the two tools often operate independently, failing to combine the strengths of recommender systems to accurately capture user tastes with search systems' ability to process user queries. We propose a novel remedy to this problem by automatically recommending personalized fashion items based on a user-provided text request. Our proposed model, WhisperLite, uses contrastive learning to capture user intent from natural language text and improves the recommendation quality of fashion products. WhisperLite combines the strength of CLIP embeddings with additional neural network layers for personalization, and is trained using a composite loss function based on binary cross entropy and contrastive loss. The model demonstrates a significant improvement in offline recommendation retrieval metrics when tested on a real-world dataset collected from an online retail fashion store, as well as widely used open-source datasets in different e-commerce domains, such as restaurants, movies and TV shows, clothing and shoe reviews. We additionally conduct a user study that captures user judgements on the relevance of the model's recommended items, confirming the relevancy of WhisperLite's recommendations in an online setting.",
        "total_citations": 8
      },
      {
        "title": "Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:_AeoHAGD03cC",
        "authors": [
          "Se-eun Yoon",
          "Zhankui He",
          "Jessica Maria Echterhoff",
          "Julian McAuley"
        ],
        "publication_date": "2024-03-13",
        "description": "Synthetic users are cost-effective proxies for real users in the evaluation of conversational recommender systems. Large language models show promise in simulating human-like behavior, raising the question of their ability to represent a diverse population of users. We introduce a new protocol to measure the degree to which language models can accurately emulate human behavior in conversational recommendation. This protocol is comprised of five tasks, each designed to evaluate a key property that a synthetic user should exhibit: choosing which items to talk about, expressing binary preferences, expressing open-ended preferences, requesting recommendations, and giving feedback. Through evaluation of baseline simulators, we demonstrate these tasks effectively reveal deviations of language models from human behavior, and offer insights on how to reduce the deviations with model selection and prompting strategies.",
        "total_citations": 7
      },
      {
        "title": "Opening closed doors: using machine learning to explore factors associated with marital sexual violence in a cross-sectional study from India",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:0CzhzZyukY4C",
        "authors": [
          "Lotus McDougal",
          "Nabamallika Dehingia",
          "Nandita Bhan",
          "Abhishek Singh",
          "Julian McAuley",
          "Anita Raj"
        ],
        "publication_date": "2021-12-01",
        "pages": "e053603",
        "publisher": "British Medical Journal Publishing Group",
        "description": "ObjectivesSexual violence against women is pervasive in India. Most of this violence is experienced in the context of marriage, and rates of marital sexual violence (MSV) have been relatively stagnant over the past decade. This paper machine learning algorithms paired with qualitative thematic analysis to identify new and potentially modifiable factors influencing MSV in India.Design, setting and participantsThis cross-sectional analysis of secondary data used data from in-person interviews with ever-married women aged 15\u201349 who responded to gender-based violence questions in the nationally representative 2015\u20132016 National Family Health Survey (N=66 013), collected between 20 January 2015 and 4 December 2016. Analyses included iterative thematic analysis (L-1 regularised regression followed by iterative qualitative thematic coding of L-2 regularised regression results) and neural network modelling\u00a0\u2026",
        "total_citations": 7
      },
      {
        "title": "Towards automatic instrumentation by learning to separate parts in symbolic multitrack music",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:_OXeSy2IsFwC",
        "authors": [
          "Hao-Wen Dong",
          "Chris Donahue",
          "Taylor Berg-Kirkpatrick",
          "Julian McAuley"
        ],
        "publication_date": "2021-10-17",
        "conference": "International Society for Music Information Retrieval Conference",
        "description": "Modern keyboards allow a musician to play multiple instruments at the same time by assigning zones -- fixed pitch ranges of the keyboard -- to different instruments. In this paper, we aim to further extend this idea and examine the feasibility of automatic instrumentation -- dynamically assigning instruments to notes in solo music during performance. In addition to the online, real-time-capable setting for performative use cases, automatic instrumentation can also find applications in assistive composing tools in an offline setting. Due to the lack of paired data of original solo music and their full arrangements, we approach automatic instrumentation by learning to separate parts (e.g., voices, instruments and tracks) from their mixture in symbolic multitrack music, assuming that the mixture is to be played on a keyboard. We frame the task of part separation as a sequential multi-class classification problem and adopt machine learning to map sequences of notes into sequences of part labels. To examine the effectiveness of our proposed models, we conduct a comprehensive empirical evaluation over four diverse datasets of different genres and ensembles -- Bach chorales, string quartets, game music and pop music. Our experiments show that the proposed models outperform various baselines. We also demonstrate the potential for our proposed models to produce alternative convincing instrumentations for an existing arrangement by separating its mixture into parts. All source code and audio samples can be found at https://salu133445.github.io/arranger/ .",
        "total_citations": 7
      },
      {
        "title": "Learning consumer and producer embeddings for user-generated content recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:q3oQSFYPqjQC",
        "authors": [
          "Wang-Cheng Kang",
          "Julian McAuley"
        ],
        "publication_date": "2018-10-17",
        "conference": "ACM Conference on Recommender Systems",
        "description": "User-Generated Content (UGC) is at the core of web applications where users can both produce and consume content. This differs from traditional e-Commerce domains where content producers and consumers are usually from two separate groups. In this work, we propose a method CPRec (consumer and producer based recommendation), for recommending content on UGC-based platforms. Specifically, we learn a core embedding for each user and two transformation matrices to project the user's core embedding into two 'role' embeddings (i.e., a producer and consumer role). We model each interaction by the ternary relation between the consumer, the consumed item, and its producer. Empirical studies on two large-scale UGC applications show that our method outperforms standard collaborative filtering methods as well as recent methods that model producer information via item features.",
        "total_citations": 7
      },
      {
        "title": "Dynamic programming bipartite belief propagation for hyper graph matching",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:yD5IFk8b50cC",
        "authors": [
          "Zhen Zhang",
          "Julian McAuley",
          "Yong Li",
          "Wei Wei",
          "Yanning Zhang",
          "Qinfeng Shi"
        ],
        "publication_date": "2017-10-17",
        "conference": "International Joint Conference on Artificial Intelligence",
        "description": "Hyper graph matching problems have drawn attention recently due to their ability to embed higher order relations between nodes. In this paper, we formulate hyper graph matching problems as constrained MAP inference problems in graphical models. Whereas previous discrete approaches introduce several global correspondence vectors, we introduce only one global correspondence vector, but several local correspondence vectors. This allows us to decompose the problem into a (linear) bipartite matching problem and several belief propagation sub-problems. Bipartite matching can be solved by traditional approaches, while the belief propagation sub-problem is further decomposed as two sub-problems with optimal substructure. Then a newly proposed dynamic programming procedure is used to solve the belief propagation sub-problem. Experiments show that the proposed methods outperform state-of-the-art techniques for hyper graph matching.",
        "total_citations": 7
      },
      {
        "title": "On the opportunities and challenges of offline reinforcement learning for recommender systems",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:kJDgFkosVoMC",
        "authors": [
          "Xiaocong Chen",
          "Siyu Wang",
          "Julian McAuley",
          "Dietmar Jannach",
          "Lina Yao"
        ],
        "publication_date": "2024-08-19",
        "pages": "1-26",
        "publisher": "ACM",
        "description": "Reinforcement learning serves as a potent tool for modeling dynamic user interests within recommender systems, garnering increasing research attention of late. However, a significant drawback persists: its poor data efficiency, stemming from its interactive nature. The training of reinforcement learning-based recommender systems demands expensive online interactions to amass adequate trajectories, essential for agents to learn user preferences. This inefficiency renders reinforcement learning-based recommender systems a formidable undertaking, necessitating the exploration of potential solutions. Recent strides in offline reinforcement learning present a new perspective. Offline reinforcement learning empowers agents to glean insights from offline datasets and deploy learned policies in online settings. Given that recommender systems possess extensive offline datasets, the framework of offline reinforcement\u00a0\u2026",
        "total_citations": 6
      },
      {
        "title": "A Survey on Large Language Models for Critical Societal Domains: Finance, Healthcare, and Law",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:37UQlXuwjP4C",
        "authors": [
          "Zhiyu Zoey Chen",
          "Jing Ma",
          "Xinlu Zhang",
          "Nan Hao",
          "An Yan",
          "Armineh Nourbakhsh",
          "Xianjun Yang",
          "Julian McAuley",
          "Linda Petzold",
          "William Yang Wang"
        ],
        "publication_date": "2024-05-02",
        "description": "In the fast-evolving domain of artificial intelligence, large language models (LLMs) such as GPT-3 and GPT-4 are revolutionizing the landscapes of finance, healthcare, and law: domains characterized by their reliance on professional expertise, challenging data acquisition, high-stakes, and stringent regulatory compliance. This survey offers a detailed exploration of the methodologies, applications, challenges, and forward-looking opportunities of LLMs within these high-stakes sectors. We highlight the instrumental role of LLMs in enhancing diagnostic and treatment methodologies in healthcare, innovating financial analytics, and refining legal interpretation and compliance strategies. Moreover, we critically examine the ethics for LLM applications in these fields, pointing out the existing ethical concerns and the need for transparent, fair, and robust AI systems that respect regulatory norms. By presenting a thorough review of current literature and practical applications, we showcase the transformative impact of LLMs, and outline the imperative for interdisciplinary cooperation, methodological advancements, and ethical vigilance. Through this lens, we aim to spark dialogue and inspire future research dedicated to maximizing the benefits of LLMs while mitigating their risks in these precision-dependent sectors. To facilitate future research on LLMs in these critical societal domains, we also initiate a reading list that tracks the latest advancements under this topic, which will be continually updated: \\url{https://github.com/czyssrs/LLM_X_papers}.",
        "total_citations": 6
      },
      {
        "title": "How large language models can augment perioperative medicine",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:2v_ZtQDX9iAC",
        "authors": [
          "Rodney A Gabriel",
          "Edward R Mariano",
          "Julian McAuley",
          "Christopher L Wu"
        ],
        "publication_date": "2023-11-01",
        "pages": "575-577",
        "publisher": "BMJ Publishing Group Ltd",
        "description": "Interest in natural language processing, specifically large language models, for clinical applications has exploded in a matter of several months since the introduction of ChatGPT. Large language models are powerful and impressive. It is important that we understand the strengths and limitations of this rapidly evolving technology so that we can brainstorm its future potential in perioperative medicine. In this daring discourse, we discuss the issues with these large language models and how we should proactively think about how to leverage these models into practice to improve patient care, rather than worry that it may take over clinical decision-making. We review three potential major areas in which it may be used to benefit perioperative medicine: (1) clinical decision support and surveillance tools, (2) improved aggregation and analysis of research data related to large retrospective studies and application in\u00a0\u2026",
        "total_citations": 6
      },
      {
        "title": "Clip also understands text: Prompting clip for phrase understanding",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:VN7nJs4JPk0C",
        "authors": [
          "An Yan",
          "Jiacheng Li",
          "Wanrong Zhu",
          "Yujie Lu",
          "William Yang Wang",
          "Julian McAuley"
        ],
        "publication_date": "2022-10-11",
        "description": "Contrastive Language-Image Pretraining (CLIP) efficiently learns visual concepts by pre-training with natural language supervision. CLIP and its visual encoder have been explored on various vision and language tasks and achieve strong zero-shot or transfer learning performance. However, the application of its text encoder solely for text understanding has been less explored. In this paper, we find that the text encoder of CLIP actually demonstrates strong ability for phrase understanding, and can even significantly outperform popular language models such as BERT with a properly designed prompt. Extensive experiments validate the effectiveness of our method across different datasets and domains on entity clustering and entity set expansion tasks.",
        "total_citations": 6
      },
      {
        "title": "Large Scale Knowledge Washing",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:JWITY9-sCbMC",
        "authors": [
          "Yu Wang",
          "Ruihan Wu",
          "Zexue He",
          "Xiusi Chen",
          "Julian McAuley"
        ],
        "publication_date": "2024-05-26",
        "description": "Large language models show impressive abilities in memorizing world knowledge, which leads to concerns regarding memorization of private information, toxic or sensitive knowledge, and copyrighted content. We introduce the problem of Large Scale Knowledge Washing, focusing on \"unlearning\" extensive amounts of factual knowledge. Previous unlearning methods usually define the reverse loss and update the model via backpropagation, which may affect the model's fluency and reasoning ability or even destroy the model due to extensive training with the reverse loss. Existing works introduce additional data from downstream tasks to prevent the model from losing capabilities, which requires downstream task awareness. Controlling the tradeoff of unlearning and maintaining existing capabilities is also challenging. To this end, we propose LAW (Large Scale Washing) to update the MLP layers in decoder-only large language models to perform knowledge washing, as inspired by model editing methods and based on the hypothesis that knowledge and reasoning are disentanglable. We derive a new objective with the knowledge to be unlearned to update the weights of certain MLP layers. Experimental results demonstrate the effectiveness of LAW in forgetting target knowledge while maintaining reasoning ability. The code will be open-sourced at https://github.com/wangyu-ustc/LargeScaleWashing.",
        "total_citations": 5
      },
      {
        "title": "Driving through the concept gridlock: Unraveling explainability bottlenecks in automated driving",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:MIg0yeAD4ggC",
        "authors": [
          "Jessica Echterhoff",
          "An Yan",
          "Kyungtae Han",
          "Amr Abdelraouf",
          "Rohit Gupta",
          "Julian McAuley"
        ],
        "publication_date": "2024-10-17",
        "conference": "Winter Conference on Applications of Computer Vision",
        "pages": "7346-7355",
        "description": "Concept bottleneck models have been successfully used for explainable machine learning by encoding information within the model with a set of human-defined concepts. In the context of human-assisted or autonomous driving, explainability models can help user acceptance and understanding of decisions made by the autonomous vehicle, which can be used to rationalize and explain driver or vehicle behavior. We propose a new approach using concept bottlenecks as visual features for control command predictions and explanations of user and vehicle behavior. We learn a human understandable concept layer that we use to explain sequential driving scenes while learning vehicle control commands. This approach can then be used to determine whether a change in a preferred gap or steering commands from a human (or autonomous vehicle) is led by an external stimulus or change in preferences. We achieve competitive performance to latent visual features while gaining interpretability within our model setup.",
        "total_citations": 5
      },
      {
        "title": "Deciphering compatibility relationships with textual descriptions via extraction and explanation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:A8cqit5AE6sC",
        "authors": [
          "Yu Wang",
          "Zexue He",
          "Zhankui He",
          "Hao Xu",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-17",
        "conference": "AAAI Conference on Artificial Intelligence",
        "description": "Understanding and accurately explaining compatibility relationships between fashion items is a challenging problem in the burgeoning domain of AI-driven outfit recommendations. Present models, while making strides in this area, still occasionally fall short, offering explanations that can be elementary and repetitive. This work aims to address these shortcomings by introducing the Pair Fashion Explanation (PFE) dataset, a unique resource that has been curated to illuminate these compatibility relationships. Furthermore, we propose an innovative two-stage pipeline model that leverages this dataset. This fine-tuning allows the model to generate explanations that convey the compatibility relationships between items. Our experiments showcase the model's potential in crafting descriptions that are knowledgeable, aligned with ground-truth matching correlations, and that produce understandable and informative descriptions, as assessed by both automatic metrics and human evaluation. Our code and data are released at https://github.com/wangyu-ustc/PairFashionExplanation/tree/main?tab=readme-ov-file#additional-experiments.",
        "total_citations": 5
      },
      {
        "title": "Generating Negative Samples for Sequential Recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:U_HPUtbDl20C",
        "authors": [
          "Yongjun Chen",
          "Jia Li",
          "Zhiwei Liu",
          "Nitish Shirish Keskar",
          "Huan Wang",
          "Julian McAuley",
          "Caiming Xiong"
        ],
        "publication_date": "2022-08-07",
        "description": "To make Sequential Recommendation (SR) successful, recent works focus on designing effective sequential encoders, fusing side information, and mining extra positive self-supervision signals. The strategy of sampling negative items at each time step is less explored. Due to the dynamics of users' interests and model updates during training, considering randomly sampled items from a user's non-interacted item set as negatives can be uninformative. As a result, the model will inaccurately learn user preferences toward items. Identifying informative negatives is challenging because informative negative items are tied with both dynamically changed interests and model parameters (and sampling process should also be efficient). To this end, we propose to Generate Negative Samples (items) for SR (GenNi). A negative item is sampled at each time step based on the current SR model's learned user preferences toward items. An efficient implementation is proposed to further accelerate the generation process, making it scalable to large-scale recommendation tasks. Extensive experiments on four public datasets verify the importance of providing high-quality negative samples for SR and demonstrate the effectiveness and efficiency of GenNi.",
        "total_citations": 5
      },
      {
        "title": "Improving choral music separation through expressive synthesized data from sampled instruments",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:kWvqk_afx_IC",
        "authors": [
          "Ke Chen",
          "Hao-Wen Dong",
          "Yi Luo",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick",
          "Miller Puckette",
          "Shlomo Dubnov"
        ],
        "publication_date": "2022-10-17",
        "conference": "International Society for Music Information Retrieval Conference",
        "description": "Choral music separation refers to the task of extracting tracks of voice parts (e.g., soprano, alto, tenor, and bass) from mixed audio. The lack of datasets has impeded research on this topic as previous work has only been able to train and evaluate models on a few minutes of choral music data due to copyright issues and dataset collection difficulties. In this paper, we investigate the use of synthesized training data for the source separation task on real choral music. We make three contributions: first, we provide an automated pipeline for synthesizing choral music data from sampled instrument plugins within controllable options for instrument expressiveness. This produces an 8.2-hour-long choral music dataset from the JSB Chorales Dataset and one can easily synthesize additional data. Second, we conduct an experiment to evaluate multiple separation models on available choral music separation datasets from previous work. To the best of our knowledge, this is the first experiment to comprehensively evaluate choral music separation. Third, experiments demonstrate that the synthesized choral data is of sufficient quality to improve the model's performance on real choral music datasets. This provides additional experimental statistics and data support for the choral music separation study.",
        "total_citations": 5
      },
      {
        "title": "List Items One by One: A New Data Source and Learning Paradigm for Multimodal LLMs",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:lYAcb2jw7qUC",
        "authors": [
          "An Yan",
          "Zhengyuan Yang",
          "Junda Wu",
          "Wanrong Zhu",
          "Jianwei Yang",
          "Linjie Li",
          "Kevin Lin",
          "Jianfeng Wang",
          "Julian McAuley",
          "Jianfeng Gao",
          "Lijuan Wang"
        ],
        "publication_date": "2024-04-25",
        "description": "Set-of-Mark (SoM) Prompting unleashes the visual grounding capability of GPT-4V, by enabling the model to associate visual objects with tags inserted on the image. These tags, marked with alphanumerics, can be indexed via text tokens for easy reference. Despite the extraordinary performance from GPT-4V, we observe that other Multimodal Large Language Models (MLLMs) struggle to understand these visual tags. To promote the learning of SoM prompting for open-source models, we propose a new learning paradigm: \"list items one by one,\" which asks the model to enumerate and describe all visual tags placed on the image following the alphanumeric orders of tags. By integrating our curated dataset with other visual instruction tuning datasets, we are able to equip existing MLLMs with the SoM prompting ability. Furthermore, we evaluate our finetuned SoM models on five MLLM benchmarks. We find that this new dataset, even in a relatively small size (10k-30k images with tags), significantly enhances visual reasoning capabilities and reduces hallucinations for MLLMs. Perhaps surprisingly, these improvements persist even when the visual tags are omitted from input images during inference. This suggests the potential of \"list items one by one\" as a new paradigm for training MLLMs, which strengthens the object-text alignment through the use of visual tags in the training stage. Finally, we conduct analyses by probing trained models to understand the working mechanism of SoM. Our code and data are available at \\url{https://github.com/zzxslp/SoM-LLaVA}.",
        "total_citations": 4
      },
      {
        "title": "LVCHAT: Facilitating Long Video Comprehension",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:BmWJbWwHJAwC",
        "authors": [
          "Yu Wang",
          "Zeyuan Zhang",
          "Julian McAuley",
          "Zexue He"
        ],
        "publication_date": "2024-02-19",
        "description": "Enabling large language models (LLMs) to read videos is vital for multimodal LLMs. Existing works show promise on short videos whereas long video (longer than e.g.~1 minute) comprehension remains challenging. The major problem lies in the over-compression of videos, i.e., the encoded video representations are not enough to represent the whole video. To address this issue, we propose Long Video Chat (LVChat), where Frame-Scalable Encoding (FSE) is introduced to dynamically adjust the number of embeddings in alignment with the duration of the video to ensure long videos are not overly compressed into a few embeddings. To deal with long videos whose length is beyond videos seen during training, we propose Interleaved Frame Encoding (IFE), repeating positional embedding and interleaving multiple groups of videos to enable long video input, avoiding performance degradation due to overly long videos. Experimental results show that LVChat significantly outperforms existing methods by up to 27\\% in accuracy on long-video QA datasets and long-video captioning benchmarks. Our code is published at https://github.com/wangyu-ustc/LVChat.",
        "total_citations": 4
      },
      {
        "title": "How to Train Data-Efficient LLMs",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:SxCCDk4iOpsC",
        "authors": [
          "Noveen Sachdeva",
          "Benjamin Coleman",
          "Wang-Cheng Kang",
          "Jianmo Ni",
          "Lichan Hong",
          "Ed H Chi",
          "James Caverlee",
          "Julian McAuley",
          "Derek Zhiyuan Cheng"
        ],
        "publication_date": "2024-02-15",
        "description": "The training of large language models (LLMs) is expensive. In this paper, we study data-efficient approaches for pre-training LLMs, i.e., techniques that aim to optimize the Pareto frontier of model quality and training resource/data consumption. We seek to understand the tradeoffs associated with data selection routines based on (i) expensive-to-compute data-quality estimates, and (ii) maximization of coverage and diversity-based measures in the feature space. Our first technique, Ask-LLM, leverages the zero-shot reasoning capabilities of instruction-tuned LLMs to directly assess the quality of a training example. To target coverage, we propose Density sampling, which models the data distribution to select a diverse sample. In our comparison of 19 samplers, involving hundreds of evaluation tasks and pre-training runs, we find that Ask-LLM and Density are the best methods in their respective categories. Coverage sampling can recover the performance of the full data, while models trained on Ask-LLM data consistently outperform full-data training -- even when we reject 90% of the original dataset, while converging up to 70% faster.",
        "total_citations": 4
      },
      {
        "title": "Plug-and-play model-agnostic counterfactual policy synthesis for deep reinforcement learning-based recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:T_ojBgVMvoEC",
        "authors": [
          "Siyu Wang",
          "Xiaocong Chen",
          "Julian McAuley",
          "Sally Cripps",
          "Lina Yao"
        ],
        "publication_date": "2023-11-16",
        "publisher": "IEEE",
        "description": "Recent advances in recommender systems have proved the potential of reinforcement learning (RL) to handle the dynamic evolution processes between users and recommender systems. However, learning to train an optimal RL agent is generally impractical with commonly sparse user feedback data in the context of recommender systems. To circumvent the lack of interaction of current RL-based recommender systems, we propose to learn a general model-agnostic counterfactual synthesis (MACS) policy for counterfactual user interaction data augmentation. The counterfactual synthesis policy aims to synthesize counterfactual states while preserving significant information in the original state relevant to the user\u2019s interests, building upon two different training approaches we designed: learning with expert demonstrations and joint training. As a result, the synthesis of each counterfactual data is based on the current\u00a0\u2026",
        "total_citations": 4
      },
      {
        "title": "Climate and gender: association between droughts and intimate partner violence in India",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:SAZ1SQo2q1kC",
        "authors": [
          "Nabamallika Dehingia",
          "Lotus McDougal",
          "Jay G Silverman",
          "Elizabeth Reed",
          "Lianne Urada",
          "Julian McAuley",
          "Abhishek Singh",
          "Anita Raj"
        ],
        "publication_date": "2023-11-15",
        "publisher": "Oxford University Press",
        "description": " Extreme climate events are related to women\u2019s exposure to different forms of violence. We examined the relationship between droughts and physical, sexual, and emotional intimate partner violence (IPV) in India by using 2 different definitions of drought: precipitation-based drought and socioeconomic drought. We analyzed data from 2 rounds of a nationally representative survey, the National Family Health Survey, where married women were asked about their experiences of IPV in the previous year (2015\u20132016 and 2019\u20132021; n\u00a0=\u00a0122,696). Precipitation-based drought was estimated using remote sensing data and geographic information system (GIS) mapping, while socioeconomic drought status was collected from government records. Logistic regression models showed precipitation-based drought to increase the risk of experiencing physical IPV and emotional IPV. Similar findings were observed for\u00a0\u2026",
        "total_citations": 4
      },
      {
        "title": "Farzi Data: Autoregressive Data Distillation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:2ywjKiB__4kC",
        "authors": [
          "Noveen Sachdeva",
          "Zexue He",
          "Wang-Cheng Kang",
          "Jianmo Ni",
          "Derek Zhiyuan Cheng",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-15",
        "description": "We study data distillation for auto-regressive machine learning tasks, where the input and output have a strict left-to-right causal structure. More specifically, we propose Farzi, which summarizes an event sequence dataset into a small number of synthetic sequences -- Farzi Data -- which are optimized to maintain (if not improve) model performance compared to training on the full dataset. Under the hood, Farzi conducts memory-efficient data distillation by (i) deriving efficient reverse-mode differentiation of the Adam optimizer by leveraging Hessian-Vector Products; and (ii) factorizing the high-dimensional discrete event-space into a latent-space which provably promotes implicit regularization. Empirically, for sequential recommendation and language modeling tasks, we are able to achieve 98-120% of downstream full-data performance when training state-of-the-art models on Farzi Data of size as little as 0.1% of the original dataset. Notably, being able to train better models with significantly less data sheds light on the design of future large auto-regressive models, and opens up new opportunities to further scale up model and data sizes.",
        "total_citations": 4
      },
      {
        "title": "Adversarially detecting and alleviating inconsistencies in natural language explanations",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:qe6vwMD2xtsC",
        "authors": [
          "Myeongjun Jang",
          "Bodhisattwa Prasad Majumder",
          "Julian McAuley",
          "Thomas Lukasiewicz",
          "Oana-Maria Camburu"
        ],
        "publication_date": "2023-10-17",
        "total_citations": 4
      },
      {
        "title": "Mirror: A natural language interface for data querying, summarization, and visualization",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:LXmCCkuhhTsC",
        "authors": [
          "Canwen Xu",
          "Julian McAuley",
          "Penghan Wang"
        ],
        "publication_date": "2023-10-17",
        "conference": "WWW, demo track",
        "description": "We present Mirror, an open-source platform for data exploration and analysis powered by large language models. Mirror offers an intuitive natural language interface for querying databases, and automatically generates executable SQL commands to retrieve relevant data and summarize it in natural language. In addition, users can preview and manually edit the generated SQL commands to ensure the accuracy of their queries. Mirror also generates visualizations to facilitate understanding of the data. Designed with flexibility and human input in mind, Mirror is suitable for both experienced data analysts and non-technical professionals looking to gain insights from their data.1",
        "total_citations": 4
      },
      {
        "title": "Synthetic pre-training tasks for neural machine translation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:eO3_k5sD8BwC",
        "authors": [
          "Zexue He",
          "Graeme Blackwood",
          "Rameswar Panda",
          "Julian McAuley",
          "Rogerio Feris"
        ],
        "publication_date": "2023-10-17",
        "conference": "Findings of ACL",
        "description": "Pre-training models with large crawled corpora can lead to issues such as toxicity and bias, as well as copyright and privacy concerns. A promising way of alleviating such concerns is to conduct pre-training with synthetic tasks and data, since no real-world information is ingested by the model. Our goal in this paper is to understand the factors that contribute to the effectiveness of pre-training models when using synthetic resources, particularly in the context of neural machine translation. We propose several novel approaches to pre-training translation models that involve different levels of lexical and structural knowledge, including: 1) generating obfuscated data from a large parallel corpus 2) concatenating phrase pairs extracted from a small word-aligned corpus, and 3) generating synthetic parallel data without real human language corpora. Our experiments on multiple language pairs reveal that pre-training benefits can be realized even with high levels of obfuscation or purely synthetic parallel data. We hope the findings from our comprehensive empirical analysis will shed light on understanding what matters for NMT pre-training, as well as pave the way for the development of more efficient and less toxic models.",
        "total_citations": 4
      },
      {
        "title": "Assistive recipe editing through critiquing",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:hsZV8lGYWTMC",
        "authors": [
          "Diego Antognini",
          "Shuyang Li",
          "Boi Faltings",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-17",
        "conference": "EACL",
        "description": "There has recently been growing interest in the automatic generation of cooking recipes that satisfy some form of dietary restrictions, thanks in part to the availability of online recipe data. Prior studies have used pre-trained language models, or relied on small paired recipe data (e.g., a recipe paired with a similar one that satisfies a dietary constraint). However, pre-trained language models generate inconsistent or incoherent recipes, and paired datasets are not available at scale. We address these deficiencies with RecipeCrit, a hierarchical denoising auto-encoder that edits recipes given ingredient-level critiques. The model is trained for recipe completion to learn semantic relationships within recipes. Our work's main innovation is our unsupervised critiquing module that allows users to edit recipes by interacting with the predicted ingredients; the system iteratively rewrites recipes to satisfy users' feedback. Experiments on the Recipe1M recipe dataset show that our model can more effectively edit recipes compared to strong language-modeling baselines, creating recipes that satisfy user constraints and are more correct, serendipitous, coherent, and relevant as measured by human judges.",
        "total_citations": 4
      },
      {
        "title": "Recipes for Success: Data science in the home kitchen",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:U4n9YNQMCAIC",
        "authors": [
          "Shuyang Li",
          "Julian McAuley"
        ],
        "publication_date": "2020-07-30",
        "publisher": "Harvard Data Science Review",
        "description": "Column Editor\u2019s note: Most people these days routinely use the internet to look up recipes. Data scientists Shuyang Li and Julian McAuley offer food for thought in this issue's Recreation in Randomness that the availability of recipes online is small potatoes compared to recent developments in searching, reconstructing and personalizing recipes to improve the experience of cooking in one's home.",
        "total_citations": 4
      },
      {
        "title": "Solving constrained combinatorial optimization problems via MAP inference without high-order penalties",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:pqnbT2bcN3wC",
        "authors": [
          "Zhen Zhang",
          "Qinfeng Shi",
          "Julian McAuley",
          "Wei Wei",
          "Yanning Zhang",
          "Rui Yao",
          "Anton van den Hengel"
        ],
        "publication_date": "2017-10-17",
        "conference": "AAAI Conference on Artificial Intelligence",
        "description": "Solving constrained combinatorial optimisation problems via MAP inference is often achieved by introducing extra potential functions for each constraint. This can result in very high order potentials, eg a 2nd-order objective with pairwise potentials and a quadratic constraint over all N variables would correspond to an unconstrained objective with an order-N potential. This limits the practicality of such an approach, since inference with high order potentials is tractable only for a few special classes of functions. We propose an approach which is able to solve constrained combinatorial problems using belief propagation without increasing the order. For example, in our scheme the 2nd-order problem above remains order 2 instead of order N. Experiments on applications ranging from foreground detection, image reconstruction, quadratic knapsack, and the M-best solutions problem demonstrate the effectiveness and efficiency of our method. Moreover, we show several situations in which our approach outperforms commercial solvers like CPLEX and others designed for specific constrained MAP inference problems.",
        "total_citations": 4
      },
      {
        "title": "Coral: Collaborative retrieval-augmented large language models improve long-tail recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:LK8CI43ZvvMC",
        "authors": [
          "Junda Wu",
          "Cheng-Chun Chang",
          "Tong Yu",
          "Zhankui He",
          "Jianing Wang",
          "Yupeng Hou",
          "Julian McAuley"
        ],
        "publication_date": "2024-08-25",
        "pages": "3391-3401",
        "description": "The long-tail recommendation is a challenging task for traditional recommender systems, due to data sparsity and data imbalance issues. The recent development of large language models (LLMs) has shown their abilities in complex reasoning, which can help to deduce users' preferences based on very few previous interactions. However, since most LLM-based systems rely on items' semantic meaning as the sole evidence for reasoning, the collaborative information of user-item interactions is neglected, which can cause the LLM's reasoning to be misaligned with task-specific collaborative information of the dataset. To further align LLMs' reasoning to task-specific user-item interaction knowledge, we introduce collaborative retrieval-augmented LLMs, CoRAL, which directly incorporate collaborative evidence into the prompts. Based on the retrieved user-item interactions, the LLM can analyze shared and distinct\u00a0\u2026",
        "total_citations": 3
      },
      {
        "title": "Mitigating hallucination in fictional character role-play",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:Og1tA8FjbJAC",
        "authors": [
          "Nafis Sadeq",
          "Zhouhang Xie",
          "Byungkyu Kang",
          "Prarit Lamba",
          "Xiang Gao",
          "Julian McAuley"
        ],
        "publication_date": "2024-06-25",
        "description": "Role-playing has wide-ranging applications in customer support, embodied agents, computational social science, etc. The influence of parametric world knowledge of large language models (LLMs) often causes role-playing characters to act out of character and hallucinate about things outside the scope of their knowledge. In this work, we focus on the evaluation and mitigation of hallucination in fictional character role-play. We introduce a dataset with more than 2,000 characters and 72,000 interviews, including 18,000 adversarial questions. We propose RoleFact, a role-playing method that mitigates hallucination by modulating the influence of parametric knowledge using a pre-calibrated confidence threshold. Experiments show that the proposed method improves the factual precision of generated responses by 18% for adversarial questions with a 44% reduction in temporal hallucination for time-sensitive interviews. The code and the dataset will be available at https://github.com/NafisSadeq/rolefact.git.",
        "total_citations": 3
      },
      {
        "title": "Beyond chain-of-thought: A survey of chain-of-x paradigms for llms",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:nqdriD65xNoC",
        "authors": [
          "Yu Xia",
          "Rui Wang",
          "Xu Liu",
          "Mingyan Li",
          "Tong Yu",
          "Xiang Chen",
          "Julian McAuley",
          "Shuai Li"
        ],
        "publication_date": "2024-04-24",
        "description": "Chain-of-Thought (CoT) has been a widely adopted prompting method, eliciting impressive reasoning abilities of Large Language Models (LLMs). Inspired by the sequential thought structure of CoT, a number of Chain-of-X (CoX) methods have been developed to address various challenges across diverse domains and tasks involving LLMs. In this paper, we provide a comprehensive survey of Chain-of-X methods for LLMs in different contexts. Specifically, we categorize them by taxonomies of nodes, i.e., the X in CoX, and application tasks. We also discuss the findings and implications of existing CoX methods, as well as potential future directions. Our survey aims to serve as a detailed and up-to-date resource for researchers seeking to apply the idea of CoT to broader scenarios.",
        "total_citations": 3
      },
      {
        "title": "CAMELoT: Towards Large Language Models with Training-Free Consolidated Associative Memory",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:t-hv7AR41mYC",
        "authors": [
          "Zexue He",
          "Leonid Karlinsky",
          "Donghyun Kim",
          "Julian McAuley",
          "Dmitry Krotov",
          "Rogerio Feris"
        ],
        "publication_date": "2024-02-21",
        "description": "Large Language Models (LLMs) struggle to handle long input sequences due to high memory and runtime costs. Memory-augmented models have emerged as a promising solution to this problem, but current methods are hindered by limited memory capacity and require costly re-training to integrate with a new LLM. In this work, we introduce an associative memory module which can be coupled to any pre-trained (frozen) attention-based LLM without re-training, enabling it to handle arbitrarily long input sequences. Unlike previous methods, our associative memory module consolidates representations of individual tokens into a non-parametric distribution model, dynamically managed by properly balancing the novelty and recency of the incoming data. By retrieving information from this consolidated associative memory, the base LLM can achieve significant (up to 29.7% on Arxiv) perplexity reduction in long-context modeling compared to other baselines evaluated on standard benchmarks. This architecture, which we call CAMELoT (Consolidated Associative Memory Enhanced Long Transformer), demonstrates superior performance even with a tiny context window of 128 tokens, and also enables improved in-context learning with a much larger set of demonstrations.",
        "total_citations": 3
      },
      {
        "title": "Violence against women on Twitter in India: Testing a taxonomy for online misogyny and measuring its prevalence during COVID-19",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:Wq2b2clWBLsC",
        "authors": [
          "Nabamallika Dehingia",
          "Julian McAuley",
          "Lotus McDougal",
          "Elizabeth Reed",
          "Jay G Silverman",
          "Lianne Urada",
          "Anita Raj"
        ],
        "publication_date": "2023-10-25",
        "pages": "e0292121",
        "publisher": "Public Library of Science",
        "description": " Background Online misogyny is a violation of women\u2019s digital rights. Empirical studies on this topic are however lacking, particularly in low- and middle- income countries. The current study aimed to estimate whether prevalence of online misogyny on Twitter in India changed since the pandemic. Methods Based on prior theoretical work, we defined online misogyny as consisting of six overlapping forms: sexist abuses, sexual objectification, threatening to physically or sexually harm women, asserting women\u2019s inferiority, justifying violence against women, and dismissing feminist efforts. Qualitative analysis of a small subset of tweets posted from India (40,672 tweets) substantiated this definition and taxonomy for online misogyny. Supervised machine learning models were used to predict the status of misogyny across a corpus of 30 million tweets posted from India between 2018 and 2021. Next, interrupted time series analysis examined changes in online misogyny prevalence, before and during COVID-19. Results Qualitative assessment showed that online misogyny in India existed most in the form of sexual objectification and sexist abusive content, which demeans women and shames them for their presumed sexual activity. Around 2% of overall tweets posted from India between 2018 and 2021 included some form of misogynistic content. The absolute volume as well as proportion of misogynistic tweets showed significant increasing trends after the onset of COVID-19, relative to trends prior to the pandemic. Conclusion Findings highlight increasing gender inequalities on Twitter since the pandemic. Aggressive and hateful tweets that target\u00a0\u2026",
        "total_citations": 3
      },
      {
        "title": "Disambiguating medical reports via contrastive knowledge infusion",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:sA9dB-pw3HoC",
        "authors": [
          "Zexue He",
          "An Yan",
          "Amilcare Gentili",
          "Julian McAuley",
          "Chun-Nan Hsu"
        ],
        "publication_date": "2023-05-15",
        "conference": "AAAI (AI for Social Impact Track)",
        "total_citations": 3
      },
      {
        "title": "Global mesoscale ocean variability from multiyear altimetry: an analysis of the influencing factors",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:NDuN12AVoxsC",
        "authors": [
          "Yao Yu",
          "Sarah T Gille",
          "David T Sandwell",
          "Julian McAuley"
        ],
        "publication_date": "2022-07-17",
        "pages": "e210008",
        "description": "              Sea surface slope (SSS) responds to oceanic processes and other environmental parameters. This study aims to identify the parameters that influence SSS variability. We use SSS calculated from multiyear satellite altimeter observations and focus on small resolvable scales in the 30\u2013100-km wavelength band. First, we revisit the correlation of mesoscale ocean variability with seafloor roughness as a function of depth, as proposed by Gille et al. Our results confirm that in shallow water there is statistically significant positive correlation between rough bathymetry and surface variability, whereas the opposite is true in the deep ocean. In the next step, we assemble 27 features as input variables to fit the SSS with a linear regression model and a boosted trees regression model, and then we make predictions. Model performance metrics for the linear regression model are             R 2             = 0.381 and\u00a0\u2026",
        "total_citations": 3
      },
      {
        "title": "Semi-supervised multi-label classification with 3D CBAM resnet for tuberculosis cavern reports",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:PyEswDtIyv0C",
        "authors": [
          "Xing Lu",
          "An Yan",
          "Eric Y Chang",
          "C-n Hsu",
          "Julian McAuley",
          "Jiang Du",
          "Amilcare Gentili"
        ],
        "publication_date": "2022-10-17",
        "conference": "CLEF2022 Working Notes",
        "description": "Detection and characterization of tuberculosis and the evaluation of lesion characteristics are challenging. To provide a solution for a multi-label classification task of tuberculosis cavern report task, we performed a deep learning study with backbones of 3D Resnet. Semi-supervised learning strategy was implied in this study to leverage the unlabeled dataset from cavern detection task. A convolutional block attention model (CBAM) was used to add an attention mechanism in each block of the Resnet to further improve the performance of the convolutional neural network (CNN). Our solution is ranked the 1st place with submissions obtained Mean_AUC of 0.687 and 0.681 for this task.",
        "total_citations": 3
      },
      {
        "title": "Bernard: A stateful neural open-domain socialbot",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:QYdC8u9Cj1oC",
        "authors": [
          "Bodhisattwa Prasad Majumder",
          "Shuyang Li",
          "Jianmo Ni",
          "Huanru Henry Mao",
          "Sophia Sun",
          "Julian McAuley"
        ],
        "publication_date": "2020-10-17",
        "description": "We propose Bernard: a framework for an engaging open-domain socialbot. While the task of open-domain dialog generation remains a difficult one, we explore various strategies to generate coherent dialog given an arbitrary dialog history. We incorporate a stateful autonomous dialog manager using non-deterministic finite automata to control multi-turn conversations. We show that powerful pretrained language models are capable of generating coherent and topical responses in the presence of grounding facts. Finally, we implement Acknowledge-Retrieve-Reply strategy to combine template-based and neural dialog generation for greater diversity and increased naturalness. Extensive human evaluation shows that the combination of generative models and retrieval models in a stateful dialog machine can achieve desired user experiences in terms of topic diversity and engagingness, as showed in extensive human evaluation.",
        "total_citations": 3
      },
      {
        "title": "Graphical models",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:WF5omc3nYNoC",
        "authors": [
          "Julian McAuley",
          "Tiberio Caetano",
          "Wray Buntine"
        ],
        "publication_date": "2010-10-17",
        "publisher": "Springer",
        "description": "Graphical Models \u2014 The Australian National University Skip to main navigation Skip to search \nSkip to main content The Australian National University Home The Australian National University \nLogo Help & FAQ Home Profiles Research output Projects Research units Search by expertise, \nname or affiliation Graphical Models Julian McAuley, Tiberio Caetano, Wray Buntine Research \noutput: Chapter in Book/Report/Conference proceeding \u203a Entry for encyclopedia/dictionary \u203a \npeer-review Overview Original language English Title of host publication Encyclopedia of \nMachine Learning Editors Claude Sammut & Geoffrey I.Webb Place of Publication New York \nPublisher Springer Pages 8pp Volume 6 ISBN (Print) 9780387307688 DOIs \nhttps://doi.org/10.1007/978-0-387-30164-8_351 Publication status Published - 2010 Access to \nDocument 10.1007/978-0-387-30164-8_351 Cite this APA Author BIBTEX Harvard Standard \u2026",
        "total_citations": 3
      },
      {
        "title": "Commit: Coordinated instruction tuning for multimodal large language models",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:AZju0d2GQJ0C",
        "authors": [
          "Junda Wu",
          "Xintong Li",
          "Tong Yu",
          "Yu Wang",
          "Xiang Chen",
          "Jiuxiang Gu",
          "Lina Yao",
          "Jingbo Shang",
          "Julian McAuley"
        ],
        "publication_date": "2024-07-29",
        "description": "Instruction tuning in multimodal large language models (MLLMs) aims to smoothly integrate a backbone LLM with a pre-trained feature encoder for downstream tasks. The major challenge is how to efficiently find the synergy through cooperative learning where LLMs adapt their reasoning abilities in downstream tasks while feature encoders adjust their encoding to provide more relevant modal information. In this paper, we analyze the MLLM instruction tuning from both theoretical and empirical perspectives, where we find unbalanced learning between the two components, i.e., the feature encoder and the LLM, can cause diminishing learning gradients that slow the model convergence and often lead to sub-optimal results due to insufficient learning. Inspired by our findings, we propose a measurement to quantitatively evaluate the learning balance, based on which we further design a dynamic learning scheduler that better coordinates the learning. In addition, we introduce an auxiliary loss regularization method to promote updating of the generation distribution of MLLMs considering the learning state of each model component, which potentially prevents each component from gradient diminishing and enables a more accurate estimation of the learning balance coefficient. We conduct experiments with multiple LLM backbones and feature encoders, where our techniques are model-agnostic and can be generically integrated with various MLLM backbones. Experiment results on multiple downstream tasks and modalities in vision and audio, demonstrate the proposed method's better efficiency and effectiveness in MLLM instruction tuning.",
        "total_citations": 2
      },
      {
        "title": "SelfVC: Voice Conversion With Iterative Refinement using Self Transformations",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:eAlLMO4JVmQC",
        "authors": [
          "Paarth Neekhara",
          "Shehzeen Hussain",
          "Rafael Valle",
          "Boris Ginsburg",
          "Rishabh Ranjan",
          "Shlomo Dubnov",
          "Farinaz Koushanfar",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-14",
        "description": "We propose SelfVC, a training strategy to iteratively improve a voice conversion model with self-synthesized examples. Previous efforts on voice conversion focus on explicitly disentangling speech representations to separately encode speaker characteristics and linguistic content. However, disentangling speech representations to capture such attributes using task-specific loss terms can lead to information loss by discarding finer nuances of the original signal. In this work, instead of explicitly disentangling attributes with loss terms, we present a framework to train a controllable voice conversion model on entangled speech representations derived from self-supervised learning and speaker verification models. First, we develop techniques to derive prosodic information from the audio signal and SSL representations to train predictive submodules in the synthesis model. Next, we propose a training strategy to iteratively improve the synthesis model for voice conversion, by creating a challenging training objective using self-synthesized examples. In this training approach, the current state of the synthesis model is used to generate voice-converted variations of an utterance, which serve as inputs for the reconstruction task, ensuring a continuous and purposeful refinement of the model. We demonstrate that incorporating such self-synthesized examples during training improves the speaker similarity of generated speech as compared to a baseline voice conversion model trained solely on heuristically perturbed inputs. SelfVC is trained without any text and is applicable to a range of tasks such as zero-shot voice conversion, cross-lingual voice\u00a0\u2026",
        "total_citations": 2
      },
      {
        "title": "Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Review",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:v6i8RKmR8ToC",
        "authors": [
          "Jessica Echterhoff",
          "An Yan",
          "Julian McAuley"
        ],
        "publication_date": "2023-07-05",
        "description": "It is time-consuming to find the best product among many similar alternatives. Comparative sentences can help to contrast one item from others in a way that highlights important features of an item that stand out. Given reviews of one or multiple items and relevant item features, we generate comparative review sentences to aid users to find the best fit. Specifically, our model consists of three successive components in a transformer: (i) an item encoding module to encode an item for comparison, (ii) a comparison generation module that generates comparative sentences in an autoregressive manner, (iii) a novel decoding method for user personalization. We show that our pipeline generates fluent and diverse comparative sentences. We run experiments on the relevance and fidelity of our generated sentences in a human evaluation study and find that our algorithm creates comparative review sentences that are relevant and truthful.",
        "total_citations": 2
      },
      {
        "title": "Driving through the concept gridlock: unraveling explainability bottlenecks",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:C33y2ycGS3YC",
        "authors": [
          "Jessica Echterhoff",
          "An Yan",
          "Kyungtae Han",
          "Amr Abdelraouf",
          "Rohit Gupta",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-17",
        "conference": "Winter Conference on Applications of Computer Vision",
        "description": "Concept bottleneck models have been successfully used for explainable machine learning by encoding information within the model with a set of human-defined concepts. In the context of human-assisted or autonomous driving, explainability models can help user acceptance and understanding of decisions made by the autonomous vehicle, which can be used to rationalize and explain driver or vehicle behavior. We propose a new approach using concept bottlenecks as visual features for control command predictions and explanations of user and vehicle behavior. We learn a human-understandable concept layer that we use to explain sequential driving scenes while learning vehicle control commands. This approach can then be used to determine whether a change in a preferred gap or steering commands from a human (or autonomous vehicle) is led by an external stimulus or change in preferences. We achieve competitive performance to latent visual features while gaining interpretability within our model setup.",
        "total_citations": 2
      },
      {
        "title": "Unsupervised improvement of factual knowledge in language models",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:aIdbFUkbNIkC",
        "authors": [
          "Nafis Sadeq",
          "Byungkyu Kang",
          "Prarit Lamba",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-17",
        "conference": "EACL",
        "description": "Masked language modeling (MLM) plays a key role in pretraining large language models. But the MLM objective is often dominated by high-frequency words that are sub-optimal for learning factual knowledge. In this work, we propose an approach for influencing MLM pretraining in a way that can improve language model performance on a variety of knowledge-intensive tasks. We force the language model to prioritize informative words in a fully unsupervised way. Experiments demonstrate that the proposed approach can significantly improve the performance of pretrained language models on tasks such as factual recall, question answering, sentiment analysis, and natural language inference in a closed-book setting.",
        "total_citations": 2
      },
      {
        "title": "GapFormer: Fast autoregressive transformers meet RNNs for personalized adaptive cruise control",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:DkZNVXde3BIC",
        "authors": [
          "Noveen Sachdeva",
          "Ziran Wang",
          "Kyungtae Han",
          "Rohit Gupta",
          "Julian McAuley"
        ],
        "publication_date": "2022-10-08",
        "conference": "International Conference on Intelligent Transportation Systems (ITSC)",
        "pages": "2528-2535",
        "publisher": "IEEE",
        "description": "Adaptive cruise control has been an important function in modern vehicles, and has proven to be helpful for assisted driving. The main challenges involve accurate gap prediction between the ego and preceding vehicles, as well as personalizing the driving behaviour for different kinds of drivers and/or cars. Correspondingly, in this paper, we make the following contributions: (1) we propose GAPFoRMER which combines the Transformer and RNN architectures to better model and personalize driving behaviour; (2) make necessary modifications to the Transformer attention mechanism for scaling to long driving contexts in a resource-efficient manner; and (3) propose an architecture-agnostic model training regime, Horizon which improves generalization by incorporating a time-horizon and makes the models more accurate and robust. Detailed experiments on both public and proprietary datasets demonstrate that\u00a0\u2026",
        "total_citations": 2
      },
      {
        "title": "Fast autoregressive transformers meet RNNs for personalized adaptive cruise control",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:__bU50VfleQC",
        "authors": [
          "Noveen Sachdeva",
          "Ziran Wang",
          "Kyungtae Han",
          "Rohit Gupta",
          "Julian McAuley"
        ],
        "publication_date": "2022-10-17",
        "conference": "IEEE International Conference on Intelligent Transportation Systems",
        "total_citations": 2
      },
      {
        "title": "Disentangled representations of style and content for visual art with generative adversarial networks",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:48xauSegjOkC",
        "authors": [
          "Chris Donahue",
          "Julian McAuley"
        ],
        "publication_date": "2017-10-17",
        "description": "We propose an approach to learning disentangled representations of style and content for generative modeling of visual art. By fixing the style portion of the latent representation, we can generate diverse images in a particular style. Furthermore, we can fix the content portion, examining a particular scene through the lens of a variety of styles. Our approach pairs generative adversarial networks with Siamese discriminators; samples from the real dataset consist of two works from the same artist, and samples from the generator consist of two images with common style code. Unlike recent style transfer approaches, our work can imagine both style and content without the need of images to characterize each.",
        "total_citations": 2
      },
      {
        "title": "Optimization of robust loss functions for weakly-labeled image taxonomies: an ImageNet case study",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:qwy9JoKyICEC",
        "authors": [
          "Julian J McAuley",
          "Arnau Ramisa",
          "Tib\u00e9rio S Caetano"
        ],
        "publication_date": "2011-07-25",
        "pages": "355-368",
        "publisher": "Springer Berlin Heidelberg",
        "description": " The recently proposed ImageNet dataset consists of several million images, each annotated with a single object category. However, these annotations may be imperfect, in the sense that many images contain multiple objects belonging to the label vocabulary. In other words, we have a multi-label problem but the annotations include only a single label (and not necessarily the most prominent). Such a setting motivates the use of a robust evaluation measure, which allows for a limited number of labels to be predicted and, as long as one of the predicted labels is correct, the overall prediction should be considered correct. This is indeed the type of evaluation measure used to assess algorithm performance in a recent competition on ImageNet data. Optimizing such types of performance measures presents several hurdles even with existing structured output learning methods. Indeed, many of the current state\u00a0\u2026",
        "total_citations": 2
      },
      {
        "title": "Federated Large Language Models: Current Progress and Future Directions",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:n3vGvpFsckwC",
        "authors": [
          "Yuhang Yao",
          "Jianyi Zhang",
          "Junda Wu",
          "Chengkai Huang",
          "Yu Xia",
          "Tong Yu",
          "Ruiyi Zhang",
          "Sungchul Kim",
          "Ryan Rossi",
          "Ang Li",
          "Lina Yao",
          "Julian McAuley",
          "Yiran Chen",
          "Carlee Joe-Wong"
        ],
        "publication_date": "2024-09-24",
        "description": "Large language models are rapidly gaining popularity and have been widely adopted in real-world applications. While the quality of training data is essential, privacy concerns arise during data collection. Federated learning offers a solution by allowing multiple clients to collaboratively train LLMs without sharing local data. However, FL introduces new challenges, such as model convergence issues due to heterogeneous data and high communication costs. A comprehensive study is required to address these challenges and guide future research. This paper surveys Federated learning for LLMs (FedLLM), highlighting recent advances and future directions. We focus on two key aspects: fine-tuning and prompt learning in a federated setting, discussing existing work and associated research challenges. We finally propose potential research directions for federated LLMs, including pre-training and how LLMs can further enhance federated learning.",
        "total_citations": 1
      },
      {
        "title": "Recommendation with Generative Models",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:1r-w4gtu6w8C",
        "authors": [
          "Yashar Deldjoo",
          "Zhankui He",
          "Julian McAuley",
          "Anton Korikov",
          "Scott Sanner",
          "Arnau Ramisa",
          "Rene Vidal",
          "Maheswaran Sathiamoorthy",
          "Atoosa Kasrizadeh",
          "Silvia Milano",
          "Francesco Ricci"
        ],
        "publication_date": "2024-09-18",
        "description": "Generative models are a class of AI models capable of creating new instances of data by learning and sampling from their statistical distributions. In recent years, these models have gained prominence in machine learning due to the development of approaches such as generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer-based architectures such as GPT. These models have applications across various domains, such as image generation, text synthesis, and music composition. In recommender systems, generative models, referred to as Gen-RecSys, improve the accuracy and diversity of recommendations by generating structured outputs, text-based interactions, and multimedia content. By leveraging these capabilities, Gen-RecSys can produce more personalized, engaging, and dynamic user experiences, expanding the role of AI in eCommerce, media, and beyond. Our book goes beyond existing literature by offering a comprehensive understanding of generative models and their applications, with a special focus on deep generative models (DGMs) and their classification. We introduce a taxonomy that categorizes DGMs into three types: ID-driven models, large language models (LLMs), and multimodal models. Each category addresses unique technical and architectural advancements within its respective research area. This taxonomy allows researchers to easily navigate developments in Gen-RecSys across domains such as conversational AI and multimodal content generation. Additionally, we examine the impact and potential risks of generative models, emphasizing the importance of robust\u00a0\u2026",
        "total_citations": 1
      },
      {
        "title": "Visual Prompting in Multimodal Large Language Models: A Survey",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:nPTYJWkExTIC",
        "authors": [
          "Junda Wu",
          "Zhehao Zhang",
          "Yu Xia",
          "Xintong Li",
          "Zhaoyang Xia",
          "Aaron Chang",
          "Tong Yu",
          "Sungchul Kim",
          "Ryan A Rossi",
          "Ruiyi Zhang",
          "Subrata Mitra",
          "Dimitris N Metaxas",
          "Lina Yao",
          "Jingbo Shang",
          "Julian McAuley"
        ],
        "publication_date": "2024-09-05",
        "description": "Multimodal large language models (MLLMs) equip pre-trained large-language models (LLMs) with visual capabilities. While textual prompting in LLMs has been widely studied, visual prompting has emerged for more fine-grained and free-form visual instructions. This paper presents the first comprehensive survey on visual prompting methods in MLLMs, focusing on visual prompting, prompt generation, compositional reasoning, and prompt learning. We categorize existing visual prompts and discuss generative methods for automatic prompt annotations on the images. We also examine visual prompting methods that enable better alignment between visual encoders and backbone LLMs, concerning MLLM's visual grounding, object referring, and compositional reasoning abilities. In addition, we provide a summary of model training and in-context learning methods to improve MLLM's perception and understanding of visual prompts. This paper examines visual prompting methods developed in MLLMs and provides a vision of the future of these methods.",
        "total_citations": 1
      },
      {
        "title": "Futga: Towards fine-grained music understanding through temporally-enhanced generative augmentation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:2vr6o8x5NLkC",
        "authors": [
          "Junda Wu",
          "Zachary Novack",
          "Amit Namburi",
          "Jiaheng Dai",
          "Hao-Wen Dong",
          "Zhouhang Xie",
          "Carol Chen",
          "Julian McAuley"
        ],
        "publication_date": "2024-07-29",
        "description": "Existing music captioning methods are limited to generating concise global descriptions of short music clips, which fail to capture fine-grained musical characteristics and time-aware musical changes. To address these limitations, we propose FUTGA, a model equipped with fined-grained music understanding capabilities through learning from generative augmentation with temporal compositions. We leverage existing music caption datasets and large language models (LLMs) to synthesize fine-grained music captions with structural descriptions and time boundaries for full-length songs. Augmented by the proposed synthetic dataset, FUTGA is enabled to identify the music's temporal changes at key transition points and their musical functions, as well as generate detailed descriptions for each music segment. We further introduce a full-length music caption dataset generated by FUTGA, as the augmentation of the MusicCaps and the Song Describer datasets. We evaluate the automatically generated captions on several downstream tasks, including music generation and retrieval. The experiments demonstrate the quality of the generated captions and the better performance in various downstream tasks achieved by the proposed music captioning approach. Our code and datasets can be found in \\href{https://huggingface.co/JoshuaW1997/FUTGA}{\\textcolor{blue}{https://huggingface.co/JoshuaW1997/FUTGA}}.",
        "total_citations": 1
      },
      {
        "title": "Auto-Encoding or Auto-Regression? A Reality Check on Causality of Self-Attention-Based Sequential Recommenders",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:OzeSX8-yOCQC",
        "authors": [
          "Yueqi Wang",
          "Zhankui He",
          "Zhenrui Yue",
          "Julian McAuley",
          "Dong Wang"
        ],
        "publication_date": "2024-06-04",
        "description": "The comparison between Auto-Encoding (AE) and Auto-Regression (AR) has become an increasingly important topic with recent advances in sequential recommendation. At the heart of this discussion lies the comparison of BERT4Rec and SASRec, which serve as representative AE and AR models for self-attentive sequential recommenders. Yet the conclusion of this debate remains uncertain due to: (1) the lack of fair and controlled environments for experiments and evaluations; and (2) the presence of numerous confounding factors w.r.t. feature selection, modeling choices and optimization algorithms. In this work, we aim to answer this question by conducting a series of controlled experiments. We start by tracing the AE/AR debate back to its origin through a systematic re-evaluation of SASRec and BERT4Rec, discovering that AR models generally surpass AE models in sequential recommendation. In addition, we find that AR models further outperforms AE models when using a customized design space that includes additional features, modeling approaches and optimization techniques. Furthermore, the performance advantage of AR models persists in the broader HuggingFace transformer ecosystems. Lastly, we provide potential explanations and insights into AE/AR performance from two key perspectives: low-rank approximation and inductive bias. We make our code and data available at https://github.com/yueqirex/ModSAR",
        "total_citations": 1
      },
      {
        "title": "Aligning as Debiasing: Causality-Aware Alignment via Reinforcement Learning with Interventional Feedback",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:yY3RG6sOEgwC",
        "authors": [
          "Yu Xia",
          "Tong Yu",
          "Zhankui He",
          "Handong Zhao",
          "Julian McAuley",
          "Shuai Li"
        ],
        "publication_date": "2024-06-17",
        "conference": "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
        "pages": "4684-4695",
        "description": "Large language models (LLMs) often generate biased outputs containing offensive, toxic, or stereotypical text. Existing LLM alignment methods such as reinforcement learning from human feedback (RLHF) alleviate biases primarily based on reward signals from current model outputs without considering the source of biases. In this work, to explore how biases are formed, we revisit LLMs\u2019 text generation from a causal perspective. We identify pretraining data and input prompts, which contain semantic correlations of textual phrases, as two confounders between LLMs and model outputs causing biases. Inspired by our causal view, we leverage the reward model in RL alignment as an instrumental variable to perform causal intervention on LLMs. Utilizing the reward difference between an initial LLM and intervened LLM as interventional feedback to guide RL finetuning, we propose Causality-Aware Alignment (CAA) for LLM debiasing. Experiments on two text generation tasks with three different alignment objectives demonstrate the advantages of our method in aligning LLMs to generate less biased and safer outputs.",
        "total_citations": 1
      },
      {
        "title": "DITTO-2: Distilled Diffusion Inference-Time T-Optimization for Music Generation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:QVtou7C4vgoC",
        "authors": [
          "Zachary Novack",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick",
          "Nicholas Bryan"
        ],
        "publication_date": "2024-05-30",
        "description": "Controllable music generation methods are critical for human-centered AI-based music creation, but are currently limited by speed, quality, and control design trade-offs. Diffusion Inference-Time T-optimization (DITTO), in particular, offers state-of-the-art results, but is over 10x slower than real-time, limiting practical use. We propose Distilled Diffusion Inference-Time T -Optimization (or DITTO-2), a new method to speed up inference-time optimization-based control and unlock faster-than-real-time generation for a wide-variety of applications such as music inpainting, outpainting, intensity, melody, and musical structure control. Our method works by (1) distilling a pre-trained diffusion model for fast sampling via an efficient, modified consistency or consistency trajectory distillation process (2) performing inference-time optimization using our distilled model with one-step sampling as an efficient surrogate optimization task and (3) running a final multi-step sampling generation (decoding) using our estimated noise latents for best-quality, fast, controllable generation. Through thorough evaluation, we find our method not only speeds up generation over 10-20x, but simultaneously improves control adherence and generation quality all at once. Furthermore, we apply our approach to a new application of maximizing text adherence (CLAP score) and show we can convert an unconditional diffusion model without text inputs into a model that yields state-of-the-art text control. Sound examples can be found at https://ditto-music.github.io/ditto2/.",
        "total_citations": 1
      },
      {
        "title": "Multi-Behavior Generative Recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:dAp6zn-oMfAC",
        "authors": [
          "Zihan Liu",
          "Yupeng Hou",
          "Julian McAuley"
        ],
        "publication_date": "2024-05-27",
        "description": "Multi-behavior sequential recommendation (MBSR) aims to incorporate behavior types of interactions for better recommendations. Existing approaches focus on the next-item prediction objective, neglecting the value of integrating the target behavior type into the learning objective. In this paper, we propose MBGen, a novel Multi-Behavior sequential Generative recommendation framework. We formulate the MBSR task into a consecutive two-step process: (1) given item sequences, MBGen first predicts the next behavior type to frame the user intention, (2) given item sequences and a target behavior type, MBGen then predicts the next items. To model such a two-step process, we tokenize both behaviors and items into tokens and construct one single token sequence with both behaviors and items placed interleaved. Furthermore, MBGen learns to autoregressively generate the next behavior and item tokens in a unified generative recommendation paradigm, naturally enabling a multi-task capability. Additionally, we exploit the heterogeneous nature of token sequences in the generative recommendation and propose a position-routed sparse architecture to efficiently and effectively scale up models. Extensive experiments on public datasets demonstrate that MBGen significantly outperforms existing MBSR models across multiple tasks.",
        "total_citations": 1
      },
      {
        "title": "Temporal Disentangled Contrastive Diffusion Model for Spatiotemporal Imputation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:hGdtkIFZdKAC",
        "authors": [
          "Yakun Chen",
          "Kaize Shi",
          "Zhangkai Wu",
          "Juan Chen",
          "Xianzhi Wang",
          "Julian McAuley",
          "Guandong Xu",
          "Shui Yu"
        ],
        "publication_date": "2024-02-18",
        "description": "Spatiotemporal data analysis is pivotal across various domains, including transportation, meteorology, and healthcare. However, the data collected in real-world scenarios often suffers incompleteness due to sensor malfunctions and network transmission errors. Spatiotemporal imputation endeavours to predict missing values by exploiting the inherent spatial and temporal dependencies present in the observed data. Traditional approaches, which rely on classical statistical and machine learning techniques, are often inadequate, particularly when the data fails to meet strict distributional assumptions. In contrast, recent deep learning-based methods, leveraging graph and recurrent neural networks, have demonstrated enhanced efficacy. Nonetheless, these approaches are prone to error accumulation. Generative models have been increasingly adopted to circumvent the reliance on potentially inaccurate historical imputed values for future predictions. These models grapple with the challenge of producing unstable results, a particular issue in diffusion-based models. We aim to address these challenges by designing conditional features to guide the generative process and expedite training. Specifically, we introduce CTSD, a novel approach incorporating trend and seasonal information as conditional features and employing contrastive learning to improve model generalizability. The extensive experiments on three real-world datasets demonstrate the superior performance of CTSD over various state-of-the-art baselines.",
        "total_citations": 1
      },
      {
        "title": "Finest: Stabilizing recommendations by rank-preserving fine-tuning",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:s9ia6_kGH2AC",
        "authors": [
          "Sejoon Oh",
          "Berk Ustun",
          "Julian McAuley",
          "Srijan Kumar"
        ],
        "publication_date": "2024-02-05",
        "description": "Modern recommender systems may output considerably different recommendations due to small perturbations in the training data. Changes in the data from a single user will alter the recommendations as well as the recommendations of other users. In applications like healthcare, housing, and finance, this sensitivity can have adverse effects on user experience. We propose a method to stabilize a given recommender system against such perturbations. This is a challenging task due to (1) the lack of a ``reference'' rank list that can be used to anchor the outputs; and (2) the computational challenges in ensuring the stability of rank lists with respect to all possible perturbations of training data. Our method, FINEST, overcomes these challenges by obtaining reference rank lists from a given recommendation model and then fine-tuning the model under simulated perturbation scenarios with rank-preserving regularization on sampled items. Our experiments on real-world datasets demonstrate that FINEST can ensure that recommender models output stable recommendations under a wide range of different perturbations without compromising next-item prediction accuracy.",
        "total_citations": 1
      },
      {
        "title": "Improving Robustness of Convolutional Networks Through Sleep-Like Replay",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:jtI9f0ekYq0C",
        "authors": [
          "Jean Erik Delanois",
          "Aditya Ahuja",
          "Giri P Krishnan",
          "Timothy Tadros",
          "Julian McAuley",
          "Maxim Bazhenov"
        ],
        "publication_date": "2023-12-15",
        "conference": "2023 International Conference on Machine Learning and Applications (ICMLA)",
        "pages": "257-264",
        "publisher": "IEEE",
        "description": "Convolutional neural networks (CNNs) are a foun-dational model architecture utilized to perform a wide variety of visual tasks. On image classification tasks CNNs achieve high performance, however model accuracy degrades quickly when inputs are perturbed by distortions such as additive noise or blurring. This drop in performance partly arises from incorrect detection of local features by convolutional layers. In this work, we develop a neuroscience-inspired unsupervised Sleep Replay Consolidation (SRC) algorithm for improving convolutional fil-ter's robustness to perturbations. We demonstrate that sleep-based optimization improves the quality of convolutional layers by the selective modification of spatial gradients across filters. We further show that, compared to other approaches such as fine-tuning, a single sleep phase improves robustness across different types of distortions in a data efficient manner.",
        "total_citations": 1
      },
      {
        "title": "Equipping pretrained unconditional music transformers with instrument and genre controls",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:-6RzNnnwWf8C",
        "authors": [
          "Weihan Xu",
          "Julian McAuley",
          "Shlomo Dubnov",
          "Hao-Wen Dong"
        ],
        "publication_date": "2023-12-15",
        "conference": "IEEE International Conference on Big Data",
        "pages": "4512-4517",
        "publisher": "IEEE",
        "description": "The \u201cpretraining-and-finetuning\u201d paradigm has become a norm for training domain-specific models in natural language processing and computer vision. In this work, we aim to examine this paradigm for symbolic music generation through leveraging the largest ever symbolic music dataset sourced from the MuseScore forum. We first pretrain a large unconditional transformer model using 1.5 million songs. We then propose a simple technique to equip this pretrained unconditional music transformer model with instrument and genre controls by finetuning the model with additional control tokens. Our proposed representation offers improved high-level controllability and expressiveness against two existing representations. The experimental results show that the proposed model can successfully generate music with user-specified instruments and genre. In a subjective listening test, the proposed model outperforms the\u00a0\u2026",
        "total_citations": 1
      },
      {
        "title": "Spoiler detection as semantic text matching",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:z6xuaG2dYH0C",
        "authors": [
          "Ryan Tran",
          "Canwen Xu",
          "Julian McAuley"
        ],
        "publication_date": "2023-12-17",
        "conference": "Empirical Methods in Natural Language Processing",
        "pages": "6109-6113",
        "description": "Engaging with discussion of TV shows online often requires individuals to refrain from consuming show-related content for extended periods to avoid spoilers. While existing research on spoiler detection shows promising results in safeguarding viewers from general spoilers, it fails to address the issue of users abstaining from show-related content during their watch. This is primarily because the definition of a spoiler varies depending on the viewer\u2019s progress in the show, and conventional spoiler detection methods lack the granularity to capture this complexity. To tackle this challenge, we propose the task of spoiler matching, which involves assigning an episode number to a spoiler given a specific TV show. We frame this task as semantic text matching and introduce a dataset comprised of comments and episode summaries to evaluate model performance. Given the length of each example, our dataset can also serve as a benchmark for long-range language models.",
        "total_citations": 1
      },
      {
        "title": "Using machine learning to understand determinants of IUD use in India: Analyses of the National Family Health Surveys (NFHS-4)",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:KNjnJ3z-R6IC",
        "authors": [
          "Arnab K Dey",
          "Nabamallika Dehingia",
          "Nandita Bhan",
          "Edwin Elizabeth Thomas",
          "Lotus McDougal",
          "Sarah Averbach",
          "Julian McAuley",
          "Abhishek Singh",
          "Anita Raj"
        ],
        "publication_date": "2022-09-01",
        "pages": "101234",
        "publisher": "Elsevier",
        "description": "Intra-uterine devices (IUDs) are a safe and effective method to delay or space pregnancies and are available for free or at low cost in the Indian public health system; yet, IUD uptake in India remains low. Limited quantitative research using national data has explored factors that may affect IUD use. Machine Learning (ML) techniques allow us to explore determinants of low prevalence behaviors in survey research, such as IUD use. We applied ML to explore the determinants of IUD use in India among married women in the 4th National Family Health Survey (NFHS-4; N\u00a0=\u00a0499,627), which collects data on demographic and health indicators among women of childbearing age. We conducted ML logistic regression (lasso and ridge) and neural network approaches to assess significant determinants and used iterative thematic analysis (ITA) to offer insight into related variable constructs generated from a series of\u00a0\u2026",
        "total_citations": 1
      },
      {
        "title": "Predicting risky behavior in social communities",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:zwpXiJ37cpgC",
        "authors": [
          "Olivia Simpson",
          "Julian McAuley"
        ],
        "publication_date": "2016-10-17",
        "conference": "International Workshop on Mining and Learning with Graphs",
        "description": "Predicting risk profiles of individuals in networks (e.g.~susceptibility to a particular disease, or likelihood of smoking) is challenging for a variety of reasons. For one, `local' features (such as an individual's demographic information) may lack sufficient information to make informative predictions; this is especially problematic when predicting `risk,' as the relevant features may be precisely those that an individual is disinclined to reveal in a survey. Secondly, even if such features are available, they still may miss crucial information, as `risk' may be a function not just of an individual's features but also those of their friends and social communities. Here, we predict individual's risk profiles as a function of both their local features and those of their friends. Instead of modeling influence from the social network directly (which proved difficult as friendship links may be sparse and partially observed), we instead model influence by discovering social communities in the network that may be related to risky behavior. The result is a model that predicts risk as a function of local features, while making up for their deficiencies and accounting for social influence by uncovering community structure in the network. We test our model by predicting risky behavior among adolescents from the Add health data set, and hometowns among users in a Facebook ego net. Compared to prediction by features alone, our model demonstrates better predictive accuracy when measured as a whole, and in particular when measured as a function of network \"richness.\"",
        "total_citations": 1
      },
      {
        "title": "TeaserGen: Generating Teasers for Long Documentaries",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:lg2tdxc6qMwC",
        "authors": [
          "Weihan Xu",
          "Paul Pu Liang",
          "Haven Kim",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick",
          "Hao-Wen Dong"
        ],
        "publication_date": "2024-10-08",
        "description": "Teasers are an effective tool for promoting content in entertainment, commercial and educational fields. However, creating an effective teaser for long videos is challenging for it requires long-range multimodal modeling on the input videos, while necessitating maintaining audiovisual alignments, managing scene changes and preserving factual accuracy for the output teasers. Due to the lack of a publicly-available dataset, progress along this research direction has been hindered. In this work, we present DocumentaryNet, a collection of 1,269 documentaries paired with their teasers, featuring multimodal data streams of video, speech, music, sound effects and narrations. With DocumentaryNet, we propose a new two-stage system for generating teasers from long documentaries. The proposed TeaserGen system first generates the teaser narration from the transcribed narration of the documentary using a pretrained large language model, and then selects the most relevant visual content to accompany the generated narration through language-vision models. For narration-video matching, we explore two approaches: a pretraining-based model using pretrained contrastive language-vision models and a deep sequential model that learns the mapping between the narrations and visuals. Our experimental results show that the pretraining-based approach is more effective at identifying relevant visual content than directly trained deep autoregressive models."
      },
      {
        "title": "MAWI Rec: Leveraging Severe Weather Data in Recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:WwIwg2wKZ0QC",
        "authors": [
          "Brendan Andrew Duncan",
          "Surya Kallumadi",
          "Taylor Berg-Kirkpatrick",
          "Julian Mcauley"
        ],
        "publication_date": "2024-10-08",
        "pages": "850-854",
        "description": "Inferring user intent in recommender systems can help performance but is difficult because intent is personal and not directly observable. Previous work has leveraged signals to stand as a proxy for intent (e.g. user interactions with resource pages), but such signals are not always available. In this paper, we instead recognize that certain events, which are observable, directly influence user intent. For example, after a flood, home improvement customers are more likely to undertake a renovation project to dry out their basement. We introduce MAWI Rec, a recommender system that leverages severe weather data to improve recommendation. Our weather-aware system achieves a significant improvement over a state-of-the-art baseline for online and in-store datasets of home improvement customers. This gain is most significant for weather-related product categories such as roof panels and flashings. "
      },
      {
        "title": "Neighborhood-Based Collaborative Filtering for Conversational Recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:PQEM9vzQD9gC",
        "authors": [
          "Zhouhang Xie",
          "Junda Wu",
          "Hyunsik Jeon",
          "Zhankui He",
          "Harald Steck",
          "Rahul Jha",
          "Dawen Liang",
          "Nathan Kallus",
          "Julian Mcauley"
        ],
        "publication_date": "2024-10-08",
        "pages": "1045-1050",
        "description": "Conversational recommender systems (CRS) should understand users\u2019 expressed interests, which are frequently semantically rich and knowledge-intensive. Prior works attempt to address this challenge by using external knowledge bases or parametric knowledge in large language models (LLMs). In this paper, we study a complementary solution, exploiting item knowledge in the training data. We hypothesize that many inference-time user requests can be answered by reusing popular crowd-written answers associated with similar training queries. Following this intuition, we define a class of neighborhood-based CRS that makes recommendations by identifying items commonly associated with similar training dialogue contexts. Experiments on Inspired, Redial, and Reddit-Movie benchmarks show our method outperforms state-of-the-art LLMs with 2 billion parameters, and offers on-par performance to 7 billion\u00a0\u2026"
      },
      {
        "title": "The 1st International Workshop on Risks, Opportunities, and Evaluation of Generative Models in Recommendation (ROEGEN)",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:sfnaS5RM6jYC",
        "authors": [
          "Yashar Deldjoo",
          "Julian Mcauley",
          "Scott Sanner",
          "Pablo Castells",
          "Shuai Zhang",
          "Enrico Palumbo"
        ],
        "publication_date": "2024-10-08",
        "pages": "1250-1252",
        "description": " We present an overview of a workshop focused on the exploration of generative models within recommender systems (RS). It highlights the dual nature of these technologies: on the one hand, they offer groundbreaking opportunities for enhancing RS through improved personalization, innovative content creation, and interactive user experiences; on the other hand, they introduce a range of challenges, including bias, misinformation, privacy concerns, and environmental impact.  The workshop, \u201cROEGen@RecSys. Risks, Opportunities, and Evaluations of Generative Models in Recommender Systems,\u201d aims to address these issues by bringing together the research community to discuss strategies for understanding, evaluating, and mitigating the potential negative impacts of these technologies.  The workshop will cover three main themes: (i) the risks and challenges posed by the deployment of generative models in\u00a0\u2026"
      },
      {
        "title": "Presto! Distilling Steps and Layers for Accelerating Music Generation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:N4u4nq0IxgcC",
        "authors": [
          "Zachary Novack",
          "Ge Zhu",
          "Jonah Casebeer",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick",
          "Nicholas J Bryan"
        ],
        "publication_date": "2024-10-07",
        "description": "Despite advances in diffusion-based text-to-music (TTM) methods, efficient, high-quality generation remains a challenge. We introduce Presto!, an approach to inference acceleration for score-based diffusion transformers via reducing both sampling steps and cost per step. To reduce steps, we develop a new score-based distribution matching distillation (DMD) method for the EDM-family of diffusion models, the first GAN-based distillation method for TTM. To reduce the cost per step, we develop a simple, but powerful improvement to a recent layer distillation method that improves learning via better preserving hidden state variance. Finally, we combine our step and layer distillation methods together for a dual-faceted approach. We evaluate our step and layer distillation methods independently and show each yield best-in-class performance. Our combined distillation method can generate high-quality outputs with improved diversity, accelerating our base model by 10-18x (230/435ms latency for 32 second mono/stereo 44.1kHz, 15x faster than comparable SOTA) -- the fastest high-quality TTM to our knowledge. Sound examples can be found at https://presto-music.github.io/web/."
      },
      {
        "title": "Inductive Generative Recommendation via Retrieval-based Speculation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:ymY9cBF3mdcC",
        "authors": [
          "Yijie Ding",
          "Yupeng Hou",
          "Jiacheng Li",
          "Julian McAuley"
        ],
        "publication_date": "2024-10-03",
        "description": "Generative recommendation (GR) is an emerging paradigm that tokenizes items into discrete tokens and learns to autoregressively generate the next tokens as predictions. Although effective, GR models operate in a transductive setting, meaning they can only generate items seen during training without applying heuristic re-ranking strategies. In this paper, we propose SpecGR, a plug-and-play framework that enables GR models to recommend new items in an inductive setting. SpecGR uses a drafter model with inductive capability to propose candidate items, which may include both existing items and new items. The GR model then acts as a verifier, accepting or rejecting candidates while retaining its strong ranking capabilities. We further introduce the guided re-drafting technique to make the proposed candidates more aligned with the outputs of generative recommendation models, improving the verification efficiency. We consider two variants for drafting: (1) using an auxiliary drafter model for better flexibility, or (2) leveraging the GR model's own encoder for parameter-efficient self-drafting. Extensive experiments on three real-world datasets demonstrate that SpecGR exhibits both strong inductive recommendation ability and the best overall performance among the compared methods. Our code is available at: https://github.com/Jamesding000/SpecGR."
      },
      {
        "title": "CoLLAP: Contrastive Long-form Language-Audio Pretraining with Musical Temporal Structure Augmentation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:hNSvKAmkeYkC",
        "authors": [
          "Junda Wu",
          "Warren Li",
          "Zachary Novack",
          "Amit Namburi",
          "Carol Chen",
          "Julian McAuley"
        ],
        "publication_date": "2024-10-03",
        "description": "Modeling temporal characteristics plays a significant role in the representation learning of audio waveform. We propose Contrastive Long-form Language-Audio Pretraining (\\textbf{CoLLAP}) to significantly extend the perception window for both the input audio (up to 5 minutes) and the language descriptions (exceeding 250 words), while enabling contrastive learning across modalities and temporal dynamics. Leveraging recent Music-LLMs to generate long-form music captions for full-length songs, augmented with musical temporal structures, we collect 51.3K audio-text pairs derived from the large-scale AudioSet training dataset, where the average audio length reaches 288 seconds. We propose a novel contrastive learning architecture that fuses language representations with structured audio representations by segmenting each song into clips and extracting their embeddings. With an attention mechanism, we capture multimodal temporal correlations, allowing the model to automatically weigh and enhance the final fusion score for improved contrastive alignment. Finally, we develop two variants of the CoLLAP model with different types of backbone language models. Through comprehensive experiments on multiple long-form music-text retrieval datasets, we demonstrate consistent performance improvement in retrieval accuracy compared with baselines. We also show the pretrained CoLLAP models can be transferred to various music information retrieval tasks, with heterogeneous long-form multimodal contexts."
      },
      {
        "title": "Generating Symbolic Music from Natural Language Prompts using an LLM-Enhanced Dataset",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:M0leSnx2MbUC",
        "authors": [
          "Weihan Xu",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick",
          "Shlomo Dubnov",
          "Hao-Wen Dong"
        ],
        "publication_date": "2024-10-02",
        "description": "Recent years have seen many audio-domain text-to-music generation models that rely on large amounts of text-audio pairs for training. However, symbolic-domain controllable music generation has lagged behind partly due to the lack of a large-scale symbolic music dataset with extensive metadata and captions. In this work, we present MetaScore, a new dataset consisting of 963K musical scores paired with rich metadata, including free-form user-annotated tags, collected from an online music forum. To approach text-to-music generation, we leverage a pretrained large language model (LLM) to generate pseudo natural language captions from the metadata. With the LLM-enhanced MetaScore, we train a text-conditioned music generation model that learns to generate symbolic music from the pseudo captions, allowing control of instruments, genre, composer, complexity and other free-form music descriptors. In addition, we train a tag-conditioned system that supports a predefined set of tags available in MetaScore. Our experimental results show that both the proposed text-to-music and tags-to-music models outperform a baseline text-to-music model in a listening test, while the text-based system offers a more natural interface that allows free-form natural language prompts."
      },
      {
        "title": "Self-Updatable Large Language Models with Parameter Integration",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:pYKElYtJMmwC",
        "authors": [
          "Yu Wang",
          "Xinshuang Liu",
          "Xiusi Chen",
          "Sean O'Brien",
          "Junda Wu",
          "Julian McAuley"
        ],
        "publication_date": "2024-10-01",
        "description": "Despite significant advancements in large language models (LLMs), the rapid and frequent integration of small-scale experiences, such as interactions with surrounding objects, remains a substantial challenge. Two critical factors in assimilating these experiences are (1) Efficacy: the ability to accurately remember recent events; (2) Retention: the capacity to recall long-past experiences. Current methods either embed experiences within model parameters using continual learning, model editing, or knowledge distillation techniques, which often struggle with rapid updates and complex interactions, or rely on external storage to achieve long-term retention, thereby increasing storage requirements. In this paper, we propose SELF-PARAM (Self-Updatable Large Language Models with Parameter Integration). SELF-PARAM requires no extra parameters while ensuring near-optimal efficacy and long-term retention. Our method employs a training objective that minimizes the Kullback-Leibler (KL) divergence between the predictions of an original model (with access to contextual information) and a target model (without such access). By generating diverse question-answer pairs related to the knowledge and minimizing the KL divergence across this dataset, we update the target model to internalize the knowledge seamlessly within its parameters. Evaluations on question-answering and conversational recommendation tasks demonstrate that SELF-PARAM significantly outperforms existing methods, even when accounting for non-zero storage requirements. This advancement paves the way for more efficient and scalable integration of experiences in\u00a0\u2026"
      },
      {
        "title": "Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:9DLIHnF0jcYC",
        "authors": [
          "Yueqi Wang",
          "Zhenrui Yue",
          "Huimin Zeng",
          "Dong Wang",
          "Julian McAuley"
        ],
        "publication_date": "2024-09-25",
        "description": "Despite recent advancements in language and vision modeling, integrating rich multimodal knowledge into recommender systems continues to pose significant challenges. This is primarily due to the need for efficient recommendation, which requires adaptive and interactive responses. In this study, we focus on sequential recommendation and introduce a lightweight framework called full-scale Matryoshka representation learning for multimodal recommendation (fMRLRec). Our fMRLRec captures item features at different granularities, learning informative representations for efficient recommendation across multiple dimensions. To integrate item features from diverse modalities, fMRLRec employs a simple mapping to project multimodal item features into an aligned feature space. Additionally, we design an efficient linear transformation that embeds smaller features into larger ones, substantially reducing memory requirements for large-scale training on recommendation data. Combined with improved state space modeling techniques, fMRLRec scales to different dimensions and only requires one-time training to produce multiple models tailored to various granularities. We demonstrate the effectiveness and efficiency of fMRLRec on multiple benchmark datasets, which consistently achieves superior performance over state-of-the-art baseline methods."
      },
      {
        "title": "Towards LifeSpan Cognitive Systems",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:jlhcAiayVhoC",
        "authors": [
          "Yu Wang",
          "Chi Han",
          "Tongtong Wu",
          "Xiaoxin He",
          "Wangchunshu Zhou",
          "Nafis Sadeq",
          "Xiusi Chen",
          "Zexue He",
          "Wei Wang",
          "Gholamreza Haffari",
          "Heng Ji",
          "Julian McAuley"
        ],
        "publication_date": "2024-09-20",
        "description": "Building a human-like system that continuously interacts with complex environments -- whether simulated digital worlds or human society -- presents several key challenges. Central to this is enabling continuous, high-frequency interactions, where the interactions are termed experiences. We refer to this envisioned system as the LifeSpan Cognitive System (LSCS). A critical feature of LSCS is its ability to engage in incremental and rapid updates while retaining and accurately recalling past experiences. We identify two major challenges in achieving this: (1) Abstraction and Experience Merging, and (2) Long-term Retention with Accurate Recall. These properties are essential for storing new experiences, organizing past experiences, and responding to the environment in ways that leverage relevant historical data. Unlike language models with continual learning, which typically rely on large corpora for fine-tuning and focus on improving performance within specific domains or tasks, LSCS must rapidly and incrementally update with new information from its environment at a high frequency. Existing technologies with the potential of solving the above two major challenges can be classified into four classes based on a conceptual metric called Storage Complexity, which measures the relative space required to store past experiences. Each of these four classes of technologies has its own strengths and limitations. Given that none of the existing technologies can achieve LSCS alone, we propose a novel paradigm for LSCS that integrates all four classes of technologies. The new paradigm operates through two core processes: Absorbing Experiences\u00a0\u2026"
      },
      {
        "title": "PDMX: A Large-Scale Public Domain MusicXML Dataset for Symbolic Music Processing",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:R-LXmdHK_14C",
        "authors": [
          "Phillip Long",
          "Zachary Novack",
          "Taylor Berg-Kirkpatrick",
          "Julian McAuley"
        ],
        "publication_date": "2024-09-17",
        "description": "The recent explosion of generative AI-Music systems has raised numerous concerns over data copyright, licensing music from musicians, and the conflict between open-source AI and large prestige companies. Such issues highlight the need for publicly available, copyright-free musical data, in which there is a large shortage, particularly for symbolic music data. To alleviate this issue, we present PDMX: a large-scale open-source dataset of over 250K public domain MusicXML scores collected from the score-sharing forum MuseScore, making it the largest available copyright-free symbolic music dataset to our knowledge. PDMX additionally includes a wealth of both tag and user interaction metadata, allowing us to efficiently analyze the dataset and filter for high quality user-generated scores. Given the additional metadata afforded by our data collection process, we conduct multitrack music generation experiments evaluating how different representative subsets of PDMX lead to different behaviors in downstream models, and how user-rating statistics can be used as an effective measure of data quality. Examples can be found at https://pnlong.github.io/PDMX.demo/."
      },
      {
        "title": "Multi-modal Generative Models in Recommendation System",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:4Yq6kJLCcecC",
        "authors": [
          "Arnau Ramisa",
          "Rene Vidal",
          "Yashar Deldjoo",
          "Zhankui He",
          "Julian McAuley",
          "Anton Korikov",
          "Scott Sanner",
          "Mahesh Sathiamoorthy",
          "Atoosa Kasrizadeh",
          "Silvia Milano",
          "Francesco Ricci"
        ],
        "publication_date": "2024-09-17",
        "description": "Many recommendation systems limit user inputs to text strings or behavior signals such as clicks and purchases, and system outputs to a list of products sorted by relevance. With the advent of generative AI, users have come to expect richer levels of interactions. In visual search, for example, a user may provide a picture of their desired product along with a natural language modification of the content of the picture (e.g., a dress like the one shown in the picture but in red color). Moreover, users may want to better understand the recommendations they receive by visualizing how the product fits their use case, e.g., with a representation of how a garment might look on them, or how a furniture item might look in their room. Such advanced levels of interaction require recommendation systems that are able to discover both shared and complementary information about the product across modalities, and visualize the product in a realistic and informative way. However, existing systems often treat multiple modalities independently: text search is usually done by comparing the user query to product titles and descriptions, while visual search is typically done by comparing an image provided by the customer to product images. We argue that future recommendation systems will benefit from a multi-modal understanding of the products that leverages the rich information retailers have about both customers and products to come up with the best recommendations. In this chapter we review recommendation systems that use multiple data modalities simultaneously."
      },
      {
        "title": "First Workshop on Generative AI for Recommender Systems and Personalization",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:iyewoVqAXLQC",
        "authors": [
          "Narges Tabari",
          "Aniket Anand Deshmukh",
          "Wang-Cheng Kang",
          "Hamed Zamani",
          "Rashmi Gangadharaiah",
          "Julian McAuley",
          "George Karypis"
        ],
        "publication_date": "2024-08-25",
        "pages": "6737-6738",
        "description": "Personalization is key in understanding user behavior and has been a main focus in the fields of knowledge discovery and information retrieval. Building personalized recommender systems is especially important now due to the vast amount of user-generated textual content, which offers deep insights into user preferences. The recent advancements in Large Language Models (LLMs) have significantly impacted research areas, mainly in Natural Language Processing and Knowledge Discovery, giving these models the ability to handle complex tasks and learn context. However, the use of generative models and user-generated text for personalized systems and recommendation is relatively new and has shown some promising results. This workshop is designed to bridge the research gap in these fields and explore personalized applications and recommender systems. We aim to fully leverage generative models\u00a0\u2026"
      },
      {
        "title": "Large Language Model Driven Recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:ji7lAbPyDbYC",
        "authors": [
          "Anton Korikov",
          "Scott Sanner",
          "Yashar Deldjoo",
          "Zhankui He",
          "Julian McAuley",
          "Arnau Ramisa",
          "Rene Vidal",
          "Mahesh Sathiamoorthy",
          "Atoosa Kasrizadeh",
          "Silvia Milano",
          "Francesco Ricci"
        ],
        "publication_date": "2024-08-20",
        "description": "While previous chapters focused on recommendation systems (RSs) based on standardized, non-verbal user feedback such as purchases, views, and clicks -- the advent of LLMs has unlocked the use of natural language (NL) interactions for recommendation. This chapter discusses how LLMs' abilities for general NL reasoning present novel opportunities to build highly personalized RSs -- which can effectively connect nuanced and diverse user preferences to items, potentially via interactive dialogues. To begin this discussion, we first present a taxonomy of the key data sources for language-driven recommendation, covering item descriptions, user-system interactions, and user profiles. We then proceed to fundamental techniques for LLM recommendation, reviewing the use of encoder-only and autoregressive LLM recommendation in both tuned and untuned settings. Afterwards, we move to multi-module recommendation architectures in which LLMs interact with components such as retrievers and RSs in multi-stage pipelines. This brings us to architectures for conversational recommender systems (CRSs), in which LLMs facilitate multi-turn dialogues where each turn presents an opportunity not only to make recommendations, but also to engage with the user in interactive preference elicitation, critiquing, and question-answering."
      },
      {
        "title": "Unlocking Decoding-time Controllability: Gradient-Free Multi-Objective Alignment with Contrastive Prompts",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:m4fbC6XIj1kC",
        "authors": [
          "Tingchen Fu",
          "Yupeng Hou",
          "Julian McAuley",
          "Rui Yan"
        ],
        "publication_date": "2024-08-09",
        "description": "The task of multi-objective alignment aims at balancing and controlling the different alignment objectives (e.g., helpfulness, harmlessness and honesty) of large language models to meet the personalized requirements of different users. However, previous methods tend to train multiple models to deal with various user preferences, with the number of trained models growing linearly with the number of alignment objectives and the number of different preferences. Meanwhile, existing methods are generally poor in extensibility and require significant re-training for each new alignment objective considered. Considering the limitation of previous approaches, we propose MCA (Multi-objective Contrastive Alignemnt), which constructs an expert prompt and an adversarial prompt for each objective to contrast at the decoding time and balances the objectives through combining the contrast. Our approach is verified to be superior to previous methods in obtaining a well-distributed Pareto front among different alignment objectives."
      },
      {
        "title": "Forecasting Live Chat Intent from Browsing History",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:wUn16MOA3RoC",
        "authors": [
          "Se-eun Yoon",
          "Ahmad Bin Rabiah",
          "Zaid Alibadi",
          "Surya Kallumadi",
          "Julian McAuley"
        ],
        "publication_date": "2024-08-07",
        "description": "Customers reach out to online live chat agents with various intents, such as asking about product details or requesting a return. In this paper, we propose the problem of predicting user intent from browsing history and address it through a two-stage approach. The first stage classifies a user's browsing history into high-level intent categories. Here, we represent each browsing history as a text sequence of page attributes and use the ground-truth class labels to fine-tune pretrained Transformers. The second stage provides a large language model (LLM) with the browsing history and predicted intent class to generate fine-grained intents. For automatic evaluation, we use a separate LLM to judge the similarity between generated and ground-truth intents, which closely aligns with human judgments. Our two-stage approach yields significant performance gains compared to generating intents without the classification stage."
      },
      {
        "title": "Calibration-Disentangled Learning and Relevance-Prioritized Reranking for Calibrated Sequential Recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:eI34FqJmdUoC",
        "authors": [
          "Hyunsik Jeon",
          "Se-eun Yoon",
          "Julian McAuley"
        ],
        "publication_date": "2024-08-04",
        "description": "Calibrated recommendation, which aims to maintain personalized proportions of categories within recommendations, is crucial in practical scenarios since it enhances user satisfaction by reflecting diverse interests. However, achieving calibration in a sequential setting (i.e., calibrated sequential recommendation) is challenging due to the need to adapt to users' evolving preferences. Previous methods typically leverage reranking algorithms to calibrate recommendations after training a model without considering the effect of calibration and do not effectively tackle the conflict between relevance and calibration during the reranking process. In this work, we propose LeapRec (Calibration-Disentangled Learning and Relevance-Prioritized Reranking), a novel approach for the calibrated sequential recommendation that addresses these challenges. LeapRec consists of two phases, model training phase and reranking phase. In the training phase, a backbone model is trained using our proposed calibration-disentangled learning-to-rank loss, which optimizes personalized rankings while integrating calibration considerations. In the reranking phase, relevant items are prioritized at the top of the list, with items needed for calibration following later to address potential conflicts between relevance and calibration. Through extensive experiments on four real-world datasets, we show that LeapRec consistently outperforms previous methods in the calibrated sequential recommendation. Our code is available at https://github.com/jeon185/LeapRec."
      },
      {
        "title": "DeCoT: Debiasing Chain-of-Thought for Knowledge-Intensive Tasks in Large Language Models via Causal Intervention",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:m92CDrhVnKEC",
        "authors": [
          "Junda Wu",
          "Tong Yu",
          "Xiang Chen",
          "Haoliang Wang",
          "Ryan Rossi",
          "Sungchul Kim",
          "Anup Rao",
          "Julian McAuley"
        ],
        "publication_date": "2024-08-17",
        "conference": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
        "pages": "14073-14087",
        "description": "Large language models (LLMs) often require task-relevant knowledge to augment their internal knowledge through prompts. However, simply injecting external knowledge into prompts does not guarantee that LLMs can identify and use relevant information in the prompts to conduct chain-of-thought reasoning, especially when the LLM\u2019s internal knowledge is derived from biased information on the pretraining data. In this paper, we propose a novel causal view to formally explain the internal knowledge bias of LLMs via a Structural Causal Model (SCM). We review the chain-of-thought (CoT) prompting from a causal perspective and discover that the biased information from pretrained models can impair LLMs\u2019 reasoning abilities. When the CoT reasoning paths are misled by irrelevant information from prompts and are logically incorrect, simply editing factual information is insufficient to reach the correct answer. To estimate the confounding effect on CoT reasoning in LLMs, we use external knowledge as an instrumental variable. We further introduce CoT as a mediator to conduct front-door adjustment and generate logically correct CoTs where the spurious correlation between LLMs\u2019 pretrained knowledge and task queries is reduced. With extensive experiments, we validate that our approach enables more accurate CoT reasoning and enhances LLM generation on knowledge-intensive tasks."
      },
      {
        "title": "Fair Sequential Recommendation without User Demographics",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:ijdKiLOsEJMC",
        "authors": [
          "Huimin Zeng",
          "Zhankui He",
          "Zhenrui Yue",
          "Julian McAuley",
          "Dong Wang"
        ],
        "publication_date": "2024-07-10",
        "pages": "395-404",
        "description": "Much existing literature on fair recommendation (i.e., group fairness) leverages users' demographic attributes (e.g., gender) to develop fair recommendation methods. However, in real-world scenarios, due to privacy concerns and convenience considerations, users may not be willing to share their demographic information with the system, which limits the application of many existing methods. Moreover, sequential recommendation (SR) models achieve state-of-the-art performance compared to traditional collaborative filtering (CF) recommenders, and can represent users solely using user-item interactions (user-free). This leaves a wrong impression that SR models are free from group unfairness by design. In this work, we explore a critical question: how can we build a fair sequential recommendation system without even knowing user demographics? To address this problem, we propose Agnostic FairSeqRec (A\u00a0\u2026"
      },
      {
        "title": "Avoiding Decision Fatigue with AI-Assisted Decision-Making",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:wSy_KLzO7YEC",
        "authors": [
          "Jessica Maria Echterhoff",
          "Aditya Melkote",
          "Sujen Kancherla",
          "Julian McAuley"
        ],
        "publication_date": "2024-06-22",
        "pages": "1-11",
        "description": " During online browsing, e.g.\u00a0when looking to select a movie to watch, we are often confronted with multiple rejection-selection steps which can lead to tens or hundreds of decisions made in quick succession. It is unclear if showing the next \u201cbest\u201d item, as often employed by standard recommenders, is the most efficient way to help users select an item. In this work, we show that we can reduce the number of decisions to selection with a reinforcement learning-based Decision Minimizer Network (DMN). By implementing a step-aware reward function we can penalize long sequences, leading to fewer decisions having to be made by humans. Using a task to select a movie to watch, we show that we can reduce the number of decisions to selection by 39% compared to heuristic strategies and by 20% compared to standard recommender while increasing user selection satisfaction. Minimizing the number of decision\u00a0\u2026"
      },
      {
        "title": "Automatic Pair Construction for Contrastive Post-training",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:BOlwja0KXvYC",
        "authors": [
          "Canwen Xu",
          "Corby Rosset",
          "Ethan Chau",
          "Luciano Corro",
          "Shweti Mahajan",
          "Julian McAuley",
          "Jennifer Neville",
          "Ahmed Awadallah",
          "Nikhil Rao"
        ],
        "publication_date": "2024-06-17",
        "conference": "Findings of the Association for Computational Linguistics: NAACL 2024",
        "pages": "149-162",
        "description": "Alignment serves as an important step to steer large language models (LLMs) towards human preferences. In this paper, we propose an automatic way to construct contrastive data for LLM, using preference pairs from multiple models of varying strengths (eg, InstructGPT, ChatGPT and GPT-4). We compare the contrastive techniques of SLiC and DPO to SFT baselines and find that DPO provides a step-function improvement even after continuing SFT saturates. We also explore a data curriculum learning scheme for contrastive post-training, which starts by learning from \u201ceasier\u201d pairs and transitioning to \u201charder\u201d ones, which further improves alignment. Finally, we scale up our experiments to train with more data and larger models like Orca. Remarkably, our automatic contrastive post-training further improves the performance of Orca, already a state-of-the-art instruction learning model tuned with GPT-4 outputs, to outperform ChatGPT."
      },
      {
        "title": "Imagery as Inquiry: Exploring A Multimodal Dataset for Conversational Recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:jmjb1lOE9QIC",
        "authors": [
          "Se-eun Yoon",
          "Hyunsik Jeon",
          "Julian McAuley"
        ],
        "publication_date": "2024-05-23",
        "description": "We introduce a multimodal dataset where users express preferences through images. These images encompass a broad spectrum of visual expressions ranging from landscapes to artistic depictions. Users request recommendations for books or music that evoke similar feelings to those captured in the images, and recommendations are endorsed by the community through upvotes. This dataset supports two recommendation tasks: title generation and multiple-choice selection. Our experiments with large foundation models reveal their limitations in these tasks. Particularly, vision-language models show no significant advantage over language-only counterparts that use descriptions, which we hypothesize is due to underutilized visual capabilities. To better harness these abilities, we propose the chain-of-imagery prompting, which results in notable improvements. We release our code and datasets."
      },
      {
        "title": "Reindex-Then-Adapt: Improving Large Language Models for Conversational Recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:pQTOvowfQioC",
        "authors": [
          "Zhankui He",
          "Zhouhang Xie",
          "Harald Steck",
          "Dawen Liang",
          "Rahul Jha",
          "Nathan Kallus",
          "Julian McAuley"
        ],
        "publication_date": "2024-05-20",
        "description": "Large language models (LLMs) are revolutionizing conversational recommender systems by adeptly indexing item content, understanding complex conversational contexts, and generating relevant item titles. However, controlling the distribution of recommended items remains a challenge. This leads to suboptimal performance due to the failure to capture rapidly changing data distributions, such as item popularity, on targeted conversational recommendation platforms. In conversational recommendation, LLMs recommend items by generating the titles (as multiple tokens) autoregressively, making it difficult to obtain and control the recommendations over all items. Thus, we propose a Reindex-Then-Adapt (RTA) framework, which converts multi-token item titles into single tokens within LLMs, and then adjusts the probability distributions over these single-token item titles accordingly. The RTA framework marries the benefits of both LLMs and traditional recommender systems (RecSys): understanding complex queries as LLMs do; while efficiently controlling the recommended item distributions in conversational recommendations as traditional RecSys do. Our framework demonstrates improved accuracy metrics across three different conversational recommendation datasets and two adaptation settings"
      },
      {
        "title": "Few-shot Dialogue Strategy Learning for Motivational Interviewing via Inductive Reasoning",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:TaaCk18tZOkC",
        "authors": [
          "Zhouhang Xie",
          "Bodhisattwa Prasad Majumder",
          "Mengjie Zhao",
          "Yoshinori Maeda",
          "Keiichi Yamada",
          "Hiromi Wakaki",
          "Julian McAuley"
        ],
        "publication_date": "2024-03-23",
        "description": "We consider the task of building a dialogue system that can motivate users to adopt positive lifestyle changes: Motivational Interviewing. Addressing such a task requires a system that can infer \\textit{how} to motivate a user effectively. We propose DIIT, a framework that is capable of learning and applying conversation strategies in the form of natural language inductive rules from expert demonstrations. Automatic and human evaluation on instruction-following large language models show natural language strategy descriptions discovered by DIIR can improve active listening skills, reduce unsolicited advice, and promote more collaborative and less authoritative responses, outperforming various demonstration utilization methods."
      },
      {
        "title": "Generating, Reconstructing, and Representing Discrete and Continuous Data: Generalized Diffusion with Learnable Encoding-Decoding",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:LGlY6t8CeOMC",
        "authors": [
          "Guangyi Liu",
          "Yu Wang",
          "Zeyu Feng",
          "Qiyu Wu",
          "Liping Tang",
          "Yuan Gao",
          "Zhen Li",
          "Shuguang Cui",
          "Julian McAuley",
          "Eric P Xing",
          "Zichao Yang",
          "Zhiting Hu"
        ],
        "publication_date": "2024-02-29",
        "description": "The vast applications of deep generative models are anchored in three core capabilities -- generating new instances, reconstructing inputs, and learning compact representations -- across various data types, such as discrete text/protein sequences and continuous images. Existing model families, like Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), autoregressive models, and diffusion models, generally excel in specific capabilities and data types but fall short in others. We introduce generalized diffusion with learnable encoder-decoder (DiLED), that seamlessly integrates the core capabilities for broad applicability and enhanced performance. DiLED generalizes the Gaussian noising-denoising in standard diffusion by introducing parameterized encoding-decoding. Crucially, DiLED is compatible with the well-established diffusion model objective and training recipes, allowing effective learning of the encoder-decoder parameters jointly with diffusion. By choosing appropriate encoder/decoder (e.g., large language models), DiLED naturally applies to different data types. Extensive experiments on text, proteins, and images demonstrate DiLED's flexibility to handle diverse data and tasks and its strong improvement over various existing models."
      },
      {
        "title": "RecWizard: A toolkit for conversational recommendation with modular, portable models and interactive user interface",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:YTuZlYwrTOUC",
        "authors": [
          "Zeyuan Zhang",
          "Tanmay Laud",
          "Zihang He",
          "Xiaojie Chen",
          "Xinshuang Liu",
          "Zhouhang Xie",
          "Julian McAuley",
          "Zhankui He"
        ],
        "publication_date": "2024-02-23",
        "conference": "AAAI (demo track)",
        "description": "We present a new Python toolkit called RecWizard for Conversational Recommender Systems (CRS). RecWizard offers support for development of models and interactive user interface, drawing from the best practices of the Huggingface ecosystems. CRS with RecWizard are modular, portable, interactive and Large Language Models (LLMs)-friendly, to streamline the learning process and reduce the additional effort for CRS research. For more comprehensive information about RecWizard, please check our GitHub https://github. com/McAuley-Lab/RecWizard."
      },
      {
        "title": "A Fashion Item Recommendation Model in Hyperbolic Space",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:4e5Qn2KL_jwC",
        "authors": [
          "Ryotaro Shimizu",
          "Yu Wang",
          "Masanari Kimura",
          "Yuki Hirakawa",
          "Takashi Wada",
          "Yuki Saito",
          "Julian McAuley"
        ],
        "publication_date": "2024-10-17",
        "conference": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
        "pages": "8377-8383",
        "description": "In this work we propose a fashion item recommendation model that incorporates hyperbolic geometry into user and item representations. Using hyperbolic space our model aims to capture implicit hierarchies among items based on their visual data and users' purchase history. During training we apply a multi-task learning framework that considers both hyperbolic and Euclidean distances in the loss function. Our experiments on three data sets show that our model performs better than previous models trained in Euclidean space only confirming the effectiveness of our model. Our ablation studies show that multi-task learning plays a key role and removing the Euclidean loss substantially deteriorates the model performance."
      },
      {
        "title": "Special Issue on Responsible Recommender Systems Part 1",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:sJPMR1oEGYQC",
        "authors": [
          "Lina Yao",
          "Julian McAuley",
          "Xianzhi Wang",
          "Dietmar Jannach"
        ],
        "publication_date": "2024-10-17",
        "publisher": "ACM",
        "description": "Recommender systems are information filtering systems that suggest items tailored to individual users or user groups. They represent a powerful machine learning tool to support various human decision-making activities in e-commerce, social networks, entertainment, transportation, healthcare, and cybersecurity. Existing recommender systems typically focus on accuracy and personalization but increasingly call for an effective means of ensuring the systems work responsibly. Without appropriate responsible techniques, recommender systems could have undesired effects on users, communities, and society. For example, a recommendation algorithm trained on imbalanced data might be biased toward catering to the preferences of a majority group of users while overlooking minority groups; a system without countermeasures to misinformation may amplify the spread of misinformation, and a recommendation that\u00a0\u2026"
      },
      {
        "title": "Unified Generation, Reconstruction, and Representation: Generalized Diffusion with Adaptive Latent Encoding-Decoding",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:wLxue7F8ec0C",
        "authors": [
          "Guangyi Liu",
          "Yu Wang",
          "Zeyu Feng",
          "Qiyu Wu",
          "Liping Tang",
          "Yuan Gao",
          "Zhen Li",
          "Shuguang Cui",
          "Julian McAuley",
          "Zichao Yang",
          "Eric P Xing",
          "Zhiting Hu"
        ],
        "publication_date": "2024-10-17",
        "conference": "International Conference on Machine Learning",
        "description": "The vast applications of deep generative models are anchored in three core capabilities---*generating* new instances, *reconstructing* inputs, and learning compact *representations*---across various data types, such as discrete text/protein sequences and continuous images. Existing model families, like variational autoencoders (VAEs), generative adversarial networks (GANs), autoregressive models, and (latent) diffusion models, generally excel in specific capabilities and data types but fall short in others. We introduce *Generalized*  ***E****ncoding*-***D****ecoding ****D****iffusion ****P****robabilistic ****M****odels* (EDDPMs) which integrate the core capabilities for broad applicability and enhanced performance. EDDPMs generalize the Gaussian noising-denoising in standard diffusion by introducing parameterized encoding-decoding. Crucially, EDDPMs are compatible with the well-established diffusion model objective and training recipes, allowing effective learning of the encoder-decoder parameters *jointly* with diffusion. By choosing appropriate encoder/decoder (e.g., large language models), EDDPMs naturally apply to different data types. Extensive experiments on text, proteins, and images demonstrate the flexibility to handle diverse data and tasks and the strong improvement over various existing models. Code is available at https://github.com/guangyliu/EDDPM ."
      },
      {
        "title": "Self-Supervised Bot Play for Transcript-Free Conversational Critiquing with Rationales",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:c59VksA5Vz4C",
        "authors": [
          "Shuyang Li",
          "Bodhisattwa Prasad Majumder",
          "Julian McAuley"
        ],
        "publication_date": "2024-10-17",
        "publisher": "ACM",
        "description": "Conversational critiquing in recommender systems offers a way for users to engage in multi-turn conversations to find items they enjoy. For users to trust an agent and give effective feedback, the recommender system must be able to explain its suggestions and rationales. We develop a two-part framework for training multi-turn conversational critiquing in recommender systems that provide recommendation rationales that users can effectively interact with to receive better recommendations. First, we train a recommender system to jointly suggest items and explain its reasoning via subjective rationales. We then fine-tune this model to incorporate iterative user feedback via self-supervised bot-play. Experiments on three real-world datasets demonstrate that our system can be applied to different recommendation models across diverse domains to achieve state-of-the-art performance in multi-turn recommendation\u00a0\u2026"
      },
      {
        "title": "InfoRank: Unbiased Learning-to-Rank via Conditional Mutual Information Minimization",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:YlPif8NxrbYC",
        "authors": [
          "Jiarui Jin",
          "Zexue He",
          "Mengyue Yang",
          "Weinan Zhang",
          "Yong Yu",
          "Jun Wang",
          "Julian McAuley"
        ],
        "publication_date": "2024-10-17",
        "conference": "WWW",
        "description": "Ranking items regarding individual user interests is a core technique of multiple downstream tasks such as recommender systems. Learning such a personalized ranker typically relies on the implicit feedback from users' past click-through behaviors. However, collected feedback is biased toward previously highly-ranked items and directly learning from it would result in \"rich-get-richer\" phenomena. In this paper, we propose a simple yet sufficient unbiased learning-to-rank paradigm named InfoRank that aims to simultaneously address both position and popularity biases. We begin by consolidating the impacts of those biases into a single observation factor, thereby providing a unified approach to addressing bias-related issues. Subsequently, we minimize the mutual information between the observation estimation and the relevance estimation conditioned on the input features. By doing so, our relevance estimation\u00a0\u2026"
      },
      {
        "title": "Generating a personalized preference ranking network for providing visually-aware item recommendations",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:LgRImbQfgY4C",
        "publication_date": "2023-11-21",
        "description": "The present disclosure relates to a fashion recommendation system that employs a task-guided learning framework to jointly train a visually-aware personalized preference ranking network. In addition, the fashion recommendation system employs implicit feedback and generated user-based triplets to learn variances in the user's fashion preferences for items with which the user has not yet interacted. In particular, the fashion recommendation system uses triplets generated from implicit user data to jointly train a Siamese convolutional neural network and a personalized ranking model, which together produce a user preference predictor that determines personalized fashion recommendations for a user."
      },
      {
        "title": "Robust multi-view fracture detection in the presence of other abnormalities using HAMIL-Net",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:tHtfpZlB6tUC",
        "authors": [
          "Xing Lu",
          "Eric Y Chang",
          "Jiang Du",
          "An Yan",
          "Julian McAuley",
          "Amilcare Gentili",
          "Chun-Nan Hsu"
        ],
        "publication_date": "2023-11-01",
        "pages": "590-597",
        "publisher": "Oxford University Press",
        "description": " Introduction Foot and ankle fractures are the most common military health problem. Automated diagnosis can save time and personnel. It is crucial to distinguish fractures not only from normal healthy cases, but also robust against the presence of other orthopedic pathologies. Artificial intelligence (AI) deep learning has been shown to be promising. Previously, we have developed HAMIL-Net to automatically detect orthopedic injuries for upper extremity injuries. In this research, we investigated the performance of HAMIL-Net for detecting foot and ankle fractures in the presence of other abnormalities. Materials and Methods HAMIL-Net is a novel deep neural network consisting of a hierarchical attention layer followed by a multiple-instance learning layer. The design allowed it to deal with imaging studies with multiple views. We used 148K musculoskeletal imaging studies for 51K\u00a0\u2026"
      },
      {
        "title": "Extending Input Contexts of Language Models through Training on Segmented Sequences",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:isU91gLudPYC",
        "authors": [
          "Petros Karypis",
          "Julian McAuley",
          "George Karypis"
        ],
        "publication_date": "2023-10-23",
        "description": "Effectively training language models on long inputs poses many technical challenges. As a cost consideration, languages models are pretrained on a fixed sequence length before being adapted to longer sequences. We explore various methods for adapting models to longer inputs by training on segmented sequences and an interpolation-based method for extending absolute positional embeddings. We develop a training procedure to extend the input context size of pretrained models with no architectural changes and no additional memory costs than training on the original input lengths. By sub-sampling segments from long inputs while maintaining their original position the model is able to learn new positional interactions. Our method benefits both models trained with absolute positional embeddings, by extending their input contexts, as well as popular relative positional embedding methods showing a reduced perplexity on sequences longer than they were trained on. We demonstrate our method can extend input contexts by a factor of 4x while improving perplexity."
      },
      {
        "title": "Unsupervised Lead Sheet Generation via Semantic Compression",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:ghEM2AJqZyQC",
        "authors": [
          "Zachary Novack",
          "Nikita Srivatsan",
          "Taylor Berg-Kirkpatrick",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-16",
        "description": "Lead sheets have become commonplace in generative music research, being used as an initial compressed representation for downstream tasks like multitrack music generation and automatic arrangement. Despite this, researchers have often fallen back on deterministic reduction methods (such as the skyline algorithm) to generate lead sheets when seeking paired lead sheets and full scores, with little attention being paid toward the quality of the lead sheets themselves and how they accurately reflect their orchestrated counterparts. To address these issues, we propose the problem of conditional lead sheet generation (i.e. generating a lead sheet given its full score version), and show that this task can be formulated as an unsupervised music compression task, where the lead sheet represents a compressed latent version of the score. We introduce a novel model, called Lead-AE, that models the lead sheets as a discrete subselection of the original sequence, using a differentiable top-k operator to allow for controllable local sparsity constraints. Across both automatic proxy tasks and direct human evaluations, we find that our method improves upon the established deterministic baseline and produces coherent reductions of large multitrack scores."
      },
      {
        "title": "Jointly modeling products and resource pages for task-oriented recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:silx2ntsSuwC",
        "authors": [
          "Brendan Duncan",
          "Surya Kallumadi",
          "Taylor Berg-Kirkpatrick",
          "Julian McAuley"
        ],
        "publication_date": "2023-04-30",
        "pages": "432-436",
        "description": " Modeling high-level user intent in recommender systems can improve performance, although it is often difficult to obtain a ground truth measure of this intent. In this paper, we investigate a novel way to obtain such an intent signal by leveraging resource pages associated with a particular task. We jointly model product interactions and resource page interactions to create a system which can recommend both products and resource pages to users. Our experiments consider the domain of home improvement product recommendation, where resource pages are DIY (do-it-yourself) project pages from Lowes.com. Each DIY page provides a list of tools, materials, and step-by-step instructions to complete a DIY project, such as building a deck, installing cabinets, and fixing a leaking pipe. We use this data as an indicator of the intended project, which is a natural high-level intent signal for home improvement shoppers. We\u00a0\u2026"
      },
      {
        "title": "A survey on dynamic neural networks for natural language processing",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:H_jBuBxbQIAC",
        "authors": [
          "Xu Canwen",
          "McAuley Julian"
        ],
        "publication_date": "2023-10-17",
        "conference": "Findings of EACL"
      },
      {
        "title": "UCEpic: Unifying aspect planning and lexical constraints for explainable recommendation",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=200&pagesize=100&citation_for_view=icbo4M0AAAAJ:pAkWuXOU-OoC",
        "authors": [
          "Jiacheng Li",
          "Zhankui He",
          "Jingbo Shang",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-17",
        "conference": "KDD"
      },
      {
        "title": "On Faithfulness and Coherence of Language Explanations for Recommendation Systems",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=300&pagesize=100&citation_for_view=icbo4M0AAAAJ:-95Q15plzcUC",
        "authors": [
          "Zhouhang Xie",
          "Julian McAuley",
          "Bodhisattwa Prasad Majumder"
        ],
        "publication_date": "2022-09-12",
        "description": "Reviews contain rich information about product characteristics and user interests and thus are commonly used to boost recommender system performance. Specifically, previous work show that jointly learning to perform review generation improves rating prediction performance. Meanwhile, these model-produced reviews serve as recommendation explanations, providing the user with insights on predicted ratings. However, while existing models could generate fluent, human-like reviews, it is unclear to what degree the reviews fully uncover the rationale behind the jointly predicted rating. In this work, we perform a series of evaluations that probes state-of-the-art models and their review generation component. We show that the generated explanations are brittle and need further evaluation before being taken as literal rationales for the estimated ratings."
      },
      {
        "title": "Recommender Systems",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=300&pagesize=100&citation_for_view=icbo4M0AAAAJ:z8nqeaKD1nsC",
        "authors": [
          "Julian McAuley"
        ],
        "publication_date": "2022-10-17",
        "description": "Every day we interact with predictive systems that seek to model our behavior, monitor our activities, and make recommendations: Whom will we befriend? What articles will we like? What products will we purchase? Who influences us in our social network? And do our activities change over time? Models that answer such questions drive important real-world systems, and at the same time are of basic scientific interest to economists, linguists, and social scientists, among others. Recommender Systems aim to solve tasks such as those above, by learning from large volumes of historical activities to describe the dynamics of user preferences and the properties of the content users interact with. Recommender systems can take many forms (Table 1), though in essence all boil down to modeling the interactions between users and content, in order to predict future actions and preferences. In this chapter, we investigate a\u00a0\u2026"
      },
      {
        "title": "Deep generation of user-customized items",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=300&pagesize=100&citation_for_view=icbo4M0AAAAJ:8xutWZnSdmoC",
        "publication_date": "2021-06-24",
        "description": "The present disclosure relates to a personalized fashion generation system that synthesizes user-customized images using deep learning techniques based on visually-aware user preferences. In particular, the personalized fashion generation system employs an image generative adversarial neural network and a personalized preference network to synthesize new fashion items that are individually customized for a user. Additionally, the personalized fashion generation system can modify existing fashion items to tailor the fashion items to a user's tastes and preferences."
      },
      {
        "title": "Mastering Task Arithmetic: Jp as a Key Indicator for Weight Disentanglement",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=300&pagesize=100&citation_for_view=icbo4M0AAAAJ:Vr2j17o0sqMC",
        "authors": [
          "Kotaro Yoshida",
          "Yuji Naraki",
          "Takafumi Horie",
          "Ryosuke Yamaki",
          "Ryotaro Shimizu",
          "Yuki Saito",
          "Julian McAuley",
          "Hiroki Naganuma"
        ],
        "conference": "NeurIPS 2024 Workshop on Fine-Tuning in Modern Machine Learning: Principles and Scalability",
        "description": "Model-editing techniques using task arithmetic (Ilharco et al., 2022) have rapidly gained attention. Through task arithmetic, simply through arithmetic operations on the weights of pre-trained and fine-tuned models create desired models, such as multi-task models, models with specific tasks unsolvable, or domain-transferred models. However, task arithmetic faces challenges, such as low reproducibility and the high cost associated with adjusting coefficients in the arithmetic operations on model parameters, which have limited its practical success. In this paper, we present three key contributions in the context of task addition and task negation within task arithmetic. First, we propose a new metric called Jp which is based on the product of the task vector () and the Jacobian of the pre-trained model with respect to its weights. We show that Jp has a causal relationship with the interference that occurs from arithmetic operations. Second, we show that introducing regularization to minimize Jp significantly mitigates interference between task inferences, which leads to eliminating coefficient tuning and better accuracy on each task. Third, in the context of continual learning, we confirmed that our Jp regularization demonstrates more robust performance in environments where future tasks to be learned are not accessible, confirming the scalability of the approach. Finally, we demonstrate that the Jp regularizer further reinforces the performance of task arithmetic by leveraging publicly available fine-tuned models, offering practical benefits for real-world applications."
      },
      {
        "title": "A Fashion Item Recommendation Model in Hyperbolic Space (Supplementary Material)",
        "link": "/citations?view_op=view_citation&hl=en&user=icbo4M0AAAAJ&cstart=300&pagesize=100&citation_for_view=icbo4M0AAAAJ:qmtmRrLr0tkC",
        "authors": [
          "Ryotaro Shimizu",
          "Yu Wang",
          "Masanari Kimura",
          "Yuki Hirakawa",
          "Takashi Wada",
          "Yuki Saito",
          "Julian McAuley"
        ],
        "description": "Out of five isometric models for modeling hyperbolic space [1, 2, 6, 15]: the Poincar\u00e9 ball model, the Poincar\u00e9 half-space model, the Lorentz model, the Klein model, and the Hemisphere model, this paper adopts the Poincar\u00e9 ball model, one of the most common models in computer vision [6, 8, 9, 13]."
      }
    ]
  },
  {
    "name": "Phillip Long",
    "scholar_id": "PNA6qVMAAAAJ",
    "publications": [
      {
        "title": "The utility of a closed breeding colony of Peromyscus leucopus for dissecting complex traits",
        "link": "/citations?view_op=view_citation&hl=en&user=PNA6qVMAAAAJ&pagesize=100&citation_for_view=PNA6qVMAAAAJ:u5HHmVD_uO8C",
        "authors": [
          "Phillip N Long",
          "Vanessa J Cook",
          "Arundhati Majumder",
          "Alan G Barbour",
          "Anthony D Long"
        ],
        "publication_date": "2022-05-01",
        "pages": "iyac026",
        "publisher": "Oxford University Press",
        "description": " Deermice of the genus Peromyscus are well suited for addressing several questions of biologist interest, including the genetic bases of longevity, behavior, physiology, adaptation, and their ability to serve as disease vectors. Here, we explore a diversity outbred approach for dissecting complex traits in Peromyscus leucopus, a nontraditional genetic model system. We take advantage of a closed colony of deer-mice founded from 38 individuals and subsequently maintained for \u223c40\u201360 generations. From 405 low-pass short-read sequenced deermice we accurate impute genotypes at 16 million single nucleotide polymorphisms. Conditional on observed genotypes simulations were conducted in which three different sized quantitative trait loci contribute to a complex trait under three different genetic models. Using a stringent significance threshold power was modest, largely a function of the percent variation\u00a0\u2026",
        "total_citations": 6
      },
      {
        "title": "PDMX: A Large-Scale Public Domain MusicXML Dataset for Symbolic Music Processing",
        "link": "/citations?view_op=view_citation&hl=en&user=PNA6qVMAAAAJ&pagesize=100&citation_for_view=PNA6qVMAAAAJ:u-x6o8ySG0sC",
        "authors": [
          "Phillip Long",
          "Zachary Novack",
          "Taylor Berg-Kirkpatrick",
          "Julian McAuley"
        ],
        "publication_date": "2024-09-17",
        "description": "The recent explosion of generative AI-Music systems has raised numerous concerns over data copyright, licensing music from musicians, and the conflict between open-source AI and large prestige companies. Such issues highlight the need for publicly available, copyright-free musical data, in which there is a large shortage, particularly for symbolic music data. To alleviate this issue, we present PDMX: a large-scale open-source dataset of over 250K public domain MusicXML scores collected from the score-sharing forum MuseScore, making it the largest available copyright-free symbolic music dataset to our knowledge. PDMX additionally includes a wealth of both tag and user interaction metadata, allowing us to efficiently analyze the dataset and filter for high quality user-generated scores. Given the additional metadata afforded by our data collection process, we conduct multitrack music generation experiments evaluating how different representative subsets of PDMX lead to different behaviors in downstream models, and how user-rating statistics can be used as an effective measure of data quality. Examples can be found at https://pnlong.github.io/PDMX.demo/."
      }
    ]
  },
  {
    "name": "Ross Greer",
    "scholar_id": "ZAX3UCwAAAAJ",
    "publications": [
      {
        "title": "Trajectory prediction in autonomous driving with a lane heading auxiliary loss",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:u-x6o8ySG0sC",
        "authors": [
          "Ross Greer",
          "Nachiket Deo",
          "Mohan Trivedi"
        ],
        "publication_date": "2021-03-25",
        "pages": "4907-4914",
        "publisher": "IEEE",
        "description": "Predicting a vehicle's trajectory is an essential ability for autonomous vehicles navigating through complex urban traffic scenes. Bird's-eye-view roadmap information provides valuable information for making trajectory predictions, and while state-of-the-art models extract this information via image convolution, auxiliary loss functions can augment patterns inferred from deep learning by further encoding common knowledge of social and legal driving behaviors. Since human driving behavior is inherently multimodal, models which allow for multimodal output tend to outperform single-prediction models on standard metrics. We propose a loss function which enhances such models by enforcing expected driving rules on all predicted modes. Our contribution to trajectory prediction is twofold; we propose a new metric which addresses failure cases of the off-road rate metric by penalizing trajectories that oppose the\u00a0\u2026",
        "total_citations": 45
      },
      {
        "title": "Autonomous vehicles that alert humans to take-over controls: Modeling with real-world data",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:d1gkVwhDpl0C",
        "authors": [
          "Akshay Rangesh",
          "Nachiket Deo",
          "Ross Greer",
          "Pujitha Gunaratne",
          "Mohan M Trivedi"
        ],
        "publication_date": "2021-09-19",
        "conference": "2021 IEEE International Intelligent Transportation Systems Conference (ITSC)",
        "pages": "231-236",
        "publisher": "IEEE",
        "description": "With increasing automation in passenger vehicles, the study of safe and smooth occupant-vehicle interaction and control transitions is key. In this study, we focus on the development of contextual, semantically meaningful representations of the driver state, which can then be used to determine the appropriate timing and conditions for transfer of control between driver and vehicle. To this end, we conduct a large-scale real-world controlled data study where participants are instructed to take-over control from an autonomous agent under different driving conditions while engaged in a variety of distracting activities. These take-over events are captured using multiple driver-facing cameras, which when labelled result in a dataset of control transitions and their corresponding takeover times (TOTs). We then develop and train TOT models that operate sequentially on mid to high-level features produced by computer vision\u00a0\u2026",
        "total_citations": 22
      },
      {
        "title": "On salience-sensitive sign classification in autonomous vehicle path planning: Experimental explorations with a novel dataset",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:2osOgNQ5qMEC",
        "authors": [
          "Ross Greer",
          "Jason Isa",
          "Nachiket Deo",
          "Akshay Rangesh",
          "Mohan M Trivedi"
        ],
        "publication_date": "2022-10-17",
        "conference": "Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision",
        "pages": "636-644",
        "description": "Safe path planning in autonomous driving is a complex task due to the interplay of static scene elements and uncertain surrounding agents. While all static scene elements are a source of information, there is asymmetric importance to the information available to the ego vehicle. We present a dataset with a novel feature, sign salience, defined to indicate whether a sign is distinctly informative to the goals of the ego vehicle with regards to traffic regulations. Using convolutional networks on cropped signs, in tandem with experimental augmentation by road type, image coordinates, and planned maneuver, we predict the sign salience property with 76% accuracy, finding the best improvement using information on vehicle maneuver with sign images.",
        "total_citations": 16
      },
      {
        "title": "Salient Sign Detection in Safe Autonomous Driving: AI Which Reasons Over Full Visual Context",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:KlAtU1dfN6UC",
        "authors": [
          "Ross Greer",
          "Akshay Gopalkrishnan",
          "Nachiket Deo",
          "Akshay Rangesh",
          "Mohan Trivedi"
        ],
        "publication_date": "2023-10-17",
        "conference": "27th International Technical Conference on the Enhanced Safety of Vehicles (ESV)",
        "description": "Detecting road traffic signs and accurately determining how they can affect the driver's future actions is a critical task for safe autonomous driving systems. However, various traffic signs in a driving scene have an unequal impact on the driver's decisions, making detecting the salient traffic signs a more important task. Our research addresses this issue, constructing a traffic sign detection model which emphasizes performance on salient signs, or signs that influence the decisions of a driver. We define a traffic sign salience property and use it to construct the LAVA Salient Signs Dataset, the first traffic sign dataset that includes an annotated salience property. Next, we use a custom salience loss function, Salience-Sensitive Focal Loss, to train a Deformable DETR object detection model in order to emphasize stronger performance on salient signs. Results show that a model trained with Salience-Sensitive Focal Loss outperforms a model trained without, with regards to recall of both salient signs and all signs combined. Further, the performance margin on salient signs compared to all signs is largest for the model trained with Salience-Sensitive Focal Loss.",
        "total_citations": 14
      },
      {
        "title": "ActiveAnno3D--An Active Learning Framework for Multi-Modal 3D Object Detection",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:mVmsd5A6BfQC",
        "authors": [
          "Ahmed Ghita",
          "Bj\u00f8rk Antoniussen",
          "Walter Zimmer",
          "Ross Greer",
          "Christian Cre\u00df",
          "Andreas M\u00f8gelmose",
          "Mohan M Trivedi",
          "Alois C Knoll"
        ],
        "publication_date": "2024-02-05",
        "description": "The curation of large-scale datasets is still costly and requires much time and resources. Data is often manually labeled, and the challenge of creating high-quality datasets remains. In this work, we fill the research gap using active learning for multi-modal 3D object detection. We propose ActiveAnno3D, an active learning framework to select data samples for labeling that are of maximum informativeness for training. We explore various continuous training methods and integrate the most efficient method regarding computational demand and detection performance. Furthermore, we perform extensive experiments and ablation studies with BEVFusion and PV-RCNN on the nuScenes and TUM Traffic Intersection dataset. We show that we can achieve almost the same performance with PV-RCNN and the entropy-based query strategy when using only half of the training data (77.25 mAP compared to 83.50 mAP) of the TUM Traffic Intersection dataset. BEVFusion achieved an mAP of 64.31 when using half of the training data and 75.0 mAP when using the complete nuScenes dataset. We integrate our active learning framework into the proAnno labeling tool to enable AI-assisted data selection and labeling and minimize the labeling costs. Finally, we provide code, weights, and visualization results on our website: https://active3d-framework.github.io/active3d-framework.",
        "total_citations": 11
      },
      {
        "title": "Robust Traffic Light Detection Using Salience-Sensitive Loss: Computational Framework and Evaluations",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:3fE2CSJIrl8C",
        "authors": [
          "Ross Greer",
          "Akshay Gopalkrishnan",
          "Jacob Landgren",
          "Lulua Rakla",
          "Anish Gopalan",
          "Mohan Trivedi"
        ],
        "publication_date": "2023-07-27",
        "conference": "2023 IEEE Intelligent Vehicles Symposium (IV)",
        "description": "One of the most important tasks for ensuring safe autonomous driving systems is accurately detecting road traffic lights and accurately determining how they impact the driver\u2019s actions. In various real-world driving situations, a scene may have numerous traffic lights with varying levels of relevance to the driver, and thus, distinguishing and detecting the lights that are relevant to the driver and influence the driver\u2019s actions is a critical safety task. This paper proposes a traffic light detection model which focuses on this task by first defining salient lights as the lights that affect the driver\u2019s future decisions. We then use this salience property to construct the LAVA Salient Lights Dataset, the first US traffic light dataset with an annotated salience property. Subsequently, we train a Deformable DETR object detection transformer model using Salience-Sensitive Focal Loss to emphasize stronger performance on salient traffic\u00a0\u2026",
        "total_citations": 11
      },
      {
        "title": "Ensemble learning for fusion of multiview vision with occlusion and missing information: Framework and evaluations with real-world data and applications in driver hand activity\u00a0\u2026",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:dhFuZR0502QC",
        "authors": [
          "Ross Greer",
          "Mohan Trivedi"
        ],
        "publication_date": "2023-01-30",
        "description": "Multi-sensor frameworks provide opportunities for ensemble learning and sensor fusion to make use of redundancy and supplemental information, helpful in real-world safety applications such as continuous driver state monitoring which necessitate predictions even in cases where information may be intermittently missing. We define this problem of intermittent instances of missing information (by occlusion, noise, or sensor failure) and design a learning framework around these data gaps, proposing and analyzing an imputation scheme to handle missing information. We apply these ideas to tasks in camera-based hand activity classification for robust safety during autonomous driving. We show that a late-fusion approach between parallel convolutional neural networks can outperform even the best-placed single camera model in estimating the hands' held objects and positions when validated on within-group subjects, and that our multi-camera framework performs best on average in cross-group validation, and that the fusion approach outperforms ensemble weighted majority and model combination schemes.",
        "total_citations": 11
      },
      {
        "title": "Safe Control Transitions: Machine Vision Based Observable Readiness Index and Data-Driven Takeover Time Prediction",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:kNdYIx-mwKoC",
        "authors": [
          "Ross Greer",
          "Nachiket Deo",
          "Akshay Rangesh",
          "Pujitha Gunaratne",
          "Mohan Trivedi"
        ],
        "publication_date": "2023-10-17",
        "conference": "27th International Technical Conference on the Enhanced Safety of Vehicles (ESV)",
        "description": "To make safe transitions from autonomous to manual control, a vehicle must have a representation of the awareness of driver state; two metrics which quantify this state are the Observable Readiness Index and Takeover Time. In this work, we show that machine learning models which predict these two metrics are robust to multiple camera views, expanding from the limited view angles in prior research. Importantly, these models take as input feature vectors corresponding to hand location and activity as well as gaze location, and we explore the tradeoffs of different views in generating these feature vectors. Further, we introduce two metrics to evaluate the quality of control transitions following the takeover event (the maximal lateral deviation and velocity deviation) and compute correlations of these post-takeover metrics to the pre-takeover predictive metrics.",
        "total_citations": 11
      },
      {
        "title": "Predicting take-over time for autonomous driving with real-world data: Robust data augmentation, models, and evaluation",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:9yKSN-GCB0IC",
        "authors": [
          "Akshay Rangesh",
          "Nachiket Deo",
          "Ross Greer",
          "Pujitha Gunaratne",
          "Mohan M Trivedi"
        ],
        "publication_date": "2021-07-27",
        "description": "Understanding occupant-vehicle interactions by modeling control transitions is important to ensure safe approaches to passenger vehicle automation. Models which contain contextual, semantically meaningful representations of driver states can be used to determine the appropriate timing and conditions for transfer of control between driver and vehicle. However, such models rely on real-world control take-over data from drivers engaged in distracting activities, which is costly to collect. Here, we introduce a scheme for data augmentation for such a dataset. Using the augmented dataset, we develop and train take-over time (TOT) models that operate sequentially on mid and high-level features produced by computer vision algorithms operating on different driver-facing camera views, showing models trained on the augmented dataset to outperform the initial dataset. The demonstrated model features encode different aspects of the driver state, pertaining to the face, hands, foot and upper body of the driver. We perform ablative experiments on feature combinations as well as model architectures, showing that a TOT model supported by augmented data can be used to produce continuous estimates of take-over times without delay, suitable for complex real-world scenarios.",
        "total_citations": 11
      },
      {
        "title": "Patterns of vehicle lights: Addressing complexities of camera-based vehicle light datasets and metrics",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:MXK_kJrjxJIC",
        "authors": [
          "Ross Greer",
          "Akshay Gopalkrishnan",
          "Maitrayee Keskar",
          "Mohan M Trivedi"
        ],
        "publication_date": "2024-02-01",
        "pages": "209-215",
        "publisher": "North-Holland",
        "description": "This paper explores the representation of vehicle lights in computer vision and its implications for various pattern recognition tasks in autonomous driving. Different representations for vehicle lights, including bounding boxes, center points, corner points, and segmentation masks, are discussed in terms of their strengths and weaknesses toward a variety of domain tasks, as well as associated data collection and annotation challenges. This leads to the introduction of the LISA Vehicle Lights Dataset, providing light annotations related to position, state, color, and signal, specifically designed for downstream applications in vehicle detection, intent and trajectory prediction, and safe path planning. A comparison of existing vehicle light datasets is provided, highlighting the unique features and limitations of each dataset. Because occlusions from vehicle pose and passing objects can limit camera observation, we introduce\u00a0\u2026",
        "total_citations": 10
      },
      {
        "title": "The Why, When, and How to Use Active Learning in Large-Data-Driven 3D Object Detection for Safe Autonomous Driving: An Empirical Exploration",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:4DMP91E08xMC",
        "authors": [
          "Ross Greer",
          "Bj\u00f8rk Antoniussen",
          "Mathias V Andersen",
          "Andreas M\u00f8gelmose",
          "Mohan M Trivedi"
        ],
        "publication_date": "2024-01-30",
        "description": "Active learning strategies for 3D object detection in autonomous driving datasets may help to address challenges of data imbalance, redundancy, and high-dimensional data. We demonstrate the effectiveness of entropy querying to select informative samples, aiming to reduce annotation costs and improve model performance. We experiment using the BEVFusion model for 3D object detection on the nuScenes dataset, comparing active learning to random sampling and demonstrating that entropy querying outperforms in most cases. The method is particularly effective in reducing the performance gap between majority and minority classes. Class-specific analysis reveals efficient allocation of annotated resources for limited data budgets, emphasizing the importance of selecting diverse and informative data for model training. Our findings suggest that entropy querying is a promising strategy for selecting data that enhances model learning in resource-constrained environments.",
        "total_citations": 10
      },
      {
        "title": "Pedestrian Behavior Maps for Safety Advisories: CHAMP Framework and Real-World Data Analysis",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:Zph67rFs4hoC",
        "authors": [
          "Ross Greer",
          "Samveed Desai",
          "Lulua Rakla",
          "Akshay Gopalkrishnan",
          "Afnan Alofi",
          "Mohan Trivedi"
        ],
        "publication_date": "2023-07-27",
        "conference": "2023 IEEE Intelligent Vehicles Symposium (IV)",
        "description": "It is critical for vehicles to prevent any collisions with pedestrians. Current methods for pedestrian collision prevention focus on integrating visual pedestrian detectors with Automatic Emergency Braking (AEB) systems which can trigger warnings and apply brakes as a pedestrian enters a vehicle\u2019s path. Unfortunately, pedestrian-detection-based systems can be hindered in certain situations such as night-time or when pedestrians are occluded. Our system addresses such issues using an online, map-based pedestrian detection aggregation system where common pedestrian locations are learned after repeated passes of locations. Using a carefully collected and annotated dataset in La Jolla, CA, we demonstrate the system\u2019s ability to learn pedestrian zones and generate advisory notices when a vehicle is approaching a pedestrian despite challenges like dark lighting or pedestrian occlusion. Using the number of\u00a0\u2026",
        "total_citations": 8
      },
      {
        "title": "Towards explainable, safe autonomous driving with language embeddings for novelty identification and active learning: Framework and experimental analysis with real-world data sets",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:9ZlFYXVOiuMC",
        "authors": [
          "Ross Greer",
          "Mohan Trivedi"
        ],
        "publication_date": "2024-02-11",
        "description": "This research explores the integration of language embeddings for active learning in autonomous driving datasets, with a focus on novelty detection. Novelty arises from unexpected scenarios that autonomous vehicles struggle to navigate, necessitating higher-level reasoning abilities. Our proposed method employs language-based representations to identify novel scenes, emphasizing the dual purpose of safety takeover responses and active learning. The research presents a clustering experiment using Contrastive Language-Image Pretrained (CLIP) embeddings to organize datasets and detect novelties. We find that the proposed algorithm effectively isolates novel scenes from a collection of subsets derived from two real-world driving datasets, one vehicle-mounted and one infrastructure-mounted. From the generated clusters, we further present methods for generating textual explanations of elements which differentiate scenes classified as novel from other scenes in the data pool, presenting qualitative examples from the clustered results. Our results demonstrate the effectiveness of language-driven embeddings in identifying novel elements and generating explanations of data, and we further discuss potential applications in safe takeovers, data curation, and multi-task active learning.",
        "total_citations": 7
      },
      {
        "title": "Multi-Frame, Lightweight & Efficient Vision-Language Models for Question Answering in Autonomous Driving",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:hC7cP41nSMkC",
        "authors": [
          "Akshay Gopalkrishnan",
          "Ross Greer",
          "Mohan Trivedi"
        ],
        "publication_date": "2024-03-28",
        "description": "Vision-Language Models (VLMs) and Multi-Modal Language models (MMLMs) have become prominent in autonomous driving research, as these models can provide interpretable textual reasoning and responses for end-to-end autonomous driving safety tasks using traffic scene images and other data modalities. However, current approaches to these systems use expensive large language model (LLM) backbones and image encoders, making such systems unsuitable for real-time autonomous driving systems where tight memory constraints exist and fast inference time is necessary. To address these previous issues, we develop EM-VLM4AD, an efficient, lightweight, multi-frame vision language model which performs Visual Question Answering for autonomous driving. In comparison to previous approaches, EM-VLM4AD requires at least 10 times less memory and floating point operations, while also achieving higher BLEU-4, METEOR, CIDEr, and ROGUE scores than the existing baseline on the DriveLM dataset. EM-VLM4AD also exhibits the ability to extract relevant information from traffic views related to prompts and can answer questions for various autonomous driving subtasks. We release our code to train and evaluate our model at https://github.com/akshaygopalkr/EM-VLM4AD.",
        "total_citations": 6
      },
      {
        "title": "Attention-based interventions for the management of pain and distress in young children (3-12 years) with burn injuries",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:Wp0gIr-vW9MC",
        "authors": [
          "K Miller",
          "B Kipping",
          "S Rodger",
          "R Greer",
          "RM Kimble"
        ],
        "publication_date": "2010-10-17",
        "total_citations": 5
      },
      {
        "title": "Deep and shallow: Machine learning in music and audio",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:Se3iqnhoufwC",
        "authors": [
          "Shlomo Dubnov",
          "Ross Greer"
        ],
        "publication_date": "2023-12-08",
        "publisher": "CRC Press",
        "description": "Providing an essential and unique bridge between the theories of signal processing, machine learning, and artificial intelligence (AI) in music, this book provides a holistic overview of foundational ideas in music, from the physical and mathematical properties of sound to symbolic representations. Combining signals and language models in one place, this book explores how sound may be represented and manipulated by computer systems, and how our devices may come to recognize particular sonic patterns as musically meaningful or creative through the lens of information theory. Introducing popular fundamental ideas in AI at a comfortable pace, more complex discussions around implementations and implications in musical creativity are gradually incorporated as the book progresses. Each chapter is accompanied by guided programming activities designed to familiarize readers with practical implications of discussed theory, without the frustrations of free-form coding. Surveying state-of-the art methods in applications of deep neural networks to audio and sound computing, as well as offering a research perspective that suggests future challenges in music and AI research, this book appeals to both students of AI and music, as well as industry professionals in the fields of machine learning, music, and AI.",
        "total_citations": 4
      },
      {
        "title": "Robust detection, assocation, and localization of vehicle lights: A context-based cascaded CNN approach and evaluations",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:UebtZRa9Y70C",
        "authors": [
          "Akshay Gopalkrishnan",
          "Ross Greer",
          "Maitrayee Keskar",
          "Mohan Trivedi"
        ],
        "publication_date": "2023-07-27",
        "description": "Vehicle light detection is required for important downstream safe autonomous driving tasks, such as predicting a vehicle's light state to determine if the vehicle is making a lane change or turning. Currently, many vehicle light detectors use single-stage detectors which predict bounding boxes to identify a vehicle light, in a manner decoupled from vehicle instances. In this paper, we present a method for detecting a vehicle light given an upstream vehicle detection and approximation of a visible light's center. Our method predicts four approximate corners associated with each vehicle light. We experiment with CNN architectures, data augmentation, and contextual preprocessing methods designed to reduce surrounding-vehicle confusion. We achieve an average distance error from the ground truth corner of 5.09 pixels, about 17.24% of the size of the vehicle light on average. We train and evaluate our model on the LISA Lights dataset, allowing us to thoroughly evaluate our vehicle light corner detection model on a large variety of vehicle light shapes and lighting conditions. We propose that this model can be integrated into a pipeline with vehicle detection and vehicle light center detection to make a fully-formed vehicle light detection network, valuable to identifying trajectory-informative signals in driving scenes.",
        "total_citations": 3
      },
      {
        "title": "From Pedestrian Detection to Crosswalk Estimation: An EM Algorithm, Analysis, and Evaluations on Diverse Datasets",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:zYLM7Y9cAGgC",
        "authors": [
          "Ross Greer",
          "Mohan Trivedi"
        ],
        "publication_date": "2022-10-17",
        "conference": "International Conference on Machine Learning, Workshop on Safe Learning for Autonomous Driving",
        "total_citations": 3
      },
      {
        "title": "Create a large-scale video driving dataset with detailed attributes using Amazon SageMaker Ground Truth",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:Y0pCki6q_DkC",
        "authors": [
          "Ninad Kulkarni",
          "Akshay Rangesh",
          "Jonathan Buck",
          "Jeremy Feltracco",
          "Mohan Trivedi",
          "Nachiket Deo",
          "Ross Greer",
          "Saman Sarraf",
          "Suchitra Sathyanarayana"
        ],
        "publication_date": "2021-06-22",
        "total_citations": 3
      },
      {
        "title": "Restoring Eye Contact to the Virtual Classroom with Machine Learning",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:qjMakFHDy7sC",
        "authors": [
          "Ross Greer",
          "Shlomo Dubnov"
        ],
        "publication_date": "2021-10-17",
        "conference": "13th International Conference on Computer Supported Education",
        "pages": "698-708",
        "description": "Nonverbal communication, in particular eye contact, is a critical element of the music classroom, shown to keep students on task, coordinate musical flow, and communicate improvisational ideas. Unfortunately, this nonverbal aspect to performance and pedagogy is lost in the virtual classroom. In this paper, we propose a machine learning system which uses single instance, single camera image frames as input to estimate the gaze target of a user seated in front of their computer, augmenting the user's video feed with a display of the estimated gaze target and thereby restoring nonverbal communication of directed gaze. The proposed estimation system consists of modular machine learning blocks, leading to a target-oriented (rather than coordinate-oriented) gaze prediction. We instantiate one such example of the complete system to run a pilot study in a virtual music classroom over Zoom software. Inference time and accuracy meet benchmarks for videoconferencing applications, and quantitative and qualitative results of pilot experiments include improved success of cue interpretation and student-reported formation of collaborative, communicative relationships between conductor and musician.",
        "total_citations": 3
      },
      {
        "title": "Perception Without Vision for Trajectory Prediction: Ego Vehicle Dynamics as Scene Representation for Efficient Active Learning in Autonomous Driving",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:R3hNpaxXUhUC",
        "authors": [
          "Ross Greer",
          "Mohan Trivedi"
        ],
        "publication_date": "2024-05-15",
        "description": "This study investigates the use of trajectory and dynamic state information for efficient data curation in autonomous driving machine learning tasks. We propose methods for clustering trajectory-states and sampling strategies in an active learning framework, aiming to reduce annotation and data costs while maintaining model performance. Our approach leverages trajectory information to guide data selection, promoting diversity in the training data. We demonstrate the effectiveness of our methods on the trajectory prediction task using the nuScenes dataset, showing consistent performance gains over random sampling across different data pool sizes, and even reaching sub-baseline displacement errors at just 50% of the data cost. Our results suggest that sampling typical data initially helps overcome the ''cold start problem,'' while introducing novelty becomes more beneficial as the training pool size increases. By integrating trajectory-state-informed active learning, we demonstrate that more efficient and robust autonomous driving systems are possible and practical using low-cost data curation strategies.",
        "total_citations": 2
      },
      {
        "title": "Language-Driven Active Learning for Diverse Open-Set 3D Object Detection",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:-f6ydRqryjwC",
        "authors": [
          "Ross Greer",
          "Bj\u00f8rk Antoniussen",
          "Andreas M\u00f8gelmose",
          "Mohan Trivedi"
        ],
        "publication_date": "2024-04-19",
        "description": "Object detection is crucial for ensuring safe autonomous driving. However, data-driven approaches face challenges when encountering minority or novel objects in the 3D driving scene. In this paper, we propose VisLED, a language-driven active learning framework for diverse open-set 3D Object Detection. Our method leverages active learning techniques to query diverse and informative data samples from an unlabeled pool, enhancing the model's ability to detect underrepresented or novel objects. Specifically, we introduce the Vision-Language Embedding Diversity Querying (VisLED-Querying) algorithm, which operates in both open-world exploring and closed-world mining settings. In open-world exploring, VisLED-Querying selects data points most novel relative to existing data, while in closed-world mining, it mines new instances of known classes. We evaluate our approach on the nuScenes dataset and demonstrate its effectiveness compared to random sampling and entropy-querying methods. Our results show that VisLED-Querying consistently outperforms random sampling and offers competitive performance compared to entropy-querying despite the latter's model-optimality, highlighting the potential of VisLED for improving object detection in autonomous driving scenarios.",
        "total_citations": 2
      },
      {
        "title": "Towards data-driven methods for decarbonizing reverse osmosis desalination",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:qUcmZB5y_30C",
        "authors": [
          "Om Sanan",
          "Joshua Sperling",
          "David Greene",
          "Ross Greer"
        ],
        "publication_date": "2023-10-06",
        "conference": "2023 IEEE MIT Undergraduate Research Technology Conference (URTC)",
        "pages": "1-5",
        "publisher": "IEEE",
        "description": "Desalination, when combined with energy-efficient operations and clean energy, has significant potential to address water security, resilience, and costs. Energy demands of desali-nation must be met, yet current inefficiencies increase costs, and the use of non-renewable sources exacerbates climate change. This research seeks to fill these gaps by advancing integrated water-energy system decarbonization, using data from multiple U.S. desalination plants while defining optimization functions and constraints to reduce energy costs and carbon emissions. A framework is designed for the optimal sizing of grid-connected hybrid renewable energy and storage systems using Artificial Intelligence algorithms to utilize at least 50% renewables.",
        "total_citations": 2
      },
      {
        "title": "Forecasting Weather and Energy Demand for Optimization of Renewable Energy and Energy Storage Systems for Water Desalination",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:IWHjjKOFINEC",
        "authors": [
          "Om Sanan",
          "Joshua Sperling",
          "David Greene",
          "Ross Greer"
        ],
        "publication_date": "2024-04-14",
        "conference": "2024 IEEE Conference on Technologies for Sustainability (SusTech)",
        "pages": "175-182",
        "publisher": "IEEE",
        "description": "The increasing intensity and frequency of water scarcity, carbon emissions, and climate risks pose critical challenges necessitating increased uptake of and a paradigm shift to energy-and climate-smart water desalination processes. This study employs metrics and a decision framework to enable and accelerate the energy efficiency, decarbonization, and costeffectiveness of water desalination processes. As an essential step, we analyze various Renewable Energy (RE) sources, such as photovoltaic, wind, concentrated solar power, geothermal, and hydro energy; in addition, we examine battery storage systems to address the intermittency challenges associated with solar and wind energy. The feasibility of these diverse RE systems was assessed at four (4) mid-to-large scale US desalination plants using operating plant and weather/environmental data, establishing optimization functions and constraints. In this research, to facilitate a comprehensive Energy Management System (EMS), we align RE generation with the anticipated energy demand of the plants. Machine Learning (ML) models, including SARIMA, Random Forest, XGBoost, and Gradient Boosting, are employed for forecasting water production, energy consumption, and longterm weather. The results show that Artificial Intelligence (AI) models, notably Gradient Boosting and an innovative XGBoost average method, demonstrated high accuracy in forecasting critical variables for RE systems in water desalination, with a normalized Root Mean Square Error of less than 10% for key metrics. This study can serve as a basis to optimize the mix of hybrid RE systems to minimize cost and\u00a0\u2026",
        "total_citations": 1
      },
      {
        "title": "Vision-based Analysis of Driver Activity and Driving Performance Under the Influence of Alcohol",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:5nxA0vEk-isC",
        "authors": [
          "Ross Greer",
          "Akshay Gopalkrishnan",
          "Sumega Mandadi",
          "Pujitha Gunaratne",
          "Mohan M Trivedi",
          "Thomas D Marcotte"
        ],
        "publication_date": "2023-09-14",
        "description": "About 30% of all traffic crash fatalities in the United States involve drunk drivers, making the prevention of drunk driving paramount to vehicle safety in the US and other locations which have a high prevalence of driving while under the influence of alcohol. Driving impairment can be monitored through active use of sensors (when drivers are asked to engage in providing breath samples to a vehicle instrument or when pulled over by a police officer), but a more passive and robust mechanism of sensing may allow for wider adoption and benefit of intelligent systems that reduce drunk driving accidents. This could assist in identifying impaired drivers before they drive, or early in the driving process (before a crash or detection by law enforcement). In this research, we introduce a study which adopts a multi-modal ensemble of visual, thermal, audio, and chemical sensors to (1) examine the impact of acute alcohol administration on driving performance in a driving simulator, and (2) identify data-driven methods for detecting driving under the influence of alcohol. We describe computer vision and machine learning models for analyzing the driver's face in thermal imagery, and introduce a pipeline for training models on data collected from drivers with a range of breath-alcohol content levels, including discussion of relevant machine learning phenomena which can help in future experiment design for related studies.",
        "total_citations": 1
      },
      {
        "title": "(Safe) SMART Hands: Hand Activity Analysis and Distraction Alerts Using a Multi-Camera Framework",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:WF5omc3nYNoC",
        "authors": [
          "Ross Greer",
          "Lulua Rakla",
          "Anish Gopalan",
          "Mohan Trivedi"
        ],
        "publication_date": "2023-01-14",
        "description": "Manual (hand-related) activity is a significant source of crash risk while driving. Accordingly, analysis of hand position and hand activity occupation is a useful component to understanding a driver's readiness to take control of a vehicle. Visual sensing through cameras provides a passive means of observing the hands, but its effectiveness varies depending on camera location. We introduce an algorithmic framework, SMART Hands, for accurate hand classification with an ensemble of camera views using machine learning. We illustrate the effectiveness of this framework in a 4-camera setup, reaching 98% classification accuracy on a variety of locations and held objects for both of the driver's hands. We conclude that this multi-camera framework can be extended to additional tasks such as gaze and pose analysis, with further applications in driver and passenger safety.",
        "total_citations": 1
      },
      {
        "title": "Creativity and Visual Communication from Machine to Musician: Sharing a Score through a Robotic Camera",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:blknAaTinKkC",
        "authors": [
          "Ross Greer",
          "Laura Fleig",
          "Shlomo Dubnov"
        ],
        "publication_date": "2024-09-09",
        "description": "This paper explores the integration of visual communication and musical interaction by implementing a robotic camera within a \"Guided Harmony\" musical game. We aim to examine co-creative behaviors between human musicians and robotic systems. Our research explores existing methodologies like improvisational game pieces and extends these concepts to include robotic participation using a PTZ camera. The robotic system interprets and responds to nonverbal cues from musicians, creating a collaborative and adaptive musical experience. This initial case study underscores the importance of intuitive visual communication channels. We also propose future research directions, including parameters for refining the visual cue toolkit and data collection methods to understand human-machine co-creativity further. Our findings contribute to the broader understanding of machine intelligence in augmenting human creativity, particularly in musical settings."
      },
      {
        "title": "Transfer Learning from Simulated to Real Scenes for Monocular 3D Object Detection",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:JV2RwH3_ST0C",
        "authors": [
          "Sondos Mohamed",
          "Walter Zimmer",
          "Ross Greer",
          "Ahmed Alaaeldin Ghita",
          "Modesto Castrill\u00f3n-Santana",
          "Mohan Trivedi",
          "Alois Knoll",
          "Salvatore Mario Carta",
          "Mirko Marras"
        ],
        "publication_date": "2024-08-28",
        "description": "Accurately detecting 3D objects from monocular images in dynamic roadside scenarios remains a challenging problem due to varying camera perspectives and unpredictable scene conditions. This paper introduces a two-stage training strategy to address these challenges. Our approach initially trains a model on the large-scale synthetic dataset, RoadSense3D, which offers a diverse range of scenarios for robust feature learning. Subsequently, we fine-tune the model on a combination of real-world datasets to enhance its adaptability to practical conditions. Experimental results of the Cube R-CNN model on challenging public benchmarks show a remarkable improvement in detection performance, with a mean average precision rising from 0.26 to 12.76 on the TUM Traffic A9 Highway dataset and from 2.09 to 6.60 on the DAIR-V2X-I dataset when performing transfer learning. Code, data, and qualitative video results are available on the project website: https://roadsense3d.github.io."
      },
      {
        "title": "Evaluating Vision-Language Models for Zero-Shot Detection, Classification, and Association of Motorcycles, Passengers, and Helmets",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:k_IJM867U9cC",
        "authors": [
          "Lucas Choi",
          "Ross Greer"
        ],
        "publication_date": "2024-08-05",
        "description": "Motorcycle accidents pose significant risks, particularly when riders and passengers do not wear helmets. This study evaluates the efficacy of an advanced vision-language foundation model, OWLv2, in detecting and classifying various helmet-wearing statuses of motorcycle occupants using video data. We extend the dataset provided by the CVPR AI City Challenge and employ a cascaded model approach for detection and classification tasks, integrating OWLv2 and CNN models. The results highlight the potential of zero-shot learning to address challenges arising from incomplete and biased training datasets, demonstrating the usage of such models in detecting motorcycles, helmet usage, and occupant positions under varied conditions. We have achieved an average precision of 0.5324 for helmet detection and provided precision-recall curves detailing the detection and classification performance. Despite limitations such as low-resolution data and poor visibility, our research shows promising advancements in automated vehicle safety and traffic safety enforcement systems."
      },
      {
        "title": "A Machine Vision Toolkit for Analyzing Tennis Racquet Positioning During Service",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:M3NEmzRMIkIC",
        "authors": [
          "Dhruv Jhamb",
          "Ross Greer"
        ],
        "publication_date": "2024-07-08",
        "conference": "2024 IEEE International Workshop on Sport, Technology and Research (STAR)",
        "pages": "222-227",
        "publisher": "IEEE",
        "description": "The integration of technology into sports, particularly tennis, makes possible new opportunities for performance analysis and skill development. This paper presents a novel approach utilizing image processing and machine learning techniques to find features which are important for analysis of the mechanics of the tennis serve, focusing on the position of the racquet at the point of ball contact. Through temporal averaging and color segmentation, we isolate the player and racquet, facilitating detailed analysis. Additionally, we employ a neural network-based keypoint detection model to accurately identify key points on the tennis racquet. Our methodology enables the extraction of meaningful insights into serve mechanics, providing valuable feedback for players, coaches, and enthusiasts. By democratizing advanced tennis analytics, our research contributes to the enhancement of coaching methodologies and player\u00a0\u2026"
      },
      {
        "title": "Pedestrian Safety by Intent Prediction: A Lightweight LSTM-Attention Architecture and Experimental Evaluations with Real-World Datasets",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:4JMBOYKVnBMC",
        "authors": [
          "Afnan Alofi",
          "Ross Greer",
          "Akshay Gopalkrishnan",
          "Mohan Trivedi"
        ],
        "publication_date": "2024-06-02",
        "conference": "2024 IEEE Intelligent Vehicles Symposium (IV)",
        "pages": "77-84",
        "publisher": "IEEE",
        "description": "Autonomous vehicles face significant challenges in understanding pedestrian behavior, particularly in urban environments. In such settings, the system must recognize pedestrian intentions and anticipate their actions to achieve safe and intelligent driving. This paper focuses on predicting pedestrian crossings, enabling oncoming vehicles to react to pedestrians in a traffic scene in a timely manner. We investigate the effectiveness of various input features for pedestrian crossing prediction, including human poses, bounding boxes, and ego vehicle speed features. We propose a novel lightweight architecture based on LSTM and attention to accurately identify crossing pedestrians. Our methods are evaluated on two widely used public datasets for pedestrian behavior, PIE and JAAD datasets, and our algorithm achieves a state-of-the-art performance in both datasets by reaching a prediction accuracy of 91% and an F1\u00a0\u2026"
      },
      {
        "title": "Learning to Find Missing Video Frames with Synthetic Data Augmentation: A General Framework and Application in Generating Thermal Images Using RGB Cameras",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:7PzlFSSx8tAC",
        "authors": [
          "Mathias Viborg Andersen",
          "Ross Greer",
          "Andreas M\u00f8gelmose",
          "Mohan M Trivedi"
        ],
        "publication_date": "2024-06-02",
        "conference": "2024 IEEE Intelligent Vehicles Symposium (IV)",
        "pages": "104-109",
        "publisher": "IEEE",
        "description": "Advanced Driver Assistance Systems (ADAS) in intelligent vehicles rely on accurate driver perception within the vehicle cabin, often leveraging a combination of sensing modalities. However, these modalities operate at varying rates, posing challenges for real-time, comprehensive driver state monitoring. This paper addresses the issue of missing data due to sensor frame rate mismatches, introducing a generative model approach to create synthetic yet realistic thermal imagery. We propose using conditional generative adversarial networks (cGANs), specifically comparing the pix2pix and CycleGAN architectures. Experimental results demonstrate that pix2pix outperforms CycleGAN, and utilizing multi-view input styles, especially stacked views, enhances the accuracy of thermal image generation. Moreover, the study evaluates the model\u2019s generalizability across different subjects, revealing the importance of\u00a0\u2026"
      },
      {
        "title": "Human-Robot Task Handoff: A Probabilistic Modeling Approach Explored through Cooperative Drawing",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:maZDTaKrznsC",
        "authors": [
          "Lucas Choi",
          "Ross Greer"
        ],
        "publication_date": "2024-05-31",
        "description": "Recent research in human-robot interaction explores the potential for human-machine collaboration in surgical procedures, dividing tasks into manual and automatable subtasks. This paper investigates the task of handoff detection, crucial for the success of robot-assisted surgery, focusing on the creation of a synthetic dataset which can be used for training and benchmarking models for this task. We present a dataset of parabolas, simulating cooperative drawing between a human and a robot, with variations in drawing rates and added noise. The study demonstrates the applicability of HMMs in determining handoff points, laying the groundwork for future research in human-machine collaborative surgery. The dataset, along with the provided code and raw data, are provided as a resource for future research. Finally, we discuss the limitations of the dataset and suggest directions for future research, emphasizing the need for higher-dimensional and real-world datasets."
      },
      {
        "title": "Driver Activity Classification Using Generalizable Representations from Vision-Language Models",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:hFOr9nPyWt4C",
        "authors": [
          "Ross Greer",
          "Mathias Viborg Andersen",
          "Andreas M\u00f8gelmose",
          "Mohan Trivedi"
        ],
        "publication_date": "2024-04-23",
        "description": "Driver activity classification is crucial for ensuring road safety, with applications ranging from driver assistance systems to autonomous vehicle control transitions. In this paper, we present a novel approach leveraging generalizable representations from vision-language models for driver activity classification. Our method employs a Semantic Representation Late Fusion Neural Network (SRLF-Net) to process synchronized video frames from multiple perspectives. Each frame is encoded using a pretrained vision-language encoder, and the resulting embeddings are fused to generate class probability predictions. By leveraging contrastively-learned vision-language representations, our approach achieves robust performance across diverse driver activities. We evaluate our method on the Naturalistic Driving Action Recognition Dataset, demonstrating strong accuracy across many classes. Our results suggest that vision-language representations offer a promising avenue for driver monitoring systems, providing both accuracy and interpretability through natural language descriptors."
      },
      {
        "title": "Towards Safe, Human-Centered Autonomous Driving: Real-World Artificial Intelligence for Enhanced Situation Awareness and Transition Control",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:RHpTSmoSYBkC",
        "authors": [
          "Ross Greer"
        ],
        "publication_date": "2024-10-17",
        "description": "Autonomous driving systems involved in perception and planning require large volumes of carefully annotated data for learning and validation. These same systems also must be aware of failure cases so that they can safely request and initiate control transitions to human drivers or remote operators. In this dissertation, I present novelty detection as a unifying solution to both of these problems. Through novelty detection, active learning algorithms can reduce annotation costs by intelligently selecting informative data, which I demonstrate on tasks of 3D object detection and vehicle trajectory prediction. Similarly, novelty detection acts as a requisite step for safely handling hazardous scenarios. Lastly, I present the concept of salience as a property of road objects which expresses their criticality to control decisions, discussing the relevance of this property in developing machine learning systems which have stronger\u00a0\u2026"
      },
      {
        "title": "Spectrogram-Based Deep Learning for Flute Audition Assessment and Intelligent Feedback",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:ZeXyd9-uunAC",
        "authors": [
          "Manu Agarwal",
          "Ross Greer"
        ],
        "publication_date": "2023-12-11",
        "conference": "2023 IEEE International Symposium on Multimedia (ISM)",
        "pages": "238-242",
        "publisher": "IEEE",
        "description": "Performers of classical music require a blend of technical precision and artistic expression in their output, and this fusion, often referred to as \u201cmusicality,\u201d is considered vital to performance quality. This paper introduces an innovative approach that leverages deep learning and LLMs to simultaneously evaluate and coach musicians using recorded performances on a variety of performance metrics at varying levels of subjectivity. A case study, centered around flute players performing a challenging excerpt from Ravel\u2019s \u201cDaphnis et Chlo\u00e9,\u201d demonstrates the proposed model\u2019s capabilities. Feedback is generated by a large-language model based on machine-assessed quality, learned from human judgments. The model showcases promise in bridging the gap between technical precision and human expression in classical music performance assessment and provides a foundation for expanding the repertoire of\u00a0\u2026"
      },
      {
        "title": "Bridging Subjectivity and Objectivity in Evaluation of Machine-Generated Jazz Music: A Multimetric Approach",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:L8Ckcad2t8MC",
        "authors": [
          "Conrad Hsu",
          "Ross Greer"
        ],
        "publication_date": "2023-12-11",
        "conference": "2023 IEEE International Symposium on Multimedia (ISM)",
        "pages": "232-237",
        "publisher": "IEEE",
        "description": "This research explores different musical metrics to bridge the gap between subjectivity and objectivity in jazz music generation by employing diverse metrics including pitch class histogram entropy, groove pattern similarity, and creating two new metrics based on jazz theoretical concepts: the chord tone emphasis and the swing deviation metric. The study utilizes both a Markov model and a Recurrent Neural Network for music generation, with a dataset consisting of choruses of F-blues. A human survey is conducted on the preferred model for jazz generation to align these objective metrics with the subjective preference of humans. The results suggest that combining these objective metrics with subjective survey responses provides a more comprehensive understanding of generative jazz music\u2019s quality. While challenges remain, these metrics contribute to a more nuanced and balanced evaluation of the artistic\u00a0\u2026"
      },
      {
        "title": "Quantifying Repetition in Symbolic Music using Lempel-Ziv Compression",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:8k81kl-MbHgC",
        "authors": [
          "Anton Chen",
          "Ross Greer"
        ],
        "publication_date": "2023-10-12",
        "conference": "2023 IEEE 14th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)",
        "pages": "0387-0393",
        "publisher": "IEEE",
        "description": "Repetition serves as a fundamental element in music by creating patterns, building structure, and emphasizing melodies, yet remains largely elusive to generative AI models. In this paper, we explore the question of quantifying musical repetition by using principles of information theory, arguing that a composition\u2019s repetitiveness is related to the compressibility of its musical data. Thus, we introduce a metric of repetition termed the LZ ratio, based on Lempel-Ziv compression. By analyzing numerous selected piano pieces, we evaluate the effectiveness of our metric in measuring different types of musical repetition. We find that our metric does well in quantifying certain types of repetition. Furthermore, we observe expected changes in our metric when we remove repetitions from pieces. Our work presents an encouraging direction to objectively quantifying the repetitiveness of music for use in generative multimedia\u00a0\u2026"
      },
      {
        "title": "Securing Quantum Computers: Safeguarding Against Eavesdropping and Side-Channel Attacks",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:_Qo2XoVZTnwC",
        "authors": [
          "Pranav Gani",
          "Ross Greer"
        ],
        "publication_date": "2023-10-06",
        "pages": "1-5",
        "publisher": "IEEE",
        "description": "Methods of eavesdropping and side-channel attacks - physical attacks on cryptosystems - have always been developing to stay in the race against classical and even quantum security protocols. In this paper, we review foundational approaches to quantum security against such attacks. In particular, we examine principles of quantum mechanics which make security protocols such as quantum key distribution and BB84 possible. Further, we describe a variety of side-channel attack configurations and conclude by describing the relevance of these attacks and security measures across modern systems, motivating future research in quantum security."
      },
      {
        "title": "Classifying Pothole Severity with Convolutional Neural Networks",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:e5wmG9Sq2KIC",
        "authors": [
          "Sahil Bhatia",
          "Ross Greer"
        ],
        "publication_date": "2023-10-06",
        "conference": "2023 IEEE MIT Undergraduate Research Technology Conference (URTC)",
        "pages": "1-4",
        "publisher": "IEEE",
        "description": "The presence of potholes in roadways can lead to dangerous consequences for road users, so detecting and filling potholes is an important task. There are multiple existing automated pothole detection methods, but a lack of methods to classify the potholes based on their severity. We create a publicly available model which takes as input a colored disparity map of a pothole and classifies it into a severity 1\u20135, with 1 being the lowest and 5 being the highest, based on human annotation of pothole severity judging features such as depth and size. The model had a test accuracy of 64%. This research paves the way for applications to prioritize pothole repairs by severity level or obstacle avoidance in intelligent vehicles."
      },
      {
        "title": "Comparative Assessment of Markov Models and Recurrent Neural Networks for Jazz Music Generation",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:ULOm3_A8WrAC",
        "authors": [
          "Conrad Hsu",
          "Ross Greer"
        ],
        "publication_date": "2023-09-14",
        "description": "As generative models have risen in popularity, a domain that has risen alongside is generative models for music. Our study aims to compare the performance of a simple Markov chain model and a recurrent neural network (RNN) model, two popular models for sequence generating tasks, in jazz music improvisation. While music, especially jazz, remains subjective in telling whether a composition is \"good\" or \"bad\", we aim to quantify our results using metrics of groove pattern similarity and pitch class histogram entropy. We trained both models using transcriptions of jazz blues choruses from professional jazz players, and also fed musical jazz seeds to help give our model some context in beginning the generation. Our results show that the RNN outperforms the Markov model on both of our metrics, indicating better rhythmic consistency and tonal stability in the generated music. Through the use of music21 library, we tokenized our jazz dataset into pitches and durations that our model could interpret and train on. Our findings contribute to the growing field of AI-generated music, highlighting the important use of metrics to assess generation quality. Future work includes expanding the dataset of MIDI files to a larger scale, conducting human surveys for subjective evaluations, and incorporating additional metrics to address the challenge of subjectivity in music evaluation. Our study provides valuable insight into the use of recurrent neural networks for sequential based tasks like generating music."
      },
      {
        "title": "DECARBONIZING WATER DESALINATION BY OPTIMIZING RENEWABLE ENERGY AND BATTERY STORAGE USING OPTIMIZATION ALGORITHMS",
        "link": "/citations?view_op=view_citation&hl=en&user=ZAX3UCwAAAAJ&pagesize=100&citation_for_view=ZAX3UCwAAAAJ:j3f4tGmQtD8C",
        "authors": [
          "Om Sanan",
          "Joshua Sperling",
          "David Greene",
          "Ross Greer"
        ],
        "description": "The escalating challenges of water scarcity and carbon emissions require a shift towards climate-smart water desalination processes to ensure sustainable management of our water resources. Desalination has significant potential to address water security, yet energy demand and costs are high. This study employs a novel automated Energy Management System (EMS) to accelerate desalination\u2019s decarbonization, energy efficiency, and cost-effectiveness using Renewable Energy (RE), battery storage, and Artificial Intelligence (AI). Leveraging Machine Learning (ML) models such as XGBoost and Gradient Boosting, we forecasted water production, energy consumption, and weather based on historical 5-year data from four real life mid-to-large scale US desalination plants. Utilizing sophisticated optimization algorithms such as Particle Swarm Optimization (PSO) we aligned RE generation with plants\u2019 energy demands. Results show that our customized innovative ML models accurately forecasted critical variables, achieving normalized Root Mean Square Error of less than 10% for key metrics such as treated water flows, energy demand, temperature, solar irradiance, wind speed, etc. Optimization led to RE system configurations that reduce costs and carbon emissions across all facilities, underpinning the study\u2019s objective of fortifying water security for a resilient water supply infrastructure and ensuring sustainable operation of desalination plants amidst climate change. A RE optimization scenario at the Tampa Bay desalination plant, which dynamically selects the optimal RE percentage between 50% and 100%, led to 99% RE mix of\u00a0\u2026"
      }
    ]
  },
  {
    "name": "Amit Namburi",
    "scholar_id": "vPtFpgIAAAAJ",
    "publications": [
      {
        "title": "Futga: Towards fine-grained music understanding through temporally-enhanced generative augmentation",
        "link": "/citations?view_op=view_citation&hl=en&user=vPtFpgIAAAAJ&pagesize=100&citation_for_view=vPtFpgIAAAAJ:u5HHmVD_uO8C",
        "authors": [
          "Junda Wu",
          "Zachary Novack",
          "Amit Namburi",
          "Jiaheng Dai",
          "Hao-Wen Dong",
          "Zhouhang Xie",
          "Carol Chen",
          "Julian McAuley"
        ],
        "publication_date": "2024-07-29",
        "description": "Existing music captioning methods are limited to generating concise global descriptions of short music clips, which fail to capture fine-grained musical characteristics and time-aware musical changes. To address these limitations, we propose FUTGA, a model equipped with fined-grained music understanding capabilities through learning from generative augmentation with temporal compositions. We leverage existing music caption datasets and large language models (LLMs) to synthesize fine-grained music captions with structural descriptions and time boundaries for full-length songs. Augmented by the proposed synthetic dataset, FUTGA is enabled to identify the music's temporal changes at key transition points and their musical functions, as well as generate detailed descriptions for each music segment. We further introduce a full-length music caption dataset generated by FUTGA, as the augmentation of the MusicCaps and the Song Describer datasets. We evaluate the automatically generated captions on several downstream tasks, including music generation and retrieval. The experiments demonstrate the quality of the generated captions and the better performance in various downstream tasks achieved by the proposed music captioning approach. Our code and datasets can be found in \\href{https://huggingface.co/JoshuaW1997/FUTGA}{\\textcolor{blue}{https://huggingface.co/JoshuaW1997/FUTGA}}.",
        "total_citations": 1
      },
      {
        "title": "CoLLAP: Contrastive Long-form Language-Audio Pretraining with Musical Temporal Structure Augmentation",
        "link": "/citations?view_op=view_citation&hl=en&user=vPtFpgIAAAAJ&pagesize=100&citation_for_view=vPtFpgIAAAAJ:u-x6o8ySG0sC",
        "authors": [
          "Junda Wu",
          "Warren Li",
          "Zachary Novack",
          "Amit Namburi",
          "Carol Chen",
          "Julian McAuley"
        ],
        "publication_date": "2024-10-03",
        "description": "Modeling temporal characteristics plays a significant role in the representation learning of audio waveform. We propose Contrastive Long-form Language-Audio Pretraining (\\textbf{CoLLAP}) to significantly extend the perception window for both the input audio (up to 5 minutes) and the language descriptions (exceeding 250 words), while enabling contrastive learning across modalities and temporal dynamics. Leveraging recent Music-LLMs to generate long-form music captions for full-length songs, augmented with musical temporal structures, we collect 51.3K audio-text pairs derived from the large-scale AudioSet training dataset, where the average audio length reaches 288 seconds. We propose a novel contrastive learning architecture that fuses language representations with structured audio representations by segmenting each song into clips and extracting their embeddings. With an attention mechanism, we capture multimodal temporal correlations, allowing the model to automatically weigh and enhance the final fusion score for improved contrastive alignment. Finally, we develop two variants of the CoLLAP model with different types of backbone language models. Through comprehensive experiments on multiple long-form music-text retrieval datasets, we demonstrate consistent performance improvement in retrieval accuracy compared with baselines. We also show the pretrained CoLLAP models can be transferred to various music information retrieval tasks, with heterogeneous long-form multimodal contexts."
      }
    ]
  },
  {
    "name": "Jingyue Huang",
    "scholar_id": "80PzfFoAAAAJ",
    "publications": [
      {
        "title": "Weakly supervised learning for textbook question answering",
        "link": "/citations?view_op=view_citation&hl=en&user=80PzfFoAAAAJ&pagesize=100&citation_for_view=80PzfFoAAAAJ:u5HHmVD_uO8C",
        "authors": [
          "Jie Ma",
          "Qi Chai",
          "Jingyue Huang",
          "Jun Liu",
          "Yang You",
          "Qinghua Zheng"
        ],
        "publication_date": "2022-06-10",
        "pages": "7378-7388",
        "publisher": "IEEE",
        "description": "Textbook Question Answering (TQA) is the task of answering diagram and non-diagram questions given large multi-modal contexts consisting of abundant text and diagrams. Deep text understandings and effective learning of diagram semantics are important for this task due to its specificity. In this paper, we propose a Weakly Supervised learning method for TQA (WSTQ), which regards the incompletely accurate results of essential intermediate procedures for this task as supervision to develop Text Matching (TM) and Relation Detection (RD) tasks and then employs the tasks to motivate itself to learn strong text comprehension and excellent diagram semantics respectively. Specifically, we apply the result of text retrieval to build positive as well as negative text pairs. In order to learn deep text understandings, we first pre-train the text understanding module of WSTQ on TM and then fine-tune it on TQA. We build\u00a0\u2026",
        "total_citations": 11
      },
      {
        "title": "Generative entity typing with curriculum learning",
        "link": "/citations?view_op=view_citation&hl=en&user=80PzfFoAAAAJ&pagesize=100&citation_for_view=80PzfFoAAAAJ:d1gkVwhDpl0C",
        "authors": [
          "Siyu Yuan",
          "Deqing Yang",
          "Jiaqing Liang",
          "Zhixu Li",
          "Jinxi Liu",
          "Jingyue Huang",
          "Yanghua Xiao"
        ],
        "publication_date": "2022-10-06",
        "description": "Entity typing aims to assign types to the entity mentions in given texts. The traditional classification-based entity typing paradigm has two unignorable drawbacks: 1) it fails to assign an entity to the types beyond the predefined type set, and 2) it can hardly handle few-shot and zero-shot situations where many long-tail types only have few or even no training instances. To overcome these drawbacks, we propose a novel generative entity typing (GET) paradigm: given a text with an entity mention, the multiple types for the role that the entity plays in the text are generated with a pre-trained language model (PLM). However, PLMs tend to generate coarse-grained types after fine-tuning upon the entity typing dataset. Besides, we only have heterogeneous training data consisting of a small portion of human-annotated data and a large portion of auto-generated but low-quality data. To tackle these problems, we employ curriculum learning (CL) to train our GET model upon the heterogeneous data, where the curriculum could be self-adjusted with the self-paced learning according to its comprehension of the type granularity and data heterogeneity. Our extensive experiments upon the datasets of different languages and downstream tasks justify the superiority of our GET model over the state-of-the-art entity typing models. The code has been released on https://github.com/siyuyuan/GET.",
        "total_citations": 10
      },
      {
        "title": "Large-scale multi-granular concept extraction based on machine reading comprehension",
        "link": "/citations?view_op=view_citation&hl=en&user=80PzfFoAAAAJ&pagesize=100&citation_for_view=80PzfFoAAAAJ:9yKSN-GCB0IC",
        "authors": [
          "Siyu Yuan",
          "Deqing Yang",
          "Jiaqing Liang",
          "Jilun Sun",
          "Jingyue Huang",
          "Kaiyan Cao",
          "Yanghua Xiao",
          "Rui Xie"
        ],
        "publication_date": "2021-09-30",
        "pages": "93-110",
        "publisher": "Springer International Publishing",
        "description": " The concepts in knowledge graphs (KGs) enable machines to understand natural language, and thus play an indispensable role in many applications. However, existing KGs have the poor coverage of concepts, especially fine-grained concepts. In order to supply existing KGs with more fine-grained and new concepts, we propose a novel concept extraction framework, namely MRC-CE, to extract large-scale multi-granular concepts from the descriptive texts of entities. Specifically, MRC-CE is built with a machine reading comprehension model based on BERT, which can extract more fine-grained concepts with a pointer network. Furthermore, a random forest and rule-based pruning are also adopted to enhance MRC-CE\u2019s precision and recall simultaneously. Our experiments evaluated upon multilingual KGs, i.e., English Probase and Chinese CN-DBpedia, justify MRC-CE\u2019s superiority over the state-of-the\u00a0\u2026",
        "total_citations": 3
      },
      {
        "title": "Communication-avoiding kernel ridge regression on parallel and distributed systems",
        "link": "/citations?view_op=view_citation&hl=en&user=80PzfFoAAAAJ&pagesize=100&citation_for_view=80PzfFoAAAAJ:u-x6o8ySG0sC",
        "authors": [
          "Yang You",
          "Jingyue Huang",
          "Cho-Jui Hsieh",
          "Richard Vuduc",
          "James Demmel"
        ],
        "publication_date": "2021-09-17",
        "pages": "252-270",
        "publisher": "Springer Singapore",
        "description": " Kernel ridge regression (KRR) is a fundamental method in machine learning. Given an n-by-d data matrix as input, a traditional implementation requires  memory to form an n-by-n kernel matrix and  flops to compute the final model. These time and storage costs prohibit KRR from scaling up to large datasets. For example, even on a relatively small dataset (a 520k-by-90 input requiring 357\u00a0MB), KRR requires 2\u00a0TB memory just to store the kernel matrix. The reason is that n usually is much larger than d for real-world applications. On the other hand, weak scaling becomes a problem: if we keep d and n/p fixed as p grows (p is the number of machines), the memory needed grows as  per processor and the flops as  per processor. In the perfect weak scaling situation, both the memory needed and the flops grow as  per processor (i.e. memory and flops are constant). The traditional Distributed KRR\u00a0\u2026",
        "total_citations": 2
      },
      {
        "title": "Emotion-driven Piano Music Generation via Two-stage Disentanglement and Functional Representation",
        "link": "/citations?view_op=view_citation&hl=en&user=80PzfFoAAAAJ&pagesize=100&citation_for_view=80PzfFoAAAAJ:2osOgNQ5qMEC",
        "authors": [
          "Jingyue Huang",
          "Ke Chen",
          "Yi-Hsuan Yang"
        ],
        "publication_date": "2024-07-30",
        "description": "Managing the emotional aspect remains a challenge in automatic music generation. Prior works aim to learn various emotions at once, leading to inadequate modeling. This paper explores the disentanglement of emotions in piano performance generation through a two-stage framework. The first stage focuses on valence modeling of lead sheet, and the second stage addresses arousal modeling by introducing performance-level attributes. To further capture features that shape valence, an aspect less explored by previous approaches, we introduce a novel functional representation of symbolic music. This representation aims to capture the emotional impact of major-minor tonality, as well as the interactions among notes, chords, and key signatures. Objective and subjective experiments validate the effectiveness of our framework in both emotional valence and arousal modeling. We further leverage our framework in a novel application of emotional controls, showing a broad potential in emotion-driven music generation.",
        "total_citations": 1
      },
      {
        "title": "Emotion-Driven Melody Harmonization via Melodic Variation and Functional Representation",
        "link": "/citations?view_op=view_citation&hl=en&user=80PzfFoAAAAJ&pagesize=100&citation_for_view=80PzfFoAAAAJ:qjMakFHDy7sC",
        "authors": [
          "Jingyue Huang",
          "Yi-Hsuan Yang"
        ],
        "publication_date": "2024-07-29",
        "description": "Emotion-driven melody harmonization aims to generate diverse harmonies for a single melody to convey desired emotions. Previous research found it hard to alter the perceived emotional valence of lead sheets only by harmonizing the same melody with different chords, which may be attributed to the constraints imposed by the melody itself and the limitation of existing music representation. In this paper, we propose a novel functional representation for symbolic music. This new method takes musical keys into account, recognizing their significant role in shaping music's emotional character through major-minor tonality. It also allows for melodic variation with respect to keys and addresses the problem of data scarcity for better emotion modeling. A Transformer is employed to harmonize key-adaptable melodies, allowing for keys determined in rule-based or model-based manner. Experimental results confirm the effectiveness of our new representation in generating key-aware harmonies, with objective and subjective evaluations affirming the potential of our approach to convey specific valence for versatile melody.",
        "total_citations": 1
      }
    ]
  },
  {
    "name": "Milan Gupta",
    "scholar_id": "5VWhH2UAAAAJ",
    "publications": [
      {
        "title": "Analyzing Speech Impairments: A Machine Learning Approach to Dysarthria Detection",
        "link": "/citations?view_op=view_citation&hl=en&user=5VWhH2UAAAAJ&pagesize=100&citation_for_view=5VWhH2UAAAAJ:UebtZRa9Y70C",
        "authors": [
          "Milan Gupta"
        ],
        "publication_date": "2024-10-02",
        "pages": "9",
        "publisher": "International Journal of Scientific & Engineering Research"
      }
    ]
  },
  {
    "name": "Matthew Rice",
    "scholar_id": "5Zu_wxQAAAAJ",
    "publications": [
      {
        "title": "General Purpose Audio Effect Removal",
        "link": "/citations?view_op=view_citation&hl=en&user=5Zu_wxQAAAAJ&pagesize=100&citation_for_view=5Zu_wxQAAAAJ:4TOpqqG69KYC",
        "authors": [
          "Matthew Rice",
          "Christian J Steinmetz",
          "George Fazekas",
          "Joshua D Reiss"
        ],
        "publication_date": "2023-10-22",
        "conference": "2023 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)",
        "pages": "1-5",
        "publisher": "IEEE",
        "description": "Although the design and application of audio effects is well understood, the inverse problem of removing these effects is significantly more challenging and far less studied. Recently, deep learning has been applied to audio effect removal; however, existing approaches have focused on narrow formulations considering only one effect or source type at a time. In realistic scenarios, multiple effects are applied with varying source content. This motivates a more general task, which we refer to as general purpose audio effect removal. We developed a dataset for this task using five audio effects across four different sources and used it to train and evaluate a set of existing architectures. We found that no single model performed optimally on all effect types and sources. To address this, we introduced RemFX, an approach designed to mirror the compositionality of applied effects. We first trained a set of the best-performing\u00a0\u2026",
        "total_citations": 6
      },
      {
        "title": "The Lena Singer Project: Simulating the Learning Experience of a Singer",
        "link": "/citations?view_op=view_citation&hl=en&user=5Zu_wxQAAAAJ&pagesize=100&citation_for_view=5Zu_wxQAAAAJ:M3ejUd6NZC8C",
        "authors": [
          "Matthew Rice",
          "Simon Colton"
        ],
        "description": "The Lena Singer project involves a generative AI process based on a recent singing voice synthesis system that iteratively produces audio to simulate a singer learning how to sing. Users can select an initial motivation and an initial ability for the singer, then, through a feedback-based process involving random elements, the singer may improve at singing, or they may get worse, which in turn boosts or diminishes its confidence, ability, and motivation. In this way, we aim to provide a simple model which simulates the learning experience of a human singer and demonstrate how it differs from standard machine learning approaches. We also explore the feedback loop that learning can have on internalized features, and exemplify how a machine might express the output of this learning. Finally, we discuss how the context provided by this process can be seen as relatable. A demo of this project can be found at https://lena-singer. vercel. app."
      }
    ]
  },
  {
    "name": "Xin Xu",
    "scholar_id": "KBdTqoEAAAAJ",
    "publications": [
      {
        "title": "Exploring collaboration mechanisms for llm agents: A social psychology view",
        "link": "/citations?view_op=view_citation&hl=en&user=KBdTqoEAAAAJ&pagesize=100&citation_for_view=KBdTqoEAAAAJ:WF5omc3nYNoC",
        "authors": [
          "Jintian Zhang*",
          "Xin Xu*",
          "Ningyu Zhang",
          "Ruibo Liu",
          "Bryan Hooi",
          "Shumin Deng"
        ],
        "publication_date": "2023-10-03",
        "conference": "ACL 2024",
        "description": "As Natural Language Processing (NLP) systems are increasingly employed in intricate social environments, a pressing query emerges: Can these NLP systems mirror human-esque collaborative intelligence, in a multi-agent society consisting of multiple large language models (LLMs)? This paper probes the collaboration mechanisms among contemporary NLP systems by melding practical experiments with theoretical insights. We fabricate four unique `societies' comprised of LLM agents, where each agent is characterized by a specific `trait' (easy-going or overconfident) and engages in collaboration with a distinct `thinking pattern' (debate or reflection). Evaluating these multi-agent societies on three benchmark datasets, we discern that LLM agents navigate tasks by leveraging diverse social behaviors, from active debates to introspective reflections. Notably, certain collaborative strategies only optimize efficiency (using fewer API tokens), but also outshine previous top-tier approaches. Moreover, our results further illustrate that LLM agents manifest human-like social behaviors, such as conformity or majority rule, mirroring foundational Social Psychology theories. In conclusion, we integrate insights from Social Psychology to contextualize the collaboration of LLM agents, inspiring further investigations into the collaboration mechanism for LLMs. We commit to sharing our code and datasets (already submitted in supplementary materials), hoping to catalyze further research in this promising avenue (All code and data are available at \\url{https://github.com/zjunlp/MachineSoM}.).",
        "total_citations": 55
      },
      {
        "title": "DeepKE: A deep learning based knowledge extraction toolkit for knowledge base population",
        "link": "/citations?view_op=view_citation&hl=en&user=KBdTqoEAAAAJ&pagesize=100&citation_for_view=KBdTqoEAAAAJ:qjMakFHDy7sC",
        "authors": [
          "Ningyu Zhang",
          "Xin Xu",
          "Liankuan Tao",
          "Haiyang Yu",
          "Hongbin Ye",
          "Xin Xie",
          "Xiang Chen",
          "Zhoubo Li",
          "Lei Li",
          "Xiaozhuan Liang",
          "Yunzhi Yao",
          "Shumin Deng",
          "Wen Zhang",
          "Zhenru Zhang",
          "Chuanqi Tan",
          "Fei Huang",
          "Guozhou Zheng",
          "Huajun Chen"
        ],
        "publication_date": "2022-01-10",
        "conference": "EMNLP 2022 System Demonstrations",
        "description": "We present an open-source and extensible knowledge extraction toolkit DeepKE, supporting complicated low-resource, document-level and multimodal scenarios in the knowledge base population. DeepKE implements various information extraction tasks, including named entity recognition, relation extraction and attribute extraction. With a unified framework, DeepKE allows developers and researchers to customize datasets and models to extract information from unstructured data according to their requirements. Specifically, DeepKE not only provides various functional modules and model implementation for different tasks and scenarios but also organizes all components by consistent frameworks to maintain sufficient modularity and extensibility. We release the source code at GitHub in https://github.com/zjunlp/DeepKE with Google Colab tutorials and comprehensive documents for beginners. Besides, we present an online system in http://deepke.openkg.cn/EN/re_doc_show.html for real-time extraction of various tasks, and a demo video.",
        "total_citations": 40
      },
      {
        "title": "MuseCoco: Generating Symbolic Music from Text",
        "link": "/citations?view_op=view_citation&hl=en&user=KBdTqoEAAAAJ&pagesize=100&citation_for_view=KBdTqoEAAAAJ:Tyk-4Ss8FVUC",
        "authors": [
          "Peiling Lu*",
          "Xin Xu*",
          "Chenfei Kang*",
          "Botao Yu*",
          "Chengyi Xing*",
          "Xu Tan",
          "Jiang Bian"
        ],
        "publication_date": "2023-05-31",
        "conference": "arXiv preprint arXiv:2306.00110",
        "description": "Generating music from text descriptions is a user-friendly mode since the text is a relatively easy interface for user engagement. While some approaches utilize texts to control music audio generation, editing musical elements in generated audio is challenging for users. In contrast, symbolic music offers ease of editing, making it more accessible for users to manipulate specific musical elements. In this paper, we propose MuseCoco, which generates symbolic music from text descriptions with musical attributes as the bridge to break down the task into text-to-attribute understanding and attribute-to-music generation stages. MuseCoCo stands for Music Composition Copilot that empowers musicians to generate music directly from given text descriptions, offering a significant improvement in efficiency compared to creating music entirely from scratch. The system has two main advantages: Firstly, it is data efficient. In the attribute-to-music generation stage, the attributes can be directly extracted from music sequences, making the model training self-supervised. In the text-to-attribute understanding stage, the text is synthesized and refined by ChatGPT based on the defined attribute templates. Secondly, the system can achieve precise control with specific attributes in text descriptions and offers multiple control options through attribute-conditioned or text-conditioned approaches. MuseCoco outperforms baseline systems in terms of musicality, controllability, and overall score by at least 1.27, 1.08, and 1.32 respectively. Besides, there is a notable enhancement of about 20% in objective control accuracy. In addition, we have developed a robust large-scale\u00a0\u2026",
        "total_citations": 32
      },
      {
        "title": "How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?",
        "link": "/citations?view_op=view_citation&hl=en&user=KBdTqoEAAAAJ&pagesize=100&citation_for_view=KBdTqoEAAAAJ:IjCSPb-OGe4C",
        "authors": [
          "Xin Xu",
          "Yuqi Zhu",
          "Xiaohan Wang",
          "Ningyu Zhang"
        ],
        "publication_date": "2023-05-02",
        "conference": "SustaiNLP 2023 @ ACL 2023",
        "description": "Scaling language models have revolutionized widespread NLP tasks, yet little comprehensively explored few-shot relation extraction with large language models. In this paper, we investigate principal methodologies, in-context learning and data generation, for few-shot relation extraction via GPT-3.5 through exhaustive experiments. To enhance few-shot performance, we further propose task-related instructions and schema-constrained data generation. We observe that in-context learning can achieve performance on par with previous prompt learning approaches, and data generation with the large language model can boost previous solutions to obtain new state-of-the-art few-shot results on four widely-studied relation extraction datasets. We hope our work can inspire future research for the capabilities of large language models in few-shot relation extraction. Code is available in https://github.com/zjunlp/DeepKE/tree/main/example/llm.",
        "total_citations": 32
      },
      {
        "title": "A Comprehensive Study of Knowledge Editing for Large Language Models",
        "link": "/citations?view_op=view_citation&hl=en&user=KBdTqoEAAAAJ&pagesize=100&citation_for_view=KBdTqoEAAAAJ:eQOLeE2rZwMC",
        "authors": [
          "Ningyu* Zhang",
          "Yunzhi* Yao",
          "Bozhong* Tian",
          "Peng* Wang",
          "Shumin* Deng",
          "Mengru Wang",
          "Zekun Xi",
          "Shengyu Mao",
          "Jintian Zhang",
          "Yuansheng Ni",
          "Siyuan Cheng",
          "Ziwen Xu",
          "Xin Xu",
          "Jia-Chen Gu",
          "Yong Jiang",
          "Pengjun Xie",
          "Fei Huang",
          "Lei Liang",
          "Zhiqiang Zhang",
          "Xiaowei Zhu",
          "Jun Zhou",
          "Huajun Chen"
        ],
        "publication_date": "2024-01-02",
        "description": "Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication. However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization. This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance. Note that many applications demand continual model adjustments post-training to address deficiencies or undesirable behaviors. There is an increasing interest in efficient, lightweight methods for on-the-fly model modifications. To this end, recent years have seen a burgeoning in the techniques of knowledge editing for LLMs, which aim to efficiently modify LLMs' behaviors within specific domains while preserving overall performance across various inputs. In this paper, we first define the knowledge editing problem and then provide a comprehensive review of cutting-edge approaches. Drawing inspiration from educational and cognitive research theories, we propose a unified categorization criterion that classifies knowledge editing methods into three groups: resorting to external knowledge, merging knowledge into the model, and editing intrinsic knowledge. Furthermore, we introduce a new benchmark, KnowEdit, for a comprehensive empirical evaluation of representative knowledge editing approaches. Additionally, we provide an in-depth analysis of knowledge location, which can provide a deeper understanding of the knowledge structures\u00a0\u2026",
        "total_citations": 19
      },
      {
        "title": "Towards Realistic Low-resource Relation Extraction: A Benchmark with Empirical Baseline Study",
        "link": "/citations?view_op=view_citation&hl=en&user=KBdTqoEAAAAJ&pagesize=100&citation_for_view=KBdTqoEAAAAJ:UeHWp8X0CEIC",
        "authors": [
          "Xin Xu",
          "Xiang Chen",
          "Ningyu Zhang",
          "Xin Xie",
          "Xi Chen",
          "Huajun Chen"
        ],
        "publication_date": "2022-10-19",
        "conference": "EMNLP 2022 Findings",
        "description": "This paper presents an empirical study to build relation extraction systems in low-resource settings. Based upon recent pre-trained language models, we comprehensively investigate three schemes to evaluate the performance in low-resource settings: (i) different types of prompt-based methods with few-shot labeled data; (ii) diverse balancing methods to address the long-tailed distribution issue; (iii) data augmentation technologies and self-training to generate more labeled in-domain data. We create a benchmark with 8 relation extraction (RE) datasets covering different languages, domains and contexts and perform extensive comparisons over the proposed schemes with combinations. Our experiments illustrate: (i) Though prompt-based tuning is beneficial in low-resource RE, there is still much potential for improvement, especially in extracting relations from cross-sentence contexts with multiple relational triples; (ii) Balancing methods are not always helpful for RE with long-tailed distribution; (iii) Data augmentation complements existing baselines and can bring much performance gain, while self-training may not consistently achieve advancement to low-resource RE. Code and datasets are in https://github.com/zjunlp/LREBench.",
        "total_citations": 11
      },
      {
        "title": "Schema-adaptable Knowledge Graph Construction",
        "link": "/citations?view_op=view_citation&hl=en&user=KBdTqoEAAAAJ&pagesize=100&citation_for_view=KBdTqoEAAAAJ:zYLM7Y9cAGgC",
        "authors": [
          "Hongbin Ye",
          "Honghao Gui",
          "Xin Xu",
          "Huajun Chen",
          "Ningyu Zhang"
        ],
        "publication_date": "2023-05-15",
        "conference": "EMNLP 2023 Findings",
        "description": "Conventional Knowledge Graph Construction (KGC) approaches typically follow the static information extraction paradigm with a closed set of pre-defined schema. As a result, such approaches fall short when applied to dynamic scenarios or domains, whereas a new type of knowledge emerges. This necessitates a system that can handle evolving schema automatically to extract information for KGC. To address this need, we propose a new task called schema-adaptable KGC, which aims to continually extract entity, relation, and event based on a dynamically changing schema graph without re-training. We first split and convert existing datasets based on three principles to build a benchmark, i.e., horizontal schema expansion, vertical schema expansion, and hybrid schema expansion; then investigate the schema-adaptable performance of several well-known approaches such as Text2Event, TANL, UIE and GPT-3.5. We further propose a simple yet effective baseline dubbed \\textsc{AdaKGC}, which contains schema-enriched prefix instructor and schema-conditioned dynamic decoding to better handle evolving schema. Comprehensive experimental results illustrate that AdaKGC can outperform baselines but still have room for improvement. We hope the proposed work can deliver benefits to the community. Code and datasets available at https://github.com/zjunlp/AdaKGC.",
        "total_citations": 1
      },
      {
        "title": "Benchmarking Chinese Knowledge Rectification in Large Language Models",
        "link": "/citations?view_op=view_citation&hl=en&user=KBdTqoEAAAAJ&pagesize=100&citation_for_view=KBdTqoEAAAAJ:ufrVoPGSRksC",
        "authors": [
          "Tianhe Lu*",
          "Jizhan Fang*",
          "Yunzhi Yao*",
          "Xin Xu",
          "Ningyu Zhang",
          "Huajun Chen"
        ],
        "publication_date": "2024-09-09",
        "description": "While Large Language Models (LLMs) exhibit remarkable generative capabilities, they are not without flaws, particularly in the form of hallucinations. This issue is even more pronounced when LLMs are applied to specific languages and domains. For example, LLMs may generate nonsense information when handling Chinese ancient poetry, proverbs, or idioms, owing to the lack of specific knowledge. To this end, this paper introduces a benchmark for rectifying Chinese knowledge in LLMs via knowledge editing. Specifically, we introduce a new Chinese dataset, CKnowEdit, by collecting seven type of knowledge from various sources, including classical texts, idioms, and content from Baidu Tieba Ruozhiba, thereby accounting for the unique polyphony, antithesis, and logical constructs inherent in the Chinese language. Through the analysis of this dataset, we uncover the challenges faced by current LLMs in mastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge editing techniques on this dataset unveil the substantial scope for advancement in the rectification of Chinese knowledge. Code and dataset are available at https://github.com/zjunlp/EasyEdit."
      }
    ]
  },
  {
    "name": "Tornike Karchkhadze",
    "scholar_id": "g70wqUsAAAAJ",
    "publications": [
      {
        "title": "Multi-Track MusicLDM: Towards Versatile Music Generation with Latent Diffusion Model",
        "link": "/citations?view_op=view_citation&hl=en&user=g70wqUsAAAAJ&pagesize=100&citation_for_view=g70wqUsAAAAJ:9yKSN-GCB0IC",
        "authors": [
          "Tornike Karchkhadze",
          "Mohammad Rasool Izadi",
          "Ke Chen",
          "Gerard Assayag",
          "Shlomo Dubnov"
        ],
        "publication_date": "2024-09-04",
        "description": "Diffusion models have shown promising results in cross-modal generation tasks involving audio and music, such as text-to-sound and text-to-music generation. These text-controlled music generation models typically focus on generating music by capturing global musical attributes like genre and mood. However, music composition is a complex, multilayered task that often involves musical arrangement as an integral part of the process. This process involves composing each instrument to align with existing ones in terms of beat, dynamics, harmony, and melody, requiring greater precision and control over tracks than text prompts usually provide. In this work, we address these challenges by extending the MusicLDM, a latent diffusion model for music, into a multi-track generative model. By learning the joint probability of tracks sharing a context, our model is capable of generating music across several tracks that correspond well to each other, either conditionally or unconditionally. Additionally, our model is capable of arrangement generation, where the model can generate any subset of tracks given the others (e.g., generating a piano track complementing given bass and drum tracks). We compared our model with an existing multi-track generative model and demonstrated that our model achieves considerable improvements across objective metrics for both total and arrangement generation tasks.",
        "total_citations": 1
      },
      {
        "title": "Latent CLAP Loss for Better Foley Sound Synthesis",
        "link": "/citations?view_op=view_citation&hl=en&user=g70wqUsAAAAJ&pagesize=100&citation_for_view=g70wqUsAAAAJ:u5HHmVD_uO8C",
        "authors": [
          "Tornike Karchkhadze",
          "Hassan Salami Kavaki",
          "Mohammad Rasool Izadi",
          "Bryce Irvin",
          "Mikolaj Kegler",
          "Ari Hertz",
          "Shuo Zhang",
          "Marko Stamenovic"
        ],
        "publication_date": "2024-03-18",
        "description": "Foley sound generation, the art of creating audio for multimedia, has recently seen notable advancements through text-conditioned latent diffusion models. These systems use multimodal text-audio representation models, such as Contrastive Language-Audio Pretraining (CLAP), whose objective is to map corresponding audio and text prompts into a joint embedding space. AudioLDM, a text-to-audio model, was the winner of the DCASE2023 task 7 Foley sound synthesis challenge. The winning system fine-tuned the model for specific audio classes and applied a post-filtering method using CLAP similarity scores between output audio and input text at inference time, requiring the generation of extra samples, thus reducing data generation efficiency. We introduce a new loss term to enhance Foley sound generation in AudioLDM without post-filtering. This loss term uses a new module based on the CLAP mode-Latent CLAP encode-to align the latent diffusion output with real audio in a shared CLAP embedding space. Our experiments demonstrate that our method effectively reduces the Frechet Audio Distance (FAD) score of the generated audio and eliminates the need for post-filtering, thus enhancing generation efficiency.",
        "total_citations": 1
      },
      {
        "title": "Simultaneous Music Separation and Generation Using Multi-Track Latent Diffusion Models",
        "link": "/citations?view_op=view_citation&hl=en&user=g70wqUsAAAAJ&pagesize=100&citation_for_view=g70wqUsAAAAJ:2osOgNQ5qMEC",
        "authors": [
          "Tornike Karchkhadze",
          "Mohammad Rasool Izadi",
          "Shlomo Dubnov"
        ],
        "publication_date": "2024-09-18",
        "description": "Diffusion models have recently shown strong potential in both music generation and music source separation tasks. Although in early stages, a trend is emerging towards integrating these tasks into a single framework, as both involve generating musically aligned parts and can be seen as facets of the same generative process. In this work, we introduce a latent diffusion-based multi-track generation model capable of both source separation and multi-track music synthesis by learning the joint probability distribution of tracks sharing a musical context. Our model also enables arrangement generation by creating any subset of tracks given the others. We trained our model on the Slakh2100 dataset, compared it with an existing simultaneous generation and separation model, and observed significant improvements across objective metrics for source separation, music, and arrangement generation tasks. Sound examples are available at https://msg-ld.github.io/."
      },
      {
        "title": "Multi-Track Music Generation with Latent Diffusion Models",
        "link": "/citations?view_op=view_citation&hl=en&user=g70wqUsAAAAJ&pagesize=100&citation_for_view=g70wqUsAAAAJ:d1gkVwhDpl0C",
        "authors": [
          "Tornike Karchkhadze"
        ],
        "publication_date": "2024-10-17",
        "description": "In recent years, diffusion models have demonstrated promising results in cross-modalgeneration tasks within generative media, encompassing image, video, and audio generation. This development has introduced a great deal of novelty to audio and music-related tasks, such as text-to-sound and text-to-music generation. However, these text-controlled music generation models typically focus on capturing global musical attributes, such as genre and mood, and do not allow for the more fine-grained control that composers might desire. Music composition is a complex, multilayered task that frequently involves intricate musical arrangements as an essential part of the creative process. This task requires composers to carefully align each instrument with existing tracks in terms of beat, dynamics, harmony, and melody, demanding a level of precision and control over individual tracks that current text-driven prompts often fail to provide.In this work, we address these challenges by presenting a multi-track music generationmodel, one of the first of its kind. Our model, by learning the joint probability of tracks sharing a context, is capable of generating music across several tracks that correspond well to each other, either conditionally or unconditionally. We achieve this by extending the MusicLDM\u2014a latent diffusion model for music\u2014into a multi-track generative model. Additionally, our model is capable of arrangement generation, where it can generate any subset of tracks given the others (e.g., generating a piano track that complements given bass and drum tracks). We compared our model with existing multi-track generative models and demonstrated that\u00a0\u2026"
      }
    ]
  },
  {
    "name": "Hao-Wen Dong",
    "scholar_id": "tEOa3O4AAAAJ",
    "publications": [
      {
        "title": "MuseGAN: Multi-track sequential generative adversarial networks for symbolic music generation and accompaniment",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:d1gkVwhDpl0C",
        "authors": [
          "Hao-Wen Dong",
          "Wen-Yi Hsiao",
          "Li-Chia Yang",
          "Yi-Hsuan Yang"
        ],
        "publication_date": "2018-04-25",
        "conference": "AAAI Conference on Artificial Intelligence",
        "description": "Generating music has a few notable differences from generating images and videos. First, music is an art of time, necessitating a temporal model. Second, music is usually composed of multiple instruments/tracks with their own temporal dynamics, but collectively they unfold over time interdependently. Lastly, musical notes are often grouped into chords, arpeggios or melodies in polyphonic music, and thereby introducing a chronological ordering of notes is not naturally suitable. In this paper, we propose three models for symbolic multi-track music generation under the framework of generative adversarial networks (GANs). The three models, which differ in the underlying assumptions and accordingly the network architectures, are referred to as the jamming model, the composer model and the hybrid model. We trained the proposed models on a dataset of over one hundred thousand bars of rock music and applied them to generate piano-rolls of five tracks: bass, drums, guitar, piano and strings. A few intra-track and inter-track objective metrics are also proposed to evaluate the generative results, in addition to a subjective user study. We show that our models can generate coherent music of four bars right from scratch (ie without human inputs). We also extend our models to human-AI cooperative music generation: given a specific track composed by human, we can generate four additional tracks to accompany it. All code, the dataset and the rendered audio samples are available at https://salu133445. github. io/musegan/.",
        "total_citations": 740
      },
      {
        "title": "Convolutional generative adversarial networks with binary neurons for polyphonic music generation",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:9yKSN-GCB0IC",
        "authors": [
          "Hao-Wen Dong",
          "Yi-Hsuan Yang"
        ],
        "publication_date": "2018-04-25",
        "conference": "International Society for Music Information Retrieval Conference",
        "description": "It has been shown recently that deep convolutional generative adversarial networks (GANs) can learn to generate music in the form of piano-rolls, which represent music by binary-valued time-pitch matrices. However, existing models can only generate real-valued piano-rolls and require further post-processing, such as hard thresholding (HT) or Bernoulli sampling (BS), to obtain the final binary-valued results. In this paper, we study whether we can have a convolutional GAN model that directly creates binary-valued piano-rolls by using binary neurons. Specifically, we propose to append to the generator an additional refiner network, which uses binary neurons at the output layer. The whole network is trained in two stages. Firstly, the generator and the discriminator are pretrained. Then, the refiner network is trained along with the discriminator to learn to binarize the real-valued piano-rolls the pretrained generator creates. Experimental results show that using binary neurons instead of HT or BS indeed leads to better results in a number of objective measures. Moreover, deterministic binary neurons perform better than stochastic ones in both objective measures and a subjective test. The source code, training data and audio examples of the generated results can be found at https://salu133445.github.io/bmusegan/ .",
        "total_citations": 131
      },
      {
        "title": "MusPy: A Toolkit for Symbolic Music Generation",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:ufrVoPGSRksC",
        "authors": [
          "Hao-Wen Dong",
          "Ke Chen",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick"
        ],
        "publication_date": "2020-08-05",
        "conference": "International Society for Music Information Retrieval Conference",
        "description": "In this paper, we present MusPy, an open source Python library for symbolic music generation. MusPy provides easy-to-use tools for essential components in a music generation system, including dataset management, data I/O, data preprocessing and model evaluation. In order to showcase its potential, we present statistical analysis of the eleven datasets currently supported by MusPy. Moreover, we conduct a cross-dataset generalizability experiment by training an autoregressive model on each dataset and measuring held-out likelihood on the others---a process which is made easier by MusPy's dataset management system. The results provide a map of domain overlap between various commonly used datasets and show that some datasets contain more representative cross-genre samples than others. Along with the dataset analysis, these results might serve as a guide for choosing datasets in future research. Source code and documentation are available at https://github.com/salu133445/muspy .",
        "total_citations": 75
      },
      {
        "title": "Automatic melody harmonization with triad chords: A comparative study",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:eQOLeE2rZwMC",
        "authors": [
          "Yin-Cheng Yeh",
          "Wen-Yi Hsiao",
          "Satoru Fukayama",
          "Tetsuro Kitahara",
          "Benjamin Genchel",
          "Hao-Min Liu",
          "Hao-Wen Dong",
          "Yian Chen",
          "Terence Leong",
          "Yi-Hsuan Yang"
        ],
        "publication_date": "2021-01-01",
        "pages": "37-51",
        "publisher": "Routledge",
        "description": "The task of automatic melody harmonization aims to build a model that generates a chord sequence as the harmonic accompaniment of a given multiple-bar melody sequence. In this paper, we present a comparative study evaluating the performance of canonical approaches to this task, including template matching, hidden Markov model, genetic algorithm and deep learning. The evaluation is conducted on a dataset of 9226 melody/chord pairs, considering 48 different triad chords. We report the result of an objective evaluation using six different metrics and a subjective study with 202 participants, showing that a deep learning method performs the best.",
        "total_citations": 59
      },
      {
        "title": "Pypianoroll: Open source Python package for handling multitrack pianoroll",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:IjCSPb-OGe4C",
        "authors": [
          "Hao-Wen Dong",
          "Wen-Yi Hsiao",
          "Yi-Hsuan Yang"
        ],
        "publication_date": "2018-10-17",
        "description": "The pianoroll representation represents music data as timepitch matrices. Although it has been used widely as a way to visualize music data, it has not been much used in computational modeling of music. To promote its usage, we present in this paper a new, open source Python package called Pypianoroll for handling multitrack pianorolls. The core element of Pypianoroll is a new, lightweight multitrack pianoroll format that contains additional tempo and program information along with the pianoroll matrices. It provides tools for creating, manipulating, storing, analyzing and visualizing multitrack pianorolls in an intuitive way. Code and documentation are available at https://github. com/salu133445/pypianoroll.",
        "total_citations": 59
      },
      {
        "title": "Multitrack music transformer",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:3fE2CSJIrl8C",
        "authors": [
          "Hao-Wen Dong",
          "Ke Chen",
          "Shlomo Dubnov",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick"
        ],
        "publication_date": "2023-06-04",
        "conference": "ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
        "pages": "1-5",
        "publisher": "IEEE",
        "description": "Existing approaches for generating multitrack music with transformer models have been limited in terms of the number of instruments, the length of the music segments and slow inference. This is partly due to the memory requirements of the lengthy input sequences necessitated by existing representations. In this work, we propose a new multitrack music representation that allows a diverse set of instruments while keeping a short sequence length. Our proposed Multitrack Music Transformer (MMT) achieves comparable performance with state-of-the-art systems, landing in between two recently proposed models in a subjective listening test, while achieving substantial speedups and memory reductions over both, making the method attractive for real time improvisation or near real time creative applications. Further, we propose a new measure for analyzing musical self-attention and show that the trained model\u00a0\u2026",
        "total_citations": 56
      },
      {
        "title": "On Output Activation Functions for Adversarial Losses: A Theoretical Analysis via Variational Divergence Minimization and An Empirical Study on MNIST Classification",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:YOwf2qJgpHMC",
        "authors": [
          "Hao-Wen Dong",
          "Yi-Hsuan Yang"
        ],
        "publication_date": "2019-01-25",
        "description": "Recent years have seen adversarial losses been applied to many fields. Their applications extend beyond the originally proposed generative modeling to conditional generative and discriminative settings. While prior work has proposed various output activation functions and regularization approaches, some open questions still remain unanswered. In this paper, we aim to study the following two research questions: 1) What types of output activation functions form a well-behaved adversarial loss? 2) How different combinations of output activation functions and regularization approaches perform empirically against one another? To answer the first question, we adopt the perspective of variational divergence minimization and consider an adversarial loss well-behaved if it behaves as a divergence-like measure between the data and model distributions. Using a generalized formulation for adversarial losses, we derive the necessary and sufficient conditions of a well-behaved adversarial loss. Our analysis reveals a large class of theoretically valid adversarial losses. For the second question, we propose a simple comparative framework for adversarial losses using discriminative adversarial networks. The proposed framework allows us to efficiently evaluate adversarial losses using a standard evaluation metric such as the classification accuracy. With the proposed framework, we evaluate a comprehensive set of 168 combinations of twelve output activation functions and fourteen regularization approaches on the handwritten digit classification problem to decouple their effects. Our empirical findings suggest that there is no single winning\u00a0\u2026",
        "total_citations": 39
      },
      {
        "title": "Deep performer: Score-to-audio music performance synthesis",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:0EnyYjriUFMC",
        "authors": [
          "Hao-Wen Dong",
          "Cong Zhou",
          "Taylor Berg-Kirkpatrick",
          "Julian McAuley"
        ],
        "publication_date": "2022-05-23",
        "conference": "ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
        "pages": "951-955",
        "publisher": "IEEE",
        "description": "Music performance synthesis aims to synthesize a musical score into a natural performance. In this paper, we borrow recent advances in text-to-speech synthesis and present the Deep Performer\u2014a novel system for score-to-audio music performance synthesis. Unlike speech, music often contains polyphony and long notes. Hence, we propose two new techniques for handling polyphonic inputs and providing a fine-grained conditioning in a transformer encoder-decoder model. To train our proposed system, we present a new violin dataset consisting of paired recordings and scores along with estimated alignments between them. We show that our proposed model can synthesize music with clear polyphony and harmonic structures. In a listening test, we achieve competitive quality against the baseline model, a conditional generative audio model, in terms of pitch accuracy, timbre and noise level. Moreover, our\u00a0\u2026",
        "total_citations": 25
      },
      {
        "title": "Clipsep: Learning text-queried sound separation with noisy unlabeled videos",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:MXK_kJrjxJIC",
        "authors": [
          "Hao-Wen Dong",
          "Naoya Takahashi",
          "Yuki Mitsufuji",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick"
        ],
        "publication_date": "2022-12-14",
        "description": "Recent years have seen progress beyond domain-specific sound separation for speech or music towards universal sound separation for arbitrary sounds. Prior work on universal sound separation has investigated separating a target sound out of an audio mixture given a text query. Such text-queried sound separation systems provide a natural and scalable interface for specifying arbitrary target sounds. However, supervised text-queried sound separation systems require costly labeled audio-text pairs for training. Moreover, the audio provided in existing datasets is often recorded in a controlled environment, causing a considerable generalization gap to noisy audio in the wild. In this work, we aim to approach text-queried universal sound separation by using only unlabeled data. We propose to leverage the visual modality as a bridge to learn the desired audio-textual correspondence. The proposed CLIPSep model first encodes the input query into a query vector using the contrastive language-image pretraining (CLIP) model, and the query vector is then used to condition an audio separation model to separate out the target sound. While the model is trained on image-audio pairs extracted from unlabeled videos, at test time we can instead query the model with text inputs in a zero-shot setting, thanks to the joint language-image embedding learned by the CLIP model. Further, videos in the wild often contain off-screen sounds and background noise that may hinder the model from learning the desired audio-textual correspondence. To address this problem, we further propose an approach called noise invariant training for training a query-based\u00a0\u2026",
        "total_citations": 20
      },
      {
        "title": "An Empirical Evaluation of End-to-End Polyphonic Optical Music Recognition",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:roLk4NBRz8UC",
        "authors": [
          "Sachinda Edirisooriya",
          "Hao-Wen Dong",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick"
        ],
        "publication_date": "2021-08-03",
        "conference": "International Society for Music Information Retrieval Conference",
        "description": "Previous work has shown that neural architectures are able to perform optical music recognition (OMR) on monophonic and homophonic music with high accuracy. However, piano and orchestral scores frequently exhibit polyphonic passages, which add a second dimension to the task. Monophonic and homophonic music can be described as homorhythmic, or having a single musical rhythm. Polyphonic music, on the other hand, can be seen as having multiple rhythmic sequences, or voices, concurrently. We first introduce a workflow for creating large-scale polyphonic datasets suitable for end-to-end recognition from sheet music publicly available on the MuseScore forum. We then propose two novel formulations for end-to-end polyphonic OMR -- one treating the problem as a type of multi-task binary classification, and the other treating it as multi-sequence detection. Building upon the encoder-decoder architecture and an image encoder proposed in past work on end-to-end OMR, we propose two novel decoder models -- FlagDecoder and RNNDecoder -- that correspond to the two formulations. Finally, we compare the empirical performance of these end-to-end approaches to polyphonic OMR and observe a new state-of-the-art performance with our multi-sequence detection decoder, RNNDecoder.",
        "total_citations": 16
      },
      {
        "title": "MuseGAN: demonstration of a convolutional gan based model for generating multi-track piano-rolls",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:YsMSGLbcyi4C",
        "authors": [
          "Hao-Wen Dong",
          "Wen-Yi Hsiao",
          "Li-Chia Yang",
          "Yi-Hsuan Yang"
        ],
        "publication_date": "2017-10-17",
        "description": "Generating realistic and aesthetic pieces is one of the most exciting tasks in the field. We present in this demo paper a new neural music generation model we recently proposed, called MuseGAN. We exploit the potential of applying generative adversarial networks (GANs) to generate multi-track pop/rock music of four bars, using convolutions in both the generators and the discriminators. Moreover, we propose an efficient approach for pre-processing symbolic data and share the data with the community. Our model can generate music either from scratch, or by following (accompanying) a track given by user.",
        "total_citations": 14
      },
      {
        "title": "CLIPSonic: Text-to-audio synthesis with unlabeled videos and pretrained language-vision models",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:KlAtU1dfN6UC",
        "authors": [
          "Hao-Wen Dong",
          "Xiaoyu Liu",
          "Jordi Pons",
          "Gautam Bhattacharya",
          "Santiago Pascual",
          "Joan Serr\u00e0",
          "Taylor Berg-Kirkpatrick",
          "Julian McAuley"
        ],
        "publication_date": "2023-10-22",
        "conference": "2023 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)",
        "pages": "1-5",
        "publisher": "IEEE",
        "description": "Recent work has studied text-to-audio synthesis using large amounts of paired text-audio data. However, audio recordings with high-quality text annotations can be difficult to acquire. In this work, we approach text-to-audio synthesis using unlabeled videos and pre-trained language-vision models. We propose to learn the desired text-audio correspondence by leveraging the visual modality as a bridge. We train a conditional diffusion model to generate the audio track of a video, given a video frame encoded by a pretrained contrastive language-image pretraining (CLIP) model. At test time, we first explore performing a zero-shot modality transfer and condition the diffusion model with a CLIP-encoded text query. However, we observe a noticeable performance drop with respect to image queries. To close this gap, we further adopt a pretrained diffusion prior model to generate a CLIP image embedding given a CLIP\u00a0\u2026",
        "total_citations": 13
      },
      {
        "title": "Training generative adversarial networks with binary neurons by end-to-end backpropagation",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:zYLM7Y9cAGgC",
        "authors": [
          "Hao-Wen Dong",
          "Yi-Hsuan Yang"
        ],
        "publication_date": "2018-10-10",
        "description": "We propose the BinaryGAN, a novel generative adversarial network (GAN) that uses binary neurons at the output layer of the generator. We employ the sigmoid-adjusted straight-through estimators to estimate the gradients for the binary neurons and train the whole network by end-to-end backpropogation. The proposed model is able to directly generate binary-valued predictions at test time. We implement such a model to generate binarized MNIST digits and experimentally compare the performance for different types of binary neurons, GAN objectives and network architectures. Although the results are still preliminary, we show that it is possible to train a GAN that has binary neurons and that the use of gradient estimators can be a promising direction for modeling discrete distributions with GANs. For reproducibility, the source code is available at https://github.com/salu133445/binarygan .",
        "total_citations": 11
      },
      {
        "title": "Towards Automatic Instrumentation by Learning to Separate Parts in Symbolic Multitrack Music",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:LkGwnXOMwfcC",
        "authors": [
          "Hao-Wen Dong",
          "Chris Donahue",
          "Taylor Berg-Kirkpatrick",
          "Julian McAuley"
        ],
        "publication_date": "2021-07-13",
        "conference": "International Society for Music Information Retrieval Conference",
        "description": "Modern keyboards allow a musician to play multiple instruments at the same time by assigning zones -- fixed pitch ranges of the keyboard -- to different instruments. In this paper, we aim to further extend this idea and examine the feasibility of automatic instrumentation -- dynamically assigning instruments to notes in solo music during performance. In addition to the online, real-time-capable setting for performative use cases, automatic instrumentation can also find applications in assistive composing tools in an offline setting. Due to the lack of paired data of original solo music and their full arrangements, we approach automatic instrumentation by learning to separate parts (e.g., voices, instruments and tracks) from their mixture in symbolic multitrack music, assuming that the mixture is to be played on a keyboard. We frame the task of part separation as a sequential multi-class classification problem and adopt machine learning to map sequences of notes into sequences of part labels. To examine the effectiveness of our proposed models, we conduct a comprehensive empirical evaluation over four diverse datasets of different genres and ensembles -- Bach chorales, string quartets, game music and pop music. Our experiments show that the proposed models outperform various baselines. We also demonstrate the potential for our proposed models to produce alternative convincing instrumentations for an existing arrangement by separating its mixture into parts. All source code and audio samples can be found at https://salu133445.github.io/arranger/ .",
        "total_citations": 7
      },
      {
        "title": "Improving choral music separation through expressive synthesized data from sampled instruments",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:8k81kl-MbHgC",
        "authors": [
          "Ke Chen",
          "Hao-Wen Dong",
          "Yi Luo",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick",
          "Miller Puckette",
          "Shlomo Dubnov"
        ],
        "publication_date": "2022-09-07",
        "description": "Choral music separation refers to the task of extracting tracks of voice parts (e.g., soprano, alto, tenor, and bass) from mixed audio. The lack of datasets has impeded research on this topic as previous work has only been able to train and evaluate models on a few minutes of choral music data due to copyright issues and dataset collection difficulties. In this paper, we investigate the use of synthesized training data for the source separation task on real choral music. We make three contributions: first, we provide an automated pipeline for synthesizing choral music data from sampled instrument plugins within controllable options for instrument expressiveness. This produces an 8.2-hour-long choral music dataset from the JSB Chorales Dataset and one can easily synthesize additional data. Second, we conduct an experiment to evaluate multiple separation models on available choral music separation datasets from previous work. To the best of our knowledge, this is the first experiment to comprehensively evaluate choral music separation. Third, experiments demonstrate that the synthesized choral data is of sufficient quality to improve the model's performance on real choral music datasets. This provides additional experimental statistics and data support for the choral music separation study.",
        "total_citations": 5
      },
      {
        "title": "Futga: Towards fine-grained music understanding through temporally-enhanced generative augmentation",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:qxL8FJ1GzNcC",
        "authors": [
          "Junda Wu",
          "Zachary Novack",
          "Amit Namburi",
          "Jiaheng Dai",
          "Hao-Wen Dong",
          "Zhouhang Xie",
          "Carol Chen",
          "Julian McAuley"
        ],
        "publication_date": "2024-07-29",
        "description": "Existing music captioning methods are limited to generating concise global descriptions of short music clips, which fail to capture fine-grained musical characteristics and time-aware musical changes. To address these limitations, we propose FUTGA, a model equipped with fined-grained music understanding capabilities through learning from generative augmentation with temporal compositions. We leverage existing music caption datasets and large language models (LLMs) to synthesize fine-grained music captions with structural descriptions and time boundaries for full-length songs. Augmented by the proposed synthetic dataset, FUTGA is enabled to identify the music's temporal changes at key transition points and their musical functions, as well as generate detailed descriptions for each music segment. We further introduce a full-length music caption dataset generated by FUTGA, as the augmentation of the MusicCaps and the Song Describer datasets. We evaluate the automatically generated captions on several downstream tasks, including music generation and retrieval. The experiments demonstrate the quality of the generated captions and the better performance in various downstream tasks achieved by the proposed music captioning approach. Our code and datasets can be found in \\href{https://huggingface.co/JoshuaW1997/FUTGA}{\\textcolor{blue}{https://huggingface.co/JoshuaW1997/FUTGA}}.",
        "total_citations": 1
      },
      {
        "title": "Equipping Pretrained Unconditional Music Transformers with Instrument and Genre Controls",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:4TOpqqG69KYC",
        "authors": [
          "Weihan Xu",
          "Julian McAuley",
          "Shlomo Dubnov",
          "Hao-Wen Dong"
        ],
        "publication_date": "2023-12-15",
        "conference": "2023 IEEE International Conference on Big Data (BigData)",
        "pages": "4512-4517",
        "publisher": "IEEE",
        "description": "The \u201cpretraining-and-finetuning\u201d paradigm has become a norm for training domain-specific models in natural language processing and computer vision. In this work, we aim to examine this paradigm for symbolic music generation through leveraging the largest ever symbolic music dataset sourced from the MuseScore forum. We first pretrain a large unconditional transformer model using 1.5 million songs. We then propose a simple technique to equip this pretrained unconditional music transformer model with instrument and genre controls by finetuning the model with additional control tokens. Our proposed representation offers improved high-level controllability and expressiveness against two existing representations. The experimental results show that the proposed model can successfully generate music with user-specified instruments and genre. In a subjective listening test, the proposed model outperforms the\u00a0\u2026",
        "total_citations": 1
      },
      {
        "title": "TeaserGen: Generating Teasers for Long Documentaries",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:mVmsd5A6BfQC",
        "authors": [
          "Weihan Xu",
          "Paul Pu Liang",
          "Haven Kim",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick",
          "Hao-Wen Dong"
        ],
        "publication_date": "2024-10-08",
        "description": "Teasers are an effective tool for promoting content in entertainment, commercial and educational fields. However, creating an effective teaser for long videos is challenging for it requires long-range multimodal modeling on the input videos, while necessitating maintaining audiovisual alignments, managing scene changes and preserving factual accuracy for the output teasers. Due to the lack of a publicly-available dataset, progress along this research direction has been hindered. In this work, we present DocumentaryNet, a collection of 1,269 documentaries paired with their teasers, featuring multimodal data streams of video, speech, music, sound effects and narrations. With DocumentaryNet, we propose a new two-stage system for generating teasers from long documentaries. The proposed TeaserGen system first generates the teaser narration from the transcribed narration of the documentary using a pretrained large language model, and then selects the most relevant visual content to accompany the generated narration through language-vision models. For narration-video matching, we explore two approaches: a pretraining-based model using pretrained contrastive language-vision models and a deep sequential model that learns the mapping between the narrations and visuals. Our experimental results show that the pretraining-based approach is more effective at identifying relevant visual content than directly trained deep autoregressive models."
      },
      {
        "title": "Deriving Representative Structure Over Music Corpora",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:9ZlFYXVOiuMC",
        "authors": [
          "Ilana Shapiro",
          "Ruanqianqian Huang",
          "Zachary Novack",
          "Cheng-I Wang",
          "Hao-Wen Dong",
          "Taylor Berg-Kirkpatrick",
          "Shlomo Dubnov",
          "Sorin Lerner"
        ],
        "publication_date": "2024-10-05",
        "description": "Western music is an innately hierarchical system of interacting levels of structure, from fine-grained melody to high-level form. In order to analyze music compositions holistically and at multiple granularities, we propose a unified, hierarchical meta-representation of musical structure called the structural temporal graph (STG). For a single piece, the STG is a data structure that defines a hierarchy of progressively finer structural musical features and the temporal relationships between them. We use the STG to enable a novel approach for deriving a representative structural summary of a music corpus, which we formalize as a dually NP-hard combinatorial optimization problem. Our approach first applies simulated annealing to develop a measure of structural distance between two music pieces rooted in graph isomorphism. Our approach then combines the formal guarantees of SMT solvers with nested simulated annealing over structural distances to produce a structurally sound, representative centroid STG for an entire corpus of STGs obtained from individual pieces. To evaluate our approach, we conduct experiments showing that structural distance accurately differentiates between music pieces, and that our computed centroids encapsulate the overarching structure of a music corpus."
      },
      {
        "title": "Generating Symbolic Music from Natural Language Prompts using an LLM-Enhanced Dataset",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:Wp0gIr-vW9MC",
        "authors": [
          "Weihan Xu",
          "Julian McAuley",
          "Taylor Berg-Kirkpatrick",
          "Shlomo Dubnov",
          "Hao-Wen Dong"
        ],
        "publication_date": "2024-10-02",
        "description": "Recent years have seen many audio-domain text-to-music generation models that rely on large amounts of text-audio pairs for training. However, symbolic-domain controllable music generation has lagged behind partly due to the lack of a large-scale symbolic music dataset with extensive metadata and captions. In this work, we present MetaScore, a new dataset consisting of 963K musical scores paired with rich metadata, including free-form user-annotated tags, collected from an online music forum. To approach text-to-music generation, we leverage a pretrained large language model (LLM) to generate pseudo natural language captions from the metadata. With the LLM-enhanced MetaScore, we train a text-conditioned music generation model that learns to generate symbolic music from the pseudo captions, allowing control of instruments, genre, composer, complexity and other free-form music descriptors. In addition, we train a tag-conditioned system that supports a predefined set of tags available in MetaScore. Our experimental results show that both the proposed text-to-music and tags-to-music models outperform a baseline text-to-music model in a listening test, while the text-based system offers a more natural interface that allows free-form natural language prompts."
      },
      {
        "title": "ViolinDiff: Enhancing Expressive Violin Synthesis with Pitch Bend Conditioning",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:4DMP91E08xMC",
        "authors": [
          "Daewoong Kim",
          "Hao-Wen Dong",
          "Dasaem Jeong"
        ],
        "publication_date": "2024-09-19",
        "description": "Modeling the natural contour of fundamental frequency (F0) plays a critical role in music audio synthesis. However, transcribing and managing multiple F0 contours in polyphonic music is challenging, and explicit F0 contour modeling has not yet been explored for polyphonic instrumental synthesis. In this paper, we present ViolinDiff, a two-stage diffusion-based synthesis framework. For a given violin MIDI file, the first stage estimates the F0 contour as pitch bend information, and the second stage generates mel spectrogram incorporating these expressive details. The quantitative metrics and listening test results show that the proposed model generates more realistic violin sounds than the model without explicit pitch bend modeling. Audio samples are available online: daewoung.github.io/ViolinDiff-Demo."
      },
      {
        "title": "Nested Music Transformer: Sequentially Decoding Compound Tokens in Symbolic Music and Audio Generation",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:aqlVkmm33-oC",
        "authors": [
          "Jiwoo Ryu",
          "Hao-Wen Dong",
          "Jongmin Jung",
          "Dasaem Jeong"
        ],
        "publication_date": "2024-08-02",
        "description": "Representing symbolic music with compound tokens, where each token consists of several different sub-tokens representing a distinct musical feature or attribute, offers the advantage of reducing sequence length. While previous research has validated the efficacy of compound tokens in music sequence modeling, predicting all sub-tokens simultaneously can lead to suboptimal results as it may not fully capture the interdependencies between them. We introduce the Nested Music Transformer (NMT), an architecture tailored for decoding compound tokens autoregressively, similar to processing flattened tokens, but with low memory usage. The NMT consists of two transformers: the main decoder that models a sequence of compound tokens and the sub-decoder for modeling sub-tokens of each compound token. The experiment results showed that applying the NMT to compound tokens can enhance the performance in terms of better perplexity in processing various symbolic music datasets and discrete audio tokens from the MAESTRO dataset."
      },
      {
        "title": "Generative AI for Music and Audio",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:M3ejUd6NZC8C",
        "authors": [
          "Hao-Wen Dong"
        ],
        "publication_date": "2024-10-17",
        "description": "Generative AI has been transforming the way we interact with technology and consume content. In the next decade, AI technology will reshape how we create audio content in various media, including music, theater, films, games, podcasts, and short videos. In this dissertation, I introduce the three main directions of my research centered around generative AI for music and audio: 1) multitrack music generation, 2) assistive music creation tools, and 3) multimodal learning for audio and music. Through my research, I aim to answer the following two fundamental questions: 1) How can AI help professionals or amateurs create music and audio content? 2) Can AI learn to create music in a way similar to how humans learn music? My long-term goal is to lower the barrier of entry for music composition and democratize audio content creation."
      },
      {
        "title": "Flow-based Deep Generative Models",
        "link": "/citations?view_op=view_citation&hl=en&user=tEOa3O4AAAAJ&pagesize=100&citation_for_view=tEOa3O4AAAAJ:Se3iqnhoufwC",
        "authors": [
          "Jiarui Xu",
          "Hao-Wen Dong"
        ],
        "description": "Flow-based Deep Generative Models Page 1 Flow-based Deep Generative Models Jiarui Xu \nand Hao-Wen Dong 1 Page 2 Outlines Deep generative models Different generative models \nGAN vs VAE vs Flow-based models Linear algebra basics Jacobian matrix and determinant \nChange of variable theorem Normalizing Flows NICE, RealNVP and Glow Autoregressive Flows \nMAF and IAF 2 Page 3 Deep Generative Models 3 Page 4 Different generative models Ian \nGoodfellow, \"Generative Adversarial Networks,\" NeurIPS tutorial, 2016. 4 Page 5 Generative \nAdversarial Networks (GANs) Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, \nDavid Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio, \"Generative Adversarial \nNets,\" NeurIPS, 2014. 5 Page 6 Generative Adversarial Networks (GANs) A discriminator \nestimates the probability of a given sample coming from the real dataset. A generator \u2026"
      }
    ]
  }
]